{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58fbf15f",
      "metadata": {
        "id": "58fbf15f",
        "outputId": "b32f3345-c27d-4763-927e-1a5b8f58ac2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: flaml[notebook]==1.0.10 in c:\\users\\17247\\anaconda3\\lib\\site-packages (1.0.10)\n",
            "Requirement already satisfied: scikit-learn>=0.24 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from flaml[notebook]==1.0.10) (0.24.1)\n",
            "Requirement already satisfied: xgboost>=0.90 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from flaml[notebook]==1.0.10) (1.6.2)\n",
            "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from flaml[notebook]==1.0.10) (1.2.4)\n",
            "Requirement already satisfied: NumPy>=1.17.0rc1 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from flaml[notebook]==1.0.10) (1.20.1)\n",
            "Requirement already satisfied: lightgbm>=2.3.1 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from flaml[notebook]==1.0.10) (3.3.2)\n",
            "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from flaml[notebook]==1.0.10) (1.6.2)\n",
            "Requirement already satisfied: matplotlib in c:\\users\\17247\\anaconda3\\lib\\site-packages (from flaml[notebook]==1.0.10) (3.3.4)\n",
            "Requirement already satisfied: catboost>=0.26 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from flaml[notebook]==1.0.10) (1.1)\n",
            "Requirement already satisfied: jupyter in c:\\users\\17247\\anaconda3\\lib\\site-packages (from flaml[notebook]==1.0.10) (1.0.0)\n",
            "Requirement already satisfied: rgf-python in c:\\users\\17247\\anaconda3\\lib\\site-packages (from flaml[notebook]==1.0.10) (3.12.0)\n",
            "Requirement already satisfied: openml==0.10.2 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from flaml[notebook]==1.0.10) (0.10.2)\n",
            "Requirement already satisfied: liac-arff>=2.4.0 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from openml==0.10.2->flaml[notebook]==1.0.10) (2.5.0)\n",
            "Requirement already satisfied: xmltodict in c:\\users\\17247\\anaconda3\\lib\\site-packages (from openml==0.10.2->flaml[notebook]==1.0.10) (0.12.0)\n",
            "Requirement already satisfied: python-dateutil in c:\\users\\17247\\anaconda3\\lib\\site-packages (from openml==0.10.2->flaml[notebook]==1.0.10) (2.8.1)\n",
            "Requirement already satisfied: requests in c:\\users\\17247\\anaconda3\\lib\\site-packages (from openml==0.10.2->flaml[notebook]==1.0.10) (2.25.1)\n",
            "Requirement already satisfied: graphviz in c:\\users\\17247\\anaconda3\\lib\\site-packages (from catboost>=0.26->flaml[notebook]==1.0.10) (0.20.1)\n",
            "Requirement already satisfied: six in c:\\users\\17247\\anaconda3\\lib\\site-packages (from catboost>=0.26->flaml[notebook]==1.0.10) (1.15.0)\n",
            "Requirement already satisfied: plotly in c:\\users\\17247\\anaconda3\\lib\\site-packages (from catboost>=0.26->flaml[notebook]==1.0.10) (5.10.0)\n",
            "Requirement already satisfied: wheel in c:\\users\\17247\\anaconda3\\lib\\site-packages (from lightgbm>=2.3.1->flaml[notebook]==1.0.10) (0.36.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->flaml[notebook]==1.0.10) (2021.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from scikit-learn>=0.24->flaml[notebook]==1.0.10) (2.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from scikit-learn>=0.24->flaml[notebook]==1.0.10) (1.0.1)\n",
            "Requirement already satisfied: qtconsole in c:\\users\\17247\\anaconda3\\lib\\site-packages (from jupyter->flaml[notebook]==1.0.10) (5.0.3)\n",
            "Requirement already satisfied: notebook in c:\\users\\17247\\anaconda3\\lib\\site-packages (from jupyter->flaml[notebook]==1.0.10) (6.3.0)\n",
            "Requirement already satisfied: ipykernel in c:\\users\\17247\\anaconda3\\lib\\site-packages (from jupyter->flaml[notebook]==1.0.10) (5.3.4)\n",
            "Requirement already satisfied: ipywidgets in c:\\users\\17247\\anaconda3\\lib\\site-packages (from jupyter->flaml[notebook]==1.0.10) (7.6.3)\n",
            "Requirement already satisfied: nbconvert in c:\\users\\17247\\anaconda3\\lib\\site-packages (from jupyter->flaml[notebook]==1.0.10) (6.0.7)\n",
            "Requirement already satisfied: jupyter-console in c:\\users\\17247\\anaconda3\\lib\\site-packages (from jupyter->flaml[notebook]==1.0.10) (6.4.0)\n",
            "Requirement already satisfied: tornado>=4.2 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from ipykernel->jupyter->flaml[notebook]==1.0.10) (6.1)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from ipykernel->jupyter->flaml[notebook]==1.0.10) (5.0.5)\n",
            "Requirement already satisfied: jupyter-client in c:\\users\\17247\\anaconda3\\lib\\site-packages (from ipykernel->jupyter->flaml[notebook]==1.0.10) (6.1.12)\n",
            "Requirement already satisfied: ipython>=5.0.0 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from ipykernel->jupyter->flaml[notebook]==1.0.10) (7.22.0)\n",
            "Requirement already satisfied: pygments in c:\\users\\17247\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel->jupyter->flaml[notebook]==1.0.10) (2.8.1)\n",
            "Requirement already satisfied: backcall in c:\\users\\17247\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel->jupyter->flaml[notebook]==1.0.10) (0.2.0)\n",
            "Requirement already satisfied: pickleshare in c:\\users\\17247\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel->jupyter->flaml[notebook]==1.0.10) (0.7.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel->jupyter->flaml[notebook]==1.0.10) (52.0.0.post20210125)\n",
            "Requirement already satisfied: jedi>=0.16 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel->jupyter->flaml[notebook]==1.0.10) (0.17.2)\n",
            "Requirement already satisfied: decorator in c:\\users\\17247\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel->jupyter->flaml[notebook]==1.0.10) (5.0.6)\n",
            "Requirement already satisfied: colorama in c:\\users\\17247\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel->jupyter->flaml[notebook]==1.0.10) (0.4.4)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel->jupyter->flaml[notebook]==1.0.10) (3.0.17)\n",
            "Requirement already satisfied: parso<0.8.0,>=0.7.0 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from jedi>=0.16->ipython>=5.0.0->ipykernel->jupyter->flaml[notebook]==1.0.10) (0.7.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: wcwidth in c:\\users\\17247\\anaconda3\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.0.0->ipykernel->jupyter->flaml[notebook]==1.0.10) (0.2.5)\n",
            "Requirement already satisfied: ipython-genutils in c:\\users\\17247\\anaconda3\\lib\\site-packages (from traitlets>=4.1.0->ipykernel->jupyter->flaml[notebook]==1.0.10) (0.2.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from ipywidgets->jupyter->flaml[notebook]==1.0.10) (1.0.0)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from ipywidgets->jupyter->flaml[notebook]==1.0.10) (5.1.3)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from ipywidgets->jupyter->flaml[notebook]==1.0.10) (3.5.1)\n",
            "Requirement already satisfied: jupyter-core in c:\\users\\17247\\anaconda3\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets->jupyter->flaml[notebook]==1.0.10) (4.7.1)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets->jupyter->flaml[notebook]==1.0.10) (3.2.0)\n",
            "Requirement already satisfied: pyrsistent>=0.14.0 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter->flaml[notebook]==1.0.10) (0.17.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter->flaml[notebook]==1.0.10) (20.3.0)\n",
            "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from notebook->jupyter->flaml[notebook]==1.0.10) (0.9.4)\n",
            "Requirement already satisfied: pyzmq>=17 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from notebook->jupyter->flaml[notebook]==1.0.10) (20.0.0)\n",
            "Requirement already satisfied: argon2-cffi in c:\\users\\17247\\anaconda3\\lib\\site-packages (from notebook->jupyter->flaml[notebook]==1.0.10) (20.1.0)\n",
            "Requirement already satisfied: prometheus-client in c:\\users\\17247\\anaconda3\\lib\\site-packages (from notebook->jupyter->flaml[notebook]==1.0.10) (0.10.1)\n",
            "Requirement already satisfied: Send2Trash>=1.5.0 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from notebook->jupyter->flaml[notebook]==1.0.10) (1.5.0)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from notebook->jupyter->flaml[notebook]==1.0.10) (2.11.3)\n",
            "Requirement already satisfied: pywin32>=1.0 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from jupyter-core->nbformat>=4.2.0->ipywidgets->jupyter->flaml[notebook]==1.0.10) (227)\n",
            "Requirement already satisfied: pywinpty>=0.5 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from terminado>=0.8.3->notebook->jupyter->flaml[notebook]==1.0.10) (0.5.7)\n",
            "Requirement already satisfied: cffi>=1.0.0 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from argon2-cffi->notebook->jupyter->flaml[notebook]==1.0.10) (1.14.5)\n",
            "Requirement already satisfied: pycparser in c:\\users\\17247\\anaconda3\\lib\\site-packages (from cffi>=1.0.0->argon2-cffi->notebook->jupyter->flaml[notebook]==1.0.10) (2.20)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from jinja2->notebook->jupyter->flaml[notebook]==1.0.10) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from matplotlib->flaml[notebook]==1.0.10) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from matplotlib->flaml[notebook]==1.0.10) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from matplotlib->flaml[notebook]==1.0.10) (2.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from matplotlib->flaml[notebook]==1.0.10) (8.2.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from nbconvert->jupyter->flaml[notebook]==1.0.10) (0.8.4)\n",
            "Requirement already satisfied: bleach in c:\\users\\17247\\anaconda3\\lib\\site-packages (from nbconvert->jupyter->flaml[notebook]==1.0.10) (3.3.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from nbconvert->jupyter->flaml[notebook]==1.0.10) (0.3)\n",
            "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from nbconvert->jupyter->flaml[notebook]==1.0.10) (0.5.3)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from nbconvert->jupyter->flaml[notebook]==1.0.10) (1.4.3)\n",
            "Requirement already satisfied: jupyterlab-pygments in c:\\users\\17247\\anaconda3\\lib\\site-packages (from nbconvert->jupyter->flaml[notebook]==1.0.10) (0.1.2)\n",
            "Requirement already satisfied: defusedxml in c:\\users\\17247\\anaconda3\\lib\\site-packages (from nbconvert->jupyter->flaml[notebook]==1.0.10) (0.7.1)\n",
            "Requirement already satisfied: testpath in c:\\users\\17247\\anaconda3\\lib\\site-packages (from nbconvert->jupyter->flaml[notebook]==1.0.10) (0.4.4)\n",
            "Requirement already satisfied: nest-asyncio in c:\\users\\17247\\anaconda3\\lib\\site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->jupyter->flaml[notebook]==1.0.10) (1.5.1)\n",
            "Requirement already satisfied: async-generator in c:\\users\\17247\\anaconda3\\lib\\site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->jupyter->flaml[notebook]==1.0.10) (1.10)\n",
            "Requirement already satisfied: packaging in c:\\users\\17247\\anaconda3\\lib\\site-packages (from bleach->nbconvert->jupyter->flaml[notebook]==1.0.10) (20.9)\n",
            "Requirement already satisfied: webencodings in c:\\users\\17247\\anaconda3\\lib\\site-packages (from bleach->nbconvert->jupyter->flaml[notebook]==1.0.10) (0.5.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from plotly->catboost>=0.26->flaml[notebook]==1.0.10) (8.1.0)\n",
            "Requirement already satisfied: qtpy in c:\\users\\17247\\anaconda3\\lib\\site-packages (from qtconsole->jupyter->flaml[notebook]==1.0.10) (1.9.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from requests->openml==0.10.2->flaml[notebook]==1.0.10) (1.26.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from requests->openml==0.10.2->flaml[notebook]==1.0.10) (2020.12.5)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from requests->openml==0.10.2->flaml[notebook]==1.0.10) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from requests->openml==0.10.2->flaml[notebook]==1.0.10) (2.10)\n"
          ]
        }
      ],
      "source": [
        "%pip install flaml[notebook]==1.0.10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "025490e7",
      "metadata": {
        "id": "025490e7",
        "outputId": "793ccf23-c053-456d-a2e6-3e296a81291a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "load dataset from ./openml_ds40536.pkl\n",
            "Dataset name: SpeedDating\n",
            "X_train.shape: (6283, 120), y_train.shape: (6283,);\n",
            "X_test.shape: (2095, 120), y_test.shape: (2095,)\n",
            "Data type: <class 'pandas.core.frame.DataFrame'> <class 'pandas.core.series.Series'>\n",
            "The first 5 rows of X_train:\n",
            "     has_null  wave  gender   age  age_o  d_age d_d_age  \\\n",
            "5546        1  14.0    male  25.0   32.0    7.0  [7-37]   \n",
            "235         0   2.0  female  21.0   24.0    3.0   [2-3]   \n",
            "7066        1  19.0  female  26.0   29.0    3.0   [2-3]   \n",
            "7357        1  20.0  female  25.0   27.0    2.0   [2-3]   \n",
            "1108        0   4.0  female  28.0   27.0    1.0   [0-1]   \n",
            "\n",
            "                                       race  \\\n",
            "5546            European/Caucasian-American   \n",
            "235   Asian/Pacific Islander/Asian-American   \n",
            "7066            European/Caucasian-American   \n",
            "7357                 Black/African American   \n",
            "1108            European/Caucasian-American   \n",
            "\n",
            "                                     race_o samerace  ...  \\\n",
            "5546            European/Caucasian-American        1  ...   \n",
            "235             European/Caucasian-American        0  ...   \n",
            "7066               Latino/Hispanic American        0  ...   \n",
            "7357  Asian/Pacific Islander/Asian-American        0  ...   \n",
            "1108            European/Caucasian-American        1  ...   \n",
            "\n",
            "      expected_num_interested_in_me  expected_num_matches  \\\n",
            "5546                            NaN                   5.0   \n",
            "235                             3.0                   3.0   \n",
            "7066                            NaN                   NaN   \n",
            "7357                            NaN                   1.0   \n",
            "1108                            6.0                   2.0   \n",
            "\n",
            "     d_expected_happy_with_sd_people d_expected_num_interested_in_me  \\\n",
            "5546                          [7-10]                           [0-3]   \n",
            "235                            [5-6]                           [0-3]   \n",
            "7066                           [0-4]                           [0-3]   \n",
            "7357                           [5-6]                           [0-3]   \n",
            "1108                           [5-6]                           [4-9]   \n",
            "\n",
            "     d_expected_num_matches  like  guess_prob_liked  d_like  \\\n",
            "5546                  [3-5]   5.0               7.0   [0-5]   \n",
            "235                   [3-5]   7.0               6.0   [6-8]   \n",
            "7066                  [0-2]   9.0               NaN  [9-10]   \n",
            "7357                  [0-2]   5.0               4.0   [0-5]   \n",
            "1108                  [0-2]   8.0               8.0   [6-8]   \n",
            "\n",
            "      d_guess_prob_liked  met  \n",
            "5546              [7-10]  0.0  \n",
            "235                [5-6]  0.0  \n",
            "7066               [0-4]  0.0  \n",
            "7357               [0-4]  0.0  \n",
            "1108              [7-10]  0.0  \n",
            "\n",
            "[5 rows x 120 columns]\n",
            "The first 5 rows of y_train:\n",
            "5546    0\n",
            "235     1\n",
            "7066    1\n",
            "7357    0\n",
            "1108    1\n",
            "Name: match, dtype: category\n",
            "Categories (2, object): ['0' < '1']\n"
          ]
        }
      ],
      "source": [
        "from flaml.data import load_openml_dataset\n",
        "X_train, X_test, y_train, y_test = load_openml_dataset(dataset_id=40536, data_dir='./')\n",
        "print(\"Data type:\", type(X_train), type(y_train))\n",
        "print(\"The first 5 rows of X_train:\")\n",
        "print(X_train.head())\n",
        "print(\"The first 5 rows of y_train:\")\n",
        "print(y_train.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5389f5e2",
      "metadata": {
        "id": "5389f5e2"
      },
      "outputs": [],
      "source": [
        "#df = df.drop(['Rk', 'Age', 'Tm'], axis=1)   THIS CAN BE USED TO FIX XGBOOST ERROR MAYBE?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e81fe4e9",
      "metadata": {
        "id": "e81fe4e9"
      },
      "outputs": [],
      "source": [
        "from flaml import AutoML\n",
        "automl = AutoML()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63e6fe50",
      "metadata": {
        "id": "63e6fe50"
      },
      "outputs": [],
      "source": [
        "settings = {\n",
        "    \"time_budget\": 600,  # total running time in seconds\n",
        "    \"metric\": 'accuracy',  # can be: 'r2', 'rmse', 'mae', 'mse', 'accuracy', 'roc_auc', 'roc_auc_ovr',\n",
        "                           # 'roc_auc_ovo', 'log_loss', 'mape', 'f1', 'ap', 'ndcg', 'micro_f1', 'macro_f1'\n",
        "    \"task\": 'classification',  # task type\n",
        "    \"log_file_name\": 'airlines_experiment.log',  # flaml log file\n",
        "    \"seed\": 9458192,    # random seed\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d261137d",
      "metadata": {
        "id": "d261137d",
        "outputId": "dea76b57-49da-45fd-ebb3-ae956b6d5afb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[flaml.automl: 10-05 14:38:50] {2540} INFO - task = classification\n",
            "[flaml.automl: 10-05 14:38:50] {2542} INFO - Data split method: stratified\n",
            "[flaml.automl: 10-05 14:38:50] {2545} INFO - Evaluation method: cv\n",
            "[flaml.automl: 10-05 14:38:50] {2664} INFO - Minimizing error metric: 1-accuracy\n",
            "[flaml.automl: 10-05 14:38:50] {2806} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'catboost', 'xgboost', 'extra_tree', 'xgb_limitdepth', 'lrl1']\n",
            "[flaml.automl: 10-05 14:38:50] {3108} INFO - iteration 0, current learner lgbm\n",
            "[flaml.automl: 10-05 14:38:53] {3241} INFO - Estimated sufficient time budget=26600s. Estimated necessary time budget=653s.\n",
            "[flaml.automl: 10-05 14:38:53] {3288} INFO -  at 3.4s,\testimator lgbm's best error=0.1623,\tbest estimator lgbm's best error=0.1623\n",
            "[flaml.automl: 10-05 14:38:53] {3108} INFO - iteration 1, current learner lgbm\n",
            "[flaml.automl: 10-05 14:38:55] {3288} INFO -  at 5.9s,\testimator lgbm's best error=0.1550,\tbest estimator lgbm's best error=0.1550\n",
            "[flaml.automl: 10-05 14:38:55] {3108} INFO - iteration 2, current learner lgbm\n",
            "[flaml.automl: 10-05 14:38:57] {3288} INFO -  at 7.7s,\testimator lgbm's best error=0.1550,\tbest estimator lgbm's best error=0.1550\n",
            "[flaml.automl: 10-05 14:38:57] {3108} INFO - iteration 3, current learner lgbm\n",
            "[flaml.automl: 10-05 14:38:59] {3288} INFO -  at 9.9s,\testimator lgbm's best error=0.1487,\tbest estimator lgbm's best error=0.1487\n",
            "[flaml.automl: 10-05 14:38:59] {3108} INFO - iteration 4, current learner lgbm\n",
            "[flaml.automl: 10-05 14:39:02] {3288} INFO -  at 12.5s,\testimator lgbm's best error=0.1487,\tbest estimator lgbm's best error=0.1487\n",
            "[flaml.automl: 10-05 14:39:02] {3108} INFO - iteration 5, current learner lgbm\n",
            "[flaml.automl: 10-05 14:39:04] {3288} INFO -  at 14.6s,\testimator lgbm's best error=0.1455,\tbest estimator lgbm's best error=0.1455\n",
            "[flaml.automl: 10-05 14:39:04] {3108} INFO - iteration 6, current learner xgboost\n",
            "[flaml.automl: 10-05 14:39:07] {3288} INFO -  at 17.3s,\testimator xgboost's best error=0.1490,\tbest estimator lgbm's best error=0.1455\n",
            "[flaml.automl: 10-05 14:39:07] {3108} INFO - iteration 7, current learner lgbm\n",
            "[flaml.automl: 10-05 14:39:09] {3288} INFO -  at 19.8s,\testimator lgbm's best error=0.1429,\tbest estimator lgbm's best error=0.1429\n",
            "[flaml.automl: 10-05 14:39:09] {3108} INFO - iteration 8, current learner lgbm\n",
            "[flaml.automl: 10-05 14:39:12] {3288} INFO -  at 22.4s,\testimator lgbm's best error=0.1429,\tbest estimator lgbm's best error=0.1429\n",
            "[flaml.automl: 10-05 14:39:12] {3108} INFO - iteration 9, current learner lgbm\n",
            "[flaml.automl: 10-05 14:39:15] {3288} INFO -  at 25.3s,\testimator lgbm's best error=0.1429,\tbest estimator lgbm's best error=0.1429\n",
            "[flaml.automl: 10-05 14:39:15] {3108} INFO - iteration 10, current learner xgboost\n",
            "[flaml.automl: 10-05 14:39:17] {3288} INFO -  at 27.6s,\testimator xgboost's best error=0.1488,\tbest estimator lgbm's best error=0.1429\n",
            "[flaml.automl: 10-05 14:39:17] {3108} INFO - iteration 11, current learner extra_tree\n",
            "[flaml.automl: 10-05 14:39:19] {3288} INFO -  at 29.5s,\testimator extra_tree's best error=0.1623,\tbest estimator lgbm's best error=0.1429\n",
            "[flaml.automl: 10-05 14:39:19] {3108} INFO - iteration 12, current learner extra_tree\n",
            "[flaml.automl: 10-05 14:39:22] {3288} INFO -  at 32.9s,\testimator extra_tree's best error=0.1619,\tbest estimator lgbm's best error=0.1429\n",
            "[flaml.automl: 10-05 14:39:22] {3108} INFO - iteration 13, current learner rf\n",
            "[flaml.automl: 10-05 14:39:24] {3288} INFO -  at 34.8s,\testimator rf's best error=0.1623,\tbest estimator lgbm's best error=0.1429\n",
            "[flaml.automl: 10-05 14:39:24] {3108} INFO - iteration 14, current learner rf\n",
            "[flaml.automl: 10-05 14:39:27] {3288} INFO -  at 37.3s,\testimator rf's best error=0.1585,\tbest estimator lgbm's best error=0.1429\n",
            "[flaml.automl: 10-05 14:39:27] {3108} INFO - iteration 15, current learner lgbm\n",
            "[flaml.automl: 10-05 14:39:30] {3288} INFO -  at 40.2s,\testimator lgbm's best error=0.1413,\tbest estimator lgbm's best error=0.1413\n",
            "[flaml.automl: 10-05 14:39:30] {3108} INFO - iteration 16, current learner lgbm\n",
            "[flaml.automl: 10-05 14:39:33] {3288} INFO -  at 43.3s,\testimator lgbm's best error=0.1348,\tbest estimator lgbm's best error=0.1348\n",
            "[flaml.automl: 10-05 14:39:33] {3108} INFO - iteration 17, current learner lgbm\n",
            "[flaml.automl: 10-05 14:39:35] {3288} INFO -  at 45.6s,\testimator lgbm's best error=0.1348,\tbest estimator lgbm's best error=0.1348\n",
            "[flaml.automl: 10-05 14:39:35] {3108} INFO - iteration 18, current learner lgbm\n",
            "[flaml.automl: 10-05 14:39:38] {3288} INFO -  at 48.1s,\testimator lgbm's best error=0.1348,\tbest estimator lgbm's best error=0.1348\n",
            "[flaml.automl: 10-05 14:39:38] {3108} INFO - iteration 19, current learner lgbm\n",
            "[flaml.automl: 10-05 14:39:41] {3288} INFO -  at 51.2s,\testimator lgbm's best error=0.1348,\tbest estimator lgbm's best error=0.1348\n",
            "[flaml.automl: 10-05 14:39:41] {3108} INFO - iteration 20, current learner lgbm\n",
            "[flaml.automl: 10-05 14:39:44] {3288} INFO -  at 54.4s,\testimator lgbm's best error=0.1348,\tbest estimator lgbm's best error=0.1348\n",
            "[flaml.automl: 10-05 14:39:44] {3108} INFO - iteration 21, current learner lgbm\n",
            "[flaml.automl: 10-05 14:39:47] {3288} INFO -  at 57.1s,\testimator lgbm's best error=0.1348,\tbest estimator lgbm's best error=0.1348\n",
            "[flaml.automl: 10-05 14:39:47] {3108} INFO - iteration 22, current learner lgbm\n",
            "[flaml.automl: 10-05 14:39:49] {3288} INFO -  at 59.6s,\testimator lgbm's best error=0.1345,\tbest estimator lgbm's best error=0.1345\n",
            "[flaml.automl: 10-05 14:39:49] {3108} INFO - iteration 23, current learner lgbm\n",
            "[flaml.automl: 10-05 14:39:51] {3288} INFO -  at 62.0s,\testimator lgbm's best error=0.1305,\tbest estimator lgbm's best error=0.1305\n",
            "[flaml.automl: 10-05 14:39:51] {3108} INFO - iteration 24, current learner lgbm\n",
            "[flaml.automl: 10-05 14:39:55] {3288} INFO -  at 65.2s,\testimator lgbm's best error=0.1305,\tbest estimator lgbm's best error=0.1305\n",
            "[flaml.automl: 10-05 14:39:55] {3108} INFO - iteration 25, current learner rf\n",
            "[flaml.automl: 10-05 14:39:57] {3288} INFO -  at 67.4s,\testimator rf's best error=0.1585,\tbest estimator lgbm's best error=0.1305\n",
            "[flaml.automl: 10-05 14:39:57] {3108} INFO - iteration 26, current learner lgbm\n",
            "[flaml.automl: 10-05 14:40:03] {3288} INFO -  at 73.5s,\testimator lgbm's best error=0.1300,\tbest estimator lgbm's best error=0.1300\n",
            "[flaml.automl: 10-05 14:40:03] {3108} INFO - iteration 27, current learner lgbm\n",
            "[flaml.automl: 10-05 14:40:06] {3288} INFO -  at 76.3s,\testimator lgbm's best error=0.1300,\tbest estimator lgbm's best error=0.1300\n",
            "[flaml.automl: 10-05 14:40:06] {3108} INFO - iteration 28, current learner rf\n",
            "[flaml.automl: 10-05 14:40:08] {3288} INFO -  at 78.6s,\testimator rf's best error=0.1573,\tbest estimator lgbm's best error=0.1300\n",
            "[flaml.automl: 10-05 14:40:08] {3108} INFO - iteration 29, current learner lgbm\n",
            "[flaml.automl: 10-05 14:40:12] {3288} INFO -  at 82.3s,\testimator lgbm's best error=0.1296,\tbest estimator lgbm's best error=0.1296\n",
            "[flaml.automl: 10-05 14:40:12] {3108} INFO - iteration 30, current learner lgbm\n",
            "[flaml.automl: 10-05 14:40:18] {3288} INFO -  at 88.3s,\testimator lgbm's best error=0.1294,\tbest estimator lgbm's best error=0.1294\n",
            "[flaml.automl: 10-05 14:40:18] {3108} INFO - iteration 31, current learner lgbm\n",
            "[flaml.automl: 10-05 14:40:22] {3288} INFO -  at 92.6s,\testimator lgbm's best error=0.1294,\tbest estimator lgbm's best error=0.1294\n",
            "[flaml.automl: 10-05 14:40:22] {3108} INFO - iteration 32, current learner lgbm\n",
            "[flaml.automl: 10-05 14:40:30] {3288} INFO -  at 100.5s,\testimator lgbm's best error=0.1294,\tbest estimator lgbm's best error=0.1294\n",
            "[flaml.automl: 10-05 14:40:30] {3108} INFO - iteration 33, current learner lgbm\n",
            "[flaml.automl: 10-05 14:40:34] {3288} INFO -  at 104.7s,\testimator lgbm's best error=0.1294,\tbest estimator lgbm's best error=0.1294\n",
            "[flaml.automl: 10-05 14:40:34] {3108} INFO - iteration 34, current learner lgbm\n",
            "[flaml.automl: 10-05 14:40:42] {3288} INFO -  at 112.6s,\testimator lgbm's best error=0.1294,\tbest estimator lgbm's best error=0.1294\n",
            "[flaml.automl: 10-05 14:40:42] {3108} INFO - iteration 35, current learner lgbm\n",
            "[flaml.automl: 10-05 14:40:52] {3288} INFO -  at 122.9s,\testimator lgbm's best error=0.1294,\tbest estimator lgbm's best error=0.1294\n",
            "[flaml.automl: 10-05 14:40:52] {3108} INFO - iteration 36, current learner extra_tree\n",
            "[flaml.automl: 10-05 14:40:54] {3288} INFO -  at 124.5s,\testimator extra_tree's best error=0.1619,\tbest estimator lgbm's best error=0.1294\n",
            "[flaml.automl: 10-05 14:40:54] {3108} INFO - iteration 37, current learner lgbm\n",
            "[flaml.automl: 10-05 14:40:58] {3288} INFO -  at 128.5s,\testimator lgbm's best error=0.1294,\tbest estimator lgbm's best error=0.1294\n",
            "[flaml.automl: 10-05 14:40:58] {3108} INFO - iteration 38, current learner lgbm\n",
            "[flaml.automl: 10-05 14:41:10] {3288} INFO -  at 140.7s,\testimator lgbm's best error=0.1257,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-05 14:41:10] {3108} INFO - iteration 39, current learner catboost\n",
            "[flaml.automl: 10-05 14:41:30] {3288} INFO -  at 160.7s,\testimator catboost's best error=0.1386,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-05 14:41:30] {3108} INFO - iteration 40, current learner catboost\n",
            "[flaml.automl: 10-05 14:42:00] {3288} INFO -  at 190.2s,\testimator catboost's best error=0.1372,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-05 14:42:00] {3108} INFO - iteration 41, current learner rf\n",
            "[flaml.automl: 10-05 14:42:02] {3288} INFO -  at 192.2s,\testimator rf's best error=0.1515,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-05 14:42:02] {3108} INFO - iteration 42, current learner rf\n",
            "[flaml.automl: 10-05 14:42:04] {3288} INFO -  at 194.3s,\testimator rf's best error=0.1502,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-05 14:42:04] {3108} INFO - iteration 43, current learner lgbm\n",
            "[flaml.automl: 10-05 14:42:08] {3288} INFO -  at 198.9s,\testimator lgbm's best error=0.1257,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-05 14:42:08] {3108} INFO - iteration 44, current learner rf\n",
            "[flaml.automl: 10-05 14:42:11] {3288} INFO -  at 201.4s,\testimator rf's best error=0.1502,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-05 14:42:11] {3108} INFO - iteration 45, current learner extra_tree\n",
            "[flaml.automl: 10-05 14:42:13] {3288} INFO -  at 203.7s,\testimator extra_tree's best error=0.1619,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-05 14:42:13] {3108} INFO - iteration 46, current learner rf\n",
            "[flaml.automl: 10-05 14:42:14] {3288} INFO -  at 205.1s,\testimator rf's best error=0.1472,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-05 14:42:14] {3108} INFO - iteration 47, current learner lgbm\n",
            "[flaml.automl: 10-05 14:42:47] {3288} INFO -  at 237.1s,\testimator lgbm's best error=0.1257,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-05 14:42:47] {3108} INFO - iteration 48, current learner rf\n",
            "[flaml.automl: 10-05 14:42:49] {3288} INFO -  at 239.2s,\testimator rf's best error=0.1472,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-05 14:42:49] {3108} INFO - iteration 49, current learner lgbm\n",
            "[flaml.automl: 10-05 14:43:07] {3288} INFO -  at 257.8s,\testimator lgbm's best error=0.1257,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-05 14:43:07] {3108} INFO - iteration 50, current learner lgbm\n",
            "[flaml.automl: 10-05 14:43:18] {3288} INFO -  at 268.2s,\testimator lgbm's best error=0.1257,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-05 14:43:18] {3108} INFO - iteration 51, current learner catboost\n",
            "[flaml.automl: 10-05 14:43:39] {3288} INFO -  at 289.6s,\testimator catboost's best error=0.1356,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-05 14:43:39] {3108} INFO - iteration 52, current learner lgbm\n",
            "[flaml.automl: 10-05 14:43:49] {3288} INFO -  at 299.4s,\testimator lgbm's best error=0.1257,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-05 14:43:49] {3108} INFO - iteration 53, current learner lgbm\n",
            "[flaml.automl: 10-05 14:44:06] {3288} INFO -  at 317.0s,\testimator lgbm's best error=0.1257,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-05 14:44:06] {3108} INFO - iteration 54, current learner lgbm\n",
            "[flaml.automl: 10-05 14:44:17] {3288} INFO -  at 327.7s,\testimator lgbm's best error=0.1257,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-05 14:44:17] {3108} INFO - iteration 55, current learner lgbm\n",
            "[flaml.automl: 10-05 14:44:33] {3288} INFO -  at 343.5s,\testimator lgbm's best error=0.1257,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-05 14:44:33] {3108} INFO - iteration 56, current learner rf\n",
            "[flaml.automl: 10-05 14:44:36] {3288} INFO -  at 346.1s,\testimator rf's best error=0.1472,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-05 14:44:36] {3108} INFO - iteration 57, current learner lgbm\n",
            "[flaml.automl: 10-05 14:44:51] {3288} INFO -  at 361.9s,\testimator lgbm's best error=0.1257,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-05 14:44:51] {3108} INFO - iteration 58, current learner lgbm\n",
            "[flaml.automl: 10-05 14:45:01] {3288} INFO -  at 371.7s,\testimator lgbm's best error=0.1257,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-05 14:45:01] {3108} INFO - iteration 59, current learner rf\n",
            "[flaml.automl: 10-05 14:45:04] {3288} INFO -  at 374.2s,\testimator rf's best error=0.1469,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-05 14:45:04] {3108} INFO - iteration 60, current learner lgbm\n",
            "[flaml.automl: 10-05 14:45:20] {3288} INFO -  at 390.8s,\testimator lgbm's best error=0.1257,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-05 14:45:20] {3108} INFO - iteration 61, current learner catboost\n",
            "[flaml.automl: 10-05 14:45:44] {3288} INFO -  at 414.3s,\testimator catboost's best error=0.1356,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-05 14:45:44] {3108} INFO - iteration 62, current learner lgbm\n",
            "[flaml.automl: 10-05 14:45:55] {3288} INFO -  at 425.5s,\testimator lgbm's best error=0.1257,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-05 14:45:55] {3108} INFO - iteration 63, current learner xgb_limitdepth\n",
            "[flaml.automl: 10-05 14:45:58] {3288} INFO -  at 428.6s,\testimator xgb_limitdepth's best error=0.1359,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-05 14:45:58] {3108} INFO - iteration 64, current learner xgb_limitdepth\n",
            "[flaml.automl: 10-05 14:46:01] {3288} INFO -  at 431.3s,\testimator xgb_limitdepth's best error=0.1359,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-05 14:46:01] {3108} INFO - iteration 65, current learner xgb_limitdepth\n",
            "[flaml.automl: 10-05 14:46:04] {3288} INFO -  at 434.5s,\testimator xgb_limitdepth's best error=0.1359,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-05 14:46:04] {3108} INFO - iteration 66, current learner xgb_limitdepth\n",
            "[flaml.automl: 10-05 14:46:07] {3288} INFO -  at 437.6s,\testimator xgb_limitdepth's best error=0.1359,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-05 14:46:07] {3108} INFO - iteration 67, current learner xgb_limitdepth\n",
            "[flaml.automl: 10-05 14:46:10] {3288} INFO -  at 441.0s,\testimator xgb_limitdepth's best error=0.1359,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-05 14:46:10] {3108} INFO - iteration 68, current learner xgb_limitdepth\n",
            "[flaml.automl: 10-05 14:46:13] {3288} INFO -  at 443.9s,\testimator xgb_limitdepth's best error=0.1359,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-05 14:46:13] {3108} INFO - iteration 69, current learner xgb_limitdepth\n",
            "[flaml.automl: 10-05 14:46:16] {3288} INFO -  at 446.9s,\testimator xgb_limitdepth's best error=0.1359,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-05 14:46:16] {3108} INFO - iteration 70, current learner lgbm\n",
            "[flaml.automl: 10-05 14:46:41] {3288} INFO -  at 471.1s,\testimator lgbm's best error=0.1257,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-05 14:46:41] {3108} INFO - iteration 71, current learner xgb_limitdepth\n",
            "[flaml.automl: 10-05 14:46:43] {3288} INFO -  at 474.0s,\testimator xgb_limitdepth's best error=0.1359,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-05 14:46:43] {3108} INFO - iteration 72, current learner xgb_limitdepth\n",
            "[flaml.automl: 10-05 14:46:46] {3288} INFO -  at 477.1s,\testimator xgb_limitdepth's best error=0.1359,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-05 14:46:46] {3108} INFO - iteration 73, current learner xgb_limitdepth\n",
            "[flaml.automl: 10-05 14:46:50] {3288} INFO -  at 480.3s,\testimator xgb_limitdepth's best error=0.1331,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-05 14:46:50] {3108} INFO - iteration 74, current learner xgb_limitdepth\n",
            "[flaml.automl: 10-05 14:46:53] {3288} INFO -  at 483.6s,\testimator xgb_limitdepth's best error=0.1331,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-05 14:46:53] {3108} INFO - iteration 75, current learner extra_tree\n",
            "[flaml.automl: 10-05 14:46:56] {3288} INFO -  at 486.1s,\testimator extra_tree's best error=0.1600,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-05 14:46:56] {3108} INFO - iteration 76, current learner xgb_limitdepth\n",
            "[flaml.automl: 10-05 14:46:58] {3288} INFO -  at 488.8s,\testimator xgb_limitdepth's best error=0.1331,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-05 14:46:58] {3108} INFO - iteration 77, current learner lgbm\n",
            "[flaml.automl: 10-05 14:47:05] {3288} INFO -  at 495.3s,\testimator lgbm's best error=0.1257,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-05 14:47:05] {3108} INFO - iteration 78, current learner lgbm\n",
            "[flaml.automl: 10-05 14:47:26] {3288} INFO -  at 516.5s,\testimator lgbm's best error=0.1257,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-05 14:47:26] {3108} INFO - iteration 79, current learner xgb_limitdepth\n",
            "[flaml.automl: 10-05 14:47:28] {3288} INFO -  at 519.1s,\testimator xgb_limitdepth's best error=0.1331,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-05 14:47:28] {3108} INFO - iteration 80, current learner xgboost\n",
            "[flaml.automl: 10-05 14:47:30] {3288} INFO -  at 520.6s,\testimator xgboost's best error=0.1488,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-05 14:47:30] {3108} INFO - iteration 81, current learner lgbm\n",
            "[flaml.automl: 10-05 14:47:35] {3288} INFO -  at 525.6s,\testimator lgbm's best error=0.1257,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-05 14:47:35] {3108} INFO - iteration 82, current learner xgb_limitdepth\n",
            "[flaml.automl: 10-05 14:47:39] {3288} INFO -  at 530.1s,\testimator xgb_limitdepth's best error=0.1331,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-05 14:47:39] {3108} INFO - iteration 83, current learner catboost\n",
            "[flaml.automl: 10-05 14:48:13] {3288} INFO -  at 564.0s,\testimator catboost's best error=0.1343,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-05 14:48:13] {3108} INFO - iteration 84, current learner xgb_limitdepth\n",
            "[flaml.automl: 10-05 14:48:16] {3288} INFO -  at 566.7s,\testimator xgb_limitdepth's best error=0.1331,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-05 14:48:16] {3108} INFO - iteration 85, current learner xgb_limitdepth\n",
            "[flaml.automl: 10-05 14:48:19] {3288} INFO -  at 569.7s,\testimator xgb_limitdepth's best error=0.1331,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-05 14:48:19] {3108} INFO - iteration 86, current learner xgb_limitdepth\n",
            "[flaml.automl: 10-05 14:48:22] {3288} INFO -  at 572.9s,\testimator xgb_limitdepth's best error=0.1331,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-05 14:48:22] {3108} INFO - iteration 87, current learner extra_tree\n",
            "[flaml.automl: 10-05 14:48:24] {3288} INFO -  at 574.8s,\testimator extra_tree's best error=0.1571,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-05 14:48:24] {3108} INFO - iteration 88, current learner extra_tree\n",
            "[flaml.automl: 10-05 14:48:27] {3288} INFO -  at 577.3s,\testimator extra_tree's best error=0.1555,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-05 14:48:27] {3108} INFO - iteration 89, current learner extra_tree\n",
            "[flaml.automl: 10-05 14:48:29] {3288} INFO -  at 579.3s,\testimator extra_tree's best error=0.1553,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-05 14:48:29] {3108} INFO - iteration 90, current learner lgbm\n",
            "[flaml.automl: 10-05 14:48:34] {3288} INFO -  at 584.8s,\testimator lgbm's best error=0.1257,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-05 14:48:34] {3108} INFO - iteration 91, current learner xgb_limitdepth\n",
            "[flaml.automl: 10-05 14:48:37] {3288} INFO -  at 588.0s,\testimator xgb_limitdepth's best error=0.1331,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-05 14:48:37] {3108} INFO - iteration 92, current learner extra_tree\n",
            "[flaml.automl: 10-05 14:48:39] {3288} INFO -  at 589.8s,\testimator extra_tree's best error=0.1553,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-05 14:48:39] {3108} INFO - iteration 93, current learner xgb_limitdepth\n",
            "[flaml.automl: 10-05 14:48:43] {3288} INFO -  at 593.2s,\testimator xgb_limitdepth's best error=0.1331,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-05 14:48:43] {3108} INFO - iteration 94, current learner xgb_limitdepth\n",
            "[flaml.automl: 10-05 14:48:47] {3288} INFO -  at 598.0s,\testimator xgb_limitdepth's best error=0.1331,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-05 14:48:47] {3108} INFO - iteration 95, current learner lrl1\n",
            "C:\\Users\\17247\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "[flaml.automl: 10-05 14:48:50] {3288} INFO -  at 600.6s,\testimator lrl1's best error=0.1376,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-05 14:48:53] {3552} INFO - retrain lgbm for 3.1s\n",
            "[flaml.automl: 10-05 14:48:53] {3559} INFO - retrained model: LGBMClassifier(colsample_bytree=0.7945324135347446,\n",
            "               learning_rate=0.07349456601711642, max_bin=511,\n",
            "               min_child_samples=81, n_estimators=383, num_leaves=148,\n",
            "               reg_alpha=0.0038090040724731134,\n",
            "               reg_lambda=0.0027820040646453358, verbose=-1)\n",
            "[flaml.automl: 10-05 14:48:53] {2837} INFO - fit succeeded\n",
            "[flaml.automl: 10-05 14:48:53] {2838} INFO - Time taken to find the best model: 140.72128438949585\n"
          ]
        }
      ],
      "source": [
        "automl.fit(X_train = X_train, y_train = y_train, **settings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab22c146",
      "metadata": {
        "id": "ab22c146",
        "outputId": "e36b6392-d65e-4a48-c369-c55c8a965519"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best ML leaner: lgbm\n",
            "Best hyperparmeter config: {'n_estimators': 383, 'num_leaves': 148, 'min_child_samples': 81, 'learning_rate': 0.07349456601711642, 'log_max_bin': 9, 'colsample_bytree': 0.7945324135347446, 'reg_alpha': 0.0038090040724731134, 'reg_lambda': 0.0027820040646453358}\n",
            "Best accuracy on validation data: 0.8743\n",
            "Training duration of best run: 3.055 s\n"
          ]
        }
      ],
      "source": [
        "print('Best ML leaner:', automl.best_estimator)\n",
        "print('Best hyperparmeter config:', automl.best_config)\n",
        "print('Best accuracy on validation data: {0:.4g}'.format(1-automl.best_loss))\n",
        "print('Training duration of best run: {0:.4g} s'.format(automl.best_config_train_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4381fb01",
      "metadata": {
        "id": "4381fb01",
        "outputId": "a9855476-e7b6-45fc-931d-10c416931494"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LGBMClassifier(colsample_bytree=0.7945324135347446,\n",
              "               learning_rate=0.07349456601711642, max_bin=511,\n",
              "               min_child_samples=81, n_estimators=383, num_leaves=148,\n",
              "               reg_alpha=0.0038090040724731134,\n",
              "               reg_lambda=0.0027820040646453358, verbose=-1)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "automl.model.estimator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f3ec619",
      "metadata": {
        "id": "5f3ec619",
        "outputId": "daaaa212-ce15-41e1-eb05-eb7ba21d89fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted labels ['0' '0' '0' ... '0' '0' '0']\n",
            "True labels 2265    0\n",
            "2851    0\n",
            "3655    0\n",
            "196     0\n",
            "3719    0\n",
            "       ..\n",
            "3791    0\n",
            "7913    0\n",
            "1790    0\n",
            "5318    0\n",
            "7318    0\n",
            "Name: match, Length: 2095, dtype: category\n",
            "Categories (2, object): ['0' < '1']\n"
          ]
        }
      ],
      "source": [
        "y_pred = automl.predict(X_test)\n",
        "print('Predicted labels', y_pred)\n",
        "print('True labels', y_test)\n",
        "y_pred_proba = automl.predict_proba(X_test)[:,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68441310",
      "metadata": {
        "id": "68441310",
        "outputId": "38a406c6-50cd-4b65-bdbb-d3e651afa4ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy = 0.8706443914081146\n",
            "roc_auc = 0.8808645533141212\n",
            "log_loss = 0.399702410433201\n"
          ]
        }
      ],
      "source": [
        "from flaml.ml import sklearn_metric_loss_score\n",
        "print('accuracy', '=', 1 - sklearn_metric_loss_score('accuracy', y_pred, y_test))\n",
        "print('roc_auc', '=', 1 - sklearn_metric_loss_score('roc_auc', y_pred_proba, y_test))\n",
        "print('log_loss', '=', sklearn_metric_loss_score('log_loss', y_pred_proba, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39eef0ed",
      "metadata": {
        "id": "39eef0ed",
        "outputId": "17873405-123a-4d64-c560-370059634c07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Current Learner': 'lgbm', 'Current Sample': 6283, 'Current Hyper-parameters': {'n_estimators': 4, 'num_leaves': 4, 'min_child_samples': 20, 'learning_rate': 0.09999999999999995, 'log_max_bin': 8, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.0}, 'Best Learner': 'lgbm', 'Best Hyper-parameters': {'n_estimators': 4, 'num_leaves': 4, 'min_child_samples': 20, 'learning_rate': 0.09999999999999995, 'log_max_bin': 8, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.0}}\n",
            "{'Current Learner': 'lgbm', 'Current Sample': 6283, 'Current Hyper-parameters': {'n_estimators': 5, 'num_leaves': 4, 'min_child_samples': 35, 'learning_rate': 0.217390709783794, 'log_max_bin': 8, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.10260733108888935}, 'Best Learner': 'lgbm', 'Best Hyper-parameters': {'n_estimators': 5, 'num_leaves': 4, 'min_child_samples': 35, 'learning_rate': 0.217390709783794, 'log_max_bin': 8, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.10260733108888935}}\n",
            "{'Current Learner': 'lgbm', 'Current Sample': 6283, 'Current Hyper-parameters': {'n_estimators': 6, 'num_leaves': 4, 'min_child_samples': 47, 'learning_rate': 0.22896368654364246, 'log_max_bin': 8, 'colsample_bytree': 1.0, 'reg_alpha': 0.0011293633547972382, 'reg_lambda': 0.009223752143831209}, 'Best Learner': 'lgbm', 'Best Hyper-parameters': {'n_estimators': 6, 'num_leaves': 4, 'min_child_samples': 47, 'learning_rate': 0.22896368654364246, 'log_max_bin': 8, 'colsample_bytree': 1.0, 'reg_alpha': 0.0011293633547972382, 'reg_lambda': 0.009223752143831209}}\n",
            "{'Current Learner': 'lgbm', 'Current Sample': 6283, 'Current Hyper-parameters': {'n_estimators': 9, 'num_leaves': 4, 'min_child_samples': 34, 'learning_rate': 0.19075302418396065, 'log_max_bin': 9, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.11001674455590196}, 'Best Learner': 'lgbm', 'Best Hyper-parameters': {'n_estimators': 9, 'num_leaves': 4, 'min_child_samples': 34, 'learning_rate': 0.19075302418396065, 'log_max_bin': 9, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.11001674455590196}}\n",
            "{'Current Learner': 'lgbm', 'Current Sample': 6283, 'Current Hyper-parameters': {'n_estimators': 6, 'num_leaves': 10, 'min_child_samples': 46, 'learning_rate': 0.22896368654364246, 'log_max_bin': 8, 'colsample_bytree': 0.9151672901279894, 'reg_alpha': 0.0028201126607683698, 'reg_lambda': 0.009223752143831213}, 'Best Learner': 'lgbm', 'Best Hyper-parameters': {'n_estimators': 6, 'num_leaves': 10, 'min_child_samples': 46, 'learning_rate': 0.22896368654364246, 'log_max_bin': 8, 'colsample_bytree': 0.9151672901279894, 'reg_alpha': 0.0028201126607683698, 'reg_lambda': 0.009223752143831213}}\n",
            "{'Current Learner': 'lgbm', 'Current Sample': 6283, 'Current Hyper-parameters': {'n_estimators': 11, 'num_leaves': 53, 'min_child_samples': 33, 'learning_rate': 0.10638311711134216, 'log_max_bin': 8, 'colsample_bytree': 0.9504814804454289, 'reg_alpha': 0.0023411461336091946, 'reg_lambda': 0.01232910415374743}, 'Best Learner': 'lgbm', 'Best Hyper-parameters': {'n_estimators': 11, 'num_leaves': 53, 'min_child_samples': 33, 'learning_rate': 0.10638311711134216, 'log_max_bin': 8, 'colsample_bytree': 0.9504814804454289, 'reg_alpha': 0.0023411461336091946, 'reg_lambda': 0.01232910415374743}}\n",
            "{'Current Learner': 'lgbm', 'Current Sample': 6283, 'Current Hyper-parameters': {'n_estimators': 33, 'num_leaves': 28, 'min_child_samples': 49, 'learning_rate': 0.07219223346014582, 'log_max_bin': 9, 'colsample_bytree': 0.8632054869229117, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.004662880494997406}, 'Best Learner': 'lgbm', 'Best Hyper-parameters': {'n_estimators': 33, 'num_leaves': 28, 'min_child_samples': 49, 'learning_rate': 0.07219223346014582, 'log_max_bin': 9, 'colsample_bytree': 0.8632054869229117, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.004662880494997406}}\n",
            "{'Current Learner': 'lgbm', 'Current Sample': 6283, 'Current Hyper-parameters': {'n_estimators': 49, 'num_leaves': 24, 'min_child_samples': 126, 'learning_rate': 0.05129608013305185, 'log_max_bin': 9, 'colsample_bytree': 0.7479283884351631, 'reg_alpha': 0.0018291617742641451, 'reg_lambda': 0.001420292799258414}, 'Best Learner': 'lgbm', 'Best Hyper-parameters': {'n_estimators': 49, 'num_leaves': 24, 'min_child_samples': 126, 'learning_rate': 0.05129608013305185, 'log_max_bin': 9, 'colsample_bytree': 0.7479283884351631, 'reg_alpha': 0.0018291617742641451, 'reg_lambda': 0.001420292799258414}}\n",
            "{'Current Learner': 'lgbm', 'Current Sample': 6283, 'Current Hyper-parameters': {'n_estimators': 52, 'num_leaves': 11, 'min_child_samples': 93, 'learning_rate': 0.13906138125808948, 'log_max_bin': 8, 'colsample_bytree': 0.9022102592823722, 'reg_alpha': 0.00405473040064328, 'reg_lambda': 0.0019142031668109981}, 'Best Learner': 'lgbm', 'Best Hyper-parameters': {'n_estimators': 52, 'num_leaves': 11, 'min_child_samples': 93, 'learning_rate': 0.13906138125808948, 'log_max_bin': 8, 'colsample_bytree': 0.9022102592823722, 'reg_alpha': 0.00405473040064328, 'reg_lambda': 0.0019142031668109981}}\n",
            "{'Current Learner': 'lgbm', 'Current Sample': 6283, 'Current Hyper-parameters': {'n_estimators': 210, 'num_leaves': 27, 'min_child_samples': 101, 'learning_rate': 0.05869313565418056, 'log_max_bin': 9, 'colsample_bytree': 0.9284938408452321, 'reg_alpha': 0.006035818587147279, 'reg_lambda': 0.0009765625}, 'Best Learner': 'lgbm', 'Best Hyper-parameters': {'n_estimators': 210, 'num_leaves': 27, 'min_child_samples': 101, 'learning_rate': 0.05869313565418056, 'log_max_bin': 9, 'colsample_bytree': 0.9284938408452321, 'reg_alpha': 0.006035818587147279, 'reg_lambda': 0.0009765625}}\n",
            "{'Current Learner': 'lgbm', 'Current Sample': 6283, 'Current Hyper-parameters': {'n_estimators': 70, 'num_leaves': 32, 'min_child_samples': 119, 'learning_rate': 0.1305053207928878, 'log_max_bin': 8, 'colsample_bytree': 1.0, 'reg_alpha': 0.006654851923923542, 'reg_lambda': 0.002124411209590999}, 'Best Learner': 'lgbm', 'Best Hyper-parameters': {'n_estimators': 70, 'num_leaves': 32, 'min_child_samples': 119, 'learning_rate': 0.1305053207928878, 'log_max_bin': 8, 'colsample_bytree': 1.0, 'reg_alpha': 0.006654851923923542, 'reg_lambda': 0.002124411209590999}}\n",
            "{'Current Learner': 'lgbm', 'Current Sample': 6283, 'Current Hyper-parameters': {'n_estimators': 211, 'num_leaves': 27, 'min_child_samples': 101, 'learning_rate': 0.05869313565418051, 'log_max_bin': 8, 'colsample_bytree': 0.8104443262964631, 'reg_alpha': 0.006035818587147279, 'reg_lambda': 0.0009765625}, 'Best Learner': 'lgbm', 'Best Hyper-parameters': {'n_estimators': 211, 'num_leaves': 27, 'min_child_samples': 101, 'learning_rate': 0.05869313565418051, 'log_max_bin': 8, 'colsample_bytree': 0.8104443262964631, 'reg_alpha': 0.006035818587147279, 'reg_lambda': 0.0009765625}}\n",
            "{'Current Learner': 'lgbm', 'Current Sample': 6283, 'Current Hyper-parameters': {'n_estimators': 383, 'num_leaves': 148, 'min_child_samples': 81, 'learning_rate': 0.07349456601711642, 'log_max_bin': 9, 'colsample_bytree': 0.7945324135347446, 'reg_alpha': 0.0038090040724731134, 'reg_lambda': 0.0027820040646453358}, 'Best Learner': 'lgbm', 'Best Hyper-parameters': {'n_estimators': 383, 'num_leaves': 148, 'min_child_samples': 81, 'learning_rate': 0.07349456601711642, 'log_max_bin': 9, 'colsample_bytree': 0.7945324135347446, 'reg_alpha': 0.0038090040724731134, 'reg_lambda': 0.0027820040646453358}}\n"
          ]
        }
      ],
      "source": [
        "from flaml.data import get_output_from_log\n",
        "time_history, best_valid_loss_history, valid_loss_history, config_history, metric_history = \\\n",
        "    get_output_from_log(filename=settings['log_file_name'], time_budget=240)\n",
        "for config in config_history:\n",
        "    print(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3570ab7c",
      "metadata": {
        "id": "3570ab7c",
        "outputId": "7fec02da-033d-4f75-c715-6601a8523458"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "plt.title('Learning Curve')\n",
        "plt.xlabel('Wall Clock Time (s)')\n",
        "plt.ylabel('Validation Accuracy')\n",
        "plt.scatter(time_history, 1 - np.array(valid_loss_history))\n",
        "plt.step(time_history, 1 - np.array(best_valid_loss_history), where='post')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c2b6e33",
      "metadata": {
        "id": "1c2b6e33"
      },
      "outputs": [],
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "lgbm = LGBMClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe602ea9",
      "metadata": {
        "id": "fe602ea9",
        "outputId": "204f14ee-856d-4d8a-86e7-196a636b251b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LGBMClassifier()"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lgbm.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "330ce537",
      "metadata": {
        "id": "330ce537"
      },
      "outputs": [],
      "source": [
        "y_pred_lgbm = lgbm.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4e84429",
      "metadata": {
        "id": "d4e84429"
      },
      "outputs": [],
      "source": [
        "from xgboost import XGBClassifier\n",
        "xgb = XGBClassifier()\n",
        "cat_columns = X_train.select_dtypes(include=['category']).columns\n",
        "X = X_train.copy()\n",
        "X[cat_columns] = X[cat_columns].apply(lambda x: x.cat.codes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4cdc1bce",
      "metadata": {
        "id": "4cdc1bce"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder = label_encoder.fit(y_train)\n",
        "y_train = label_encoder.transform(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80f59e28",
      "metadata": {
        "id": "80f59e28",
        "outputId": "7d86fe31-00c9-4604-a599-dfe9b1c0d161"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
              "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
              "              early_stopping_rounds=None, enable_categorical=False,\n",
              "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
              "              importance_type=None, interaction_constraints='',\n",
              "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
              "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
              "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
              "              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=0,\n",
              "              reg_alpha=0, reg_lambda=1, ...)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "xgb.fit(X, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c43e152a",
      "metadata": {
        "id": "c43e152a"
      },
      "outputs": [],
      "source": [
        "X = X_test.copy()\n",
        "X[cat_columns] = X[cat_columns].apply(lambda x: x.cat.codes)\n",
        "y_pred_xgb = xgb.predict(X)\n",
        "#label_encoded_y_test = label_encoder.transform(y_pred_xgb)\n",
        "#y_pred_xgb = label_encoder.transform(y_pred_xgb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8914ab7",
      "metadata": {
        "id": "b8914ab7"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('automl.pkl', 'wb') as f:\n",
        "    pickle.dump(automl, f, pickle.HIGHEST_PROTOCOL)\n",
        "'''load pickled automl object'''\n",
        "with open('automl.pkl', 'rb') as f:\n",
        "    automl = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dac4d447",
      "metadata": {
        "id": "dac4d447"
      },
      "outputs": [],
      "source": [
        "y_test = [int(x) for x in np.array(y_test)]\n",
        "# print(np.array(y_pred_xgb))\n",
        "# print(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9f5cd39",
      "metadata": {
        "id": "b9f5cd39",
        "outputId": "fc5fcfd9-9833-4f22-a5f7-e5a834b44639"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "default xgboost accuracy = 0.8692124105011934\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "Labels in y_true and y_pred should be of the same type. Got y_true=[0 1] and y_pred=['0' '1']. Make sure that the predictions provided by the classifier coincides with the true labels.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m    106\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m                 \u001b[0munique_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munion1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36munion1d\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py\u001b[0m in \u001b[0;36munion1d\u001b[1;34m(ar1, ar2)\u001b[0m\n\u001b[0;32m    751\u001b[0m     \"\"\"\n\u001b[1;32m--> 752\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mar1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mar2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    753\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36munique\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py\u001b[0m in \u001b[0;36munique\u001b[1;34m(ar, return_index, return_inverse, return_counts, axis)\u001b[0m\n\u001b[0;32m    261\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_unique1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    263\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_unpack_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py\u001b[0m in \u001b[0;36m_unique1d\u001b[1;34m(ar, return_index, return_inverse, return_counts)\u001b[0m\n\u001b[0;32m    322\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 323\u001b[1;33m         \u001b[0mar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    324\u001b[0m         \u001b[0maux\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'str' and 'int'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-45-6eb4a2237ef5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'default xgboost accuracy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'='\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0msklearn_metric_loss_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred_xgb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'default lgbm accuracy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'='\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0msklearn_metric_loss_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred_lgbm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'flaml (10 min) accuracy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'='\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0msklearn_metric_loss_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\flaml\\ml.py\u001b[0m in \u001b[0;36msklearn_metric_loss_score\u001b[1;34m(metric_name, y_predict, y_true, labels, sample_weight, groups)\u001b[0m\n\u001b[0;32m    266\u001b[0m         \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_predict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmetric_name\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"accuracy\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 268\u001b[1;33m         \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_predict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    269\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmetric_name\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"roc_auc\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m         \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_predict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m     \u001b[1;31m# Compute accuracy for each possible representation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 202\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    203\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'multilabel'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m    111\u001b[0m                 \u001b[1;31m# `y_pred` given by the classifier will also be encoded with\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m                 \u001b[1;31m# strings. So we raise a meaningful error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m                 raise TypeError(\n\u001b[0m\u001b[0;32m    114\u001b[0m                     \u001b[1;34mf\"Labels in y_true and y_pred should be of the same type. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m                     \u001b[1;34mf\"Got y_true={np.unique(y_true)} and \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mTypeError\u001b[0m: Labels in y_true and y_pred should be of the same type. Got y_true=[0 1] and y_pred=['0' '1']. Make sure that the predictions provided by the classifier coincides with the true labels."
          ]
        }
      ],
      "source": [
        "print('default xgboost accuracy', '=', 1 - sklearn_metric_loss_score('accuracy', np.array(y_pred_xgb), np.array(y_test)))\n",
        "print('default lgbm accuracy', '=', 1 - sklearn_metric_loss_score('accuracy', y_pred_lgbm, y_test))\n",
        "print('flaml (10 min) accuracy', '=', 1 - sklearn_metric_loss_score('accuracy', y_pred, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8c6c9c8",
      "metadata": {
        "id": "b8c6c9c8",
        "outputId": "2fce195f-ce68-4840-c2aa-7058e4f0da2d"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'train_test_split' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-25-a31e2c32769f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mauc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mXbin_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXbin_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mybin_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mybin_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mybin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpoly_clf2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXbin_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mybin_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mybin_test_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpoly_clf2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXbin_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'train_test_split' is not defined"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "Xbin_train, Xbin_test, ybin_train, ybin_test = train_test_split(X, ybin, test_size=0.3)\n",
        "\n",
        "poly_clf2.fit(Xbin_train, ybin_train)\n",
        "ybin_test_pred = poly_clf2.decision_function(Xbin_test)\n",
        "fpr1, tpr1, te_thresholds1 = roc_curve(ybin_test, ybin_test_pred)\n",
        "\n",
        "xgb_clf2.fit(Xbin_train, ybin_train)\n",
        "ybin_test_pred2 = xgb_clf2.predict_proba(Xbin_test)[:,1]\n",
        "fpr2, tpr2, te_thresholds2 = roc_curve(ybin_test, ybin_test_pred2)\n",
        "\n",
        "log_reg1.fit(Xbin_train, ybin_train)\n",
        "ybin_test_pred3 = log_reg1.predict_proba(Xbin_test)[:,1]\n",
        "fpr3, tpr3, te_thresholds3 = roc_curve(ybin_test, ybin_test_pred3)\n",
        "\n",
        "plt.figure(figsize=(10,7))\n",
        "plt.grid()\n",
        "plt.plot(fpr1, tpr1, label='Poly_SVM')\n",
        "plt.plot(fpr2, tpr2, label='XGBoost_clf')\n",
        "plt.plot(fpr3, tpr3, label='Logistic_reg')\n",
        "plt.legend(loc='lower right')\n",
        "plt.plot([0,1],[0,1], 'k--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6dd0305",
      "metadata": {
        "id": "b6dd0305"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from flaml import AutoML\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_boston\n",
        "from sklearn.metrics import max_error, mean_absolute_error, mean_squared_log_error, mean_squared_error, r2_score\n",
        "# Classification with FLAML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "461fb901",
      "metadata": {
        "id": "461fb901",
        "outputId": "dd3de70c-2a2c-4ad5-8a05-97eb4bb7277b"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'dataset' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-27-8ca0b188f21e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mautoml_clf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAutoML\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mautoml_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"classification\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'dataset' is not defined"
          ]
        }
      ],
      "source": [
        "x = dataset.data\n",
        "y = dataset.target\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=100)\n",
        "automl_clf = AutoML()\n",
        "automl_clf.fit(x_train, y_train, task=\"classification\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80b319eb",
      "metadata": {
        "id": "80b319eb"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}