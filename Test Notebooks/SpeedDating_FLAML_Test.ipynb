{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58fbf15f",
      "metadata": {
        "id": "58fbf15f",
        "outputId": "9b237266-e2a4-4690-b0ee-f77a5567f0d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: flaml[notebook]==1.0.10 in c:\\users\\17247\\anaconda3\\lib\\site-packages (1.0.10)\n",
            "Requirement already satisfied: scikit-learn>=0.24 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from flaml[notebook]==1.0.10) (0.24.1)\n",
            "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from flaml[notebook]==1.0.10) (1.6.2)\n",
            "Requirement already satisfied: xgboost>=0.90 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from flaml[notebook]==1.0.10) (1.6.2)\n",
            "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from flaml[notebook]==1.0.10) (1.2.4)\n",
            "Requirement already satisfied: lightgbm>=2.3.1 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from flaml[notebook]==1.0.10) (3.3.2)\n",
            "Requirement already satisfied: NumPy>=1.17.0rc1 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from flaml[notebook]==1.0.10) (1.20.1)\n",
            "Requirement already satisfied: rgf-python in c:\\users\\17247\\anaconda3\\lib\\site-packages (from flaml[notebook]==1.0.10) (3.12.0)\n",
            "Requirement already satisfied: catboost>=0.26 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from flaml[notebook]==1.0.10) (1.1)\n",
            "Requirement already satisfied: matplotlib in c:\\users\\17247\\anaconda3\\lib\\site-packages (from flaml[notebook]==1.0.10) (3.3.4)\n",
            "Requirement already satisfied: openml==0.10.2 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from flaml[notebook]==1.0.10) (0.10.2)\n",
            "Requirement already satisfied: jupyter in c:\\users\\17247\\anaconda3\\lib\\site-packages (from flaml[notebook]==1.0.10) (1.0.0)\n",
            "Requirement already satisfied: requests in c:\\users\\17247\\anaconda3\\lib\\site-packages (from openml==0.10.2->flaml[notebook]==1.0.10) (2.25.1)\n",
            "Requirement already satisfied: python-dateutil in c:\\users\\17247\\anaconda3\\lib\\site-packages (from openml==0.10.2->flaml[notebook]==1.0.10) (2.8.1)\n",
            "Requirement already satisfied: liac-arff>=2.4.0 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from openml==0.10.2->flaml[notebook]==1.0.10) (2.5.0)\n",
            "Requirement already satisfied: xmltodict in c:\\users\\17247\\anaconda3\\lib\\site-packages (from openml==0.10.2->flaml[notebook]==1.0.10) (0.12.0)\n",
            "Requirement already satisfied: plotly in c:\\users\\17247\\anaconda3\\lib\\site-packages (from catboost>=0.26->flaml[notebook]==1.0.10) (5.10.0)\n",
            "Requirement already satisfied: graphviz in c:\\users\\17247\\anaconda3\\lib\\site-packages (from catboost>=0.26->flaml[notebook]==1.0.10) (0.20.1)\n",
            "Requirement already satisfied: six in c:\\users\\17247\\anaconda3\\lib\\site-packages (from catboost>=0.26->flaml[notebook]==1.0.10) (1.15.0)\n",
            "Requirement already satisfied: wheel in c:\\users\\17247\\anaconda3\\lib\\site-packages (from lightgbm>=2.3.1->flaml[notebook]==1.0.10) (0.36.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->flaml[notebook]==1.0.10) (2021.1)\n",
            "Requirement already satisfied: joblib>=0.11 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from scikit-learn>=0.24->flaml[notebook]==1.0.10) (1.0.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from scikit-learn>=0.24->flaml[notebook]==1.0.10) (2.1.0)\n",
            "Requirement already satisfied: qtconsole in c:\\users\\17247\\anaconda3\\lib\\site-packages (from jupyter->flaml[notebook]==1.0.10) (5.0.3)\n",
            "Requirement already satisfied: jupyter-console in c:\\users\\17247\\anaconda3\\lib\\site-packages (from jupyter->flaml[notebook]==1.0.10) (6.4.0)\n",
            "Requirement already satisfied: nbconvert in c:\\users\\17247\\anaconda3\\lib\\site-packages (from jupyter->flaml[notebook]==1.0.10) (6.0.7)\n",
            "Requirement already satisfied: notebook in c:\\users\\17247\\anaconda3\\lib\\site-packages (from jupyter->flaml[notebook]==1.0.10) (6.3.0)\n",
            "Requirement already satisfied: ipywidgets in c:\\users\\17247\\anaconda3\\lib\\site-packages (from jupyter->flaml[notebook]==1.0.10) (7.6.3)\n",
            "Requirement already satisfied: ipykernel in c:\\users\\17247\\anaconda3\\lib\\site-packages (from jupyter->flaml[notebook]==1.0.10) (5.3.4)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from matplotlib->flaml[notebook]==1.0.10) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from matplotlib->flaml[notebook]==1.0.10) (1.3.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from matplotlib->flaml[notebook]==1.0.10) (8.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from matplotlib->flaml[notebook]==1.0.10) (2.4.7)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from ipykernel->jupyter->flaml[notebook]==1.0.10) (5.0.5)\n",
            "Requirement already satisfied: jupyter-client in c:\\users\\17247\\anaconda3\\lib\\site-packages (from ipykernel->jupyter->flaml[notebook]==1.0.10) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from ipykernel->jupyter->flaml[notebook]==1.0.10) (6.1)\n",
            "Requirement already satisfied: ipython>=5.0.0 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from ipykernel->jupyter->flaml[notebook]==1.0.10) (7.22.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from ipywidgets->jupyter->flaml[notebook]==1.0.10) (1.0.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from ipywidgets->jupyter->flaml[notebook]==1.0.10) (3.5.1)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from ipywidgets->jupyter->flaml[notebook]==1.0.10) (5.1.3)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from jupyter-console->jupyter->flaml[notebook]==1.0.10) (3.0.17)\n",
            "Requirement already satisfied: pygments in c:\\users\\17247\\anaconda3\\lib\\site-packages (from jupyter-console->jupyter->flaml[notebook]==1.0.10) (2.8.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from nbconvert->jupyter->flaml[notebook]==1.0.10) (0.8.4)\n",
            "Requirement already satisfied: jupyterlab-pygments in c:\\users\\17247\\anaconda3\\lib\\site-packages (from nbconvert->jupyter->flaml[notebook]==1.0.10) (0.1.2)\n",
            "Requirement already satisfied: testpath in c:\\users\\17247\\anaconda3\\lib\\site-packages (from nbconvert->jupyter->flaml[notebook]==1.0.10) (0.4.4)\n",
            "Requirement already satisfied: jinja2>=2.4 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from nbconvert->jupyter->flaml[notebook]==1.0.10) (2.11.3)\n",
            "Requirement already satisfied: bleach in c:\\users\\17247\\anaconda3\\lib\\site-packages (from nbconvert->jupyter->flaml[notebook]==1.0.10) (3.3.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from nbconvert->jupyter->flaml[notebook]==1.0.10) (1.4.3)\n",
            "Requirement already satisfied: jupyter-core in c:\\users\\17247\\anaconda3\\lib\\site-packages (from nbconvert->jupyter->flaml[notebook]==1.0.10) (4.7.1)\n",
            "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from nbconvert->jupyter->flaml[notebook]==1.0.10) (0.5.3)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from nbconvert->jupyter->flaml[notebook]==1.0.10) (0.3)\n",
            "Requirement already satisfied: defusedxml in c:\\users\\17247\\anaconda3\\lib\\site-packages (from nbconvert->jupyter->flaml[notebook]==1.0.10) (0.7.1)\n",
            "Requirement already satisfied: argon2-cffi in c:\\users\\17247\\anaconda3\\lib\\site-packages (from notebook->jupyter->flaml[notebook]==1.0.10) (20.1.0)\n",
            "Requirement already satisfied: ipython-genutils in c:\\users\\17247\\anaconda3\\lib\\site-packages (from notebook->jupyter->flaml[notebook]==1.0.10) (0.2.0)\n",
            "Requirement already satisfied: Send2Trash>=1.5.0 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from notebook->jupyter->flaml[notebook]==1.0.10) (1.5.0)\n",
            "Requirement already satisfied: prometheus-client in c:\\users\\17247\\anaconda3\\lib\\site-packages (from notebook->jupyter->flaml[notebook]==1.0.10) (0.10.1)\n",
            "Requirement already satisfied: pyzmq>=17 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from notebook->jupyter->flaml[notebook]==1.0.10) (20.0.0)\n",
            "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from notebook->jupyter->flaml[notebook]==1.0.10) (0.9.4)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from plotly->catboost>=0.26->flaml[notebook]==1.0.10) (8.1.0)\n",
            "Requirement already satisfied: qtpy in c:\\users\\17247\\anaconda3\\lib\\site-packages (from qtconsole->jupyter->flaml[notebook]==1.0.10) (1.9.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from requests->openml==0.10.2->flaml[notebook]==1.0.10) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from requests->openml==0.10.2->flaml[notebook]==1.0.10) (1.26.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from requests->openml==0.10.2->flaml[notebook]==1.0.10) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from requests->openml==0.10.2->flaml[notebook]==1.0.10) (2.10)\n",
            "Requirement already satisfied: decorator in c:\\users\\17247\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel->jupyter->flaml[notebook]==1.0.10) (5.0.6)\n",
            "Requirement already satisfied: jedi>=0.16 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel->jupyter->flaml[notebook]==1.0.10) (0.17.2)\n",
            "Requirement already satisfied: colorama in c:\\users\\17247\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel->jupyter->flaml[notebook]==1.0.10) (0.4.4)\n",
            "Requirement already satisfied: pickleshare in c:\\users\\17247\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel->jupyter->flaml[notebook]==1.0.10) (0.7.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel->jupyter->flaml[notebook]==1.0.10) (52.0.0.post20210125)\n",
            "Requirement already satisfied: backcall in c:\\users\\17247\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel->jupyter->flaml[notebook]==1.0.10) (0.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from jinja2>=2.4->nbconvert->jupyter->flaml[notebook]==1.0.10) (1.1.1)\n",
            "Requirement already satisfied: pywin32>=1.0 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from jupyter-core->nbconvert->jupyter->flaml[notebook]==1.0.10) (227)\n",
            "Requirement already satisfied: async-generator in c:\\users\\17247\\anaconda3\\lib\\site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->jupyter->flaml[notebook]==1.0.10) (1.10)\n",
            "Requirement already satisfied: nest-asyncio in c:\\users\\17247\\anaconda3\\lib\\site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->jupyter->flaml[notebook]==1.0.10) (1.5.1)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets->jupyter->flaml[notebook]==1.0.10) (3.2.0)\n",
            "Requirement already satisfied: wcwidth in c:\\users\\17247\\anaconda3\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->jupyter-console->jupyter->flaml[notebook]==1.0.10) (0.2.5)\n",
            "Requirement already satisfied: pywinpty>=0.5 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from terminado>=0.8.3->notebook->jupyter->flaml[notebook]==1.0.10) (0.5.7)\n",
            "Requirement already satisfied: cffi>=1.0.0 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from argon2-cffi->notebook->jupyter->flaml[notebook]==1.0.10) (1.14.5)\n",
            "Requirement already satisfied: webencodings in c:\\users\\17247\\anaconda3\\lib\\site-packages (from bleach->nbconvert->jupyter->flaml[notebook]==1.0.10) (0.5.1)\n",
            "Requirement already satisfied: packaging in c:\\users\\17247\\anaconda3\\lib\\site-packages (from bleach->nbconvert->jupyter->flaml[notebook]==1.0.10) (20.9)\n",
            "Requirement already satisfied: pycparser in c:\\users\\17247\\anaconda3\\lib\\site-packages (from cffi>=1.0.0->argon2-cffi->notebook->jupyter->flaml[notebook]==1.0.10) (2.20)\n",
            "Requirement already satisfied: parso<0.8.0,>=0.7.0 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from jedi>=0.16->ipython>=5.0.0->ipykernel->jupyter->flaml[notebook]==1.0.10) (0.7.0)\n",
            "Requirement already satisfied: pyrsistent>=0.14.0 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter->flaml[notebook]==1.0.10) (0.17.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\17247\\anaconda3\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter->flaml[notebook]==1.0.10) (20.3.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 21.3; however, version 22.2.2 is available.\n",
            "You should consider upgrading via the 'C:\\Users\\17247\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        }
      ],
      "source": [
        "%pip install flaml[notebook]==1.0.10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "025490e7",
      "metadata": {
        "id": "025490e7",
        "outputId": "f94f7c68-64e1-4c85-89c3-669bb975e2cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "load dataset from ./openml_ds40536.pkl\n",
            "Dataset name: SpeedDating\n",
            "X_train.shape: (6283, 120), y_train.shape: (6283,);\n",
            "X_test.shape: (2095, 120), y_test.shape: (2095,)\n",
            "Data type: <class 'pandas.core.frame.DataFrame'> <class 'pandas.core.series.Series'>\n",
            "The first 5 rows of X_train:\n",
            "     has_null  wave  gender   age  age_o  d_age d_d_age  \\\n",
            "5546        1  14.0    male  25.0   32.0    7.0  [7-37]   \n",
            "235         0   2.0  female  21.0   24.0    3.0   [2-3]   \n",
            "7066        1  19.0  female  26.0   29.0    3.0   [2-3]   \n",
            "7357        1  20.0  female  25.0   27.0    2.0   [2-3]   \n",
            "1108        0   4.0  female  28.0   27.0    1.0   [0-1]   \n",
            "\n",
            "                                       race  \\\n",
            "5546            European/Caucasian-American   \n",
            "235   Asian/Pacific Islander/Asian-American   \n",
            "7066            European/Caucasian-American   \n",
            "7357                 Black/African American   \n",
            "1108            European/Caucasian-American   \n",
            "\n",
            "                                     race_o samerace  ...  \\\n",
            "5546            European/Caucasian-American        1  ...   \n",
            "235             European/Caucasian-American        0  ...   \n",
            "7066               Latino/Hispanic American        0  ...   \n",
            "7357  Asian/Pacific Islander/Asian-American        0  ...   \n",
            "1108            European/Caucasian-American        1  ...   \n",
            "\n",
            "      expected_num_interested_in_me  expected_num_matches  \\\n",
            "5546                            NaN                   5.0   \n",
            "235                             3.0                   3.0   \n",
            "7066                            NaN                   NaN   \n",
            "7357                            NaN                   1.0   \n",
            "1108                            6.0                   2.0   \n",
            "\n",
            "     d_expected_happy_with_sd_people d_expected_num_interested_in_me  \\\n",
            "5546                          [7-10]                           [0-3]   \n",
            "235                            [5-6]                           [0-3]   \n",
            "7066                           [0-4]                           [0-3]   \n",
            "7357                           [5-6]                           [0-3]   \n",
            "1108                           [5-6]                           [4-9]   \n",
            "\n",
            "     d_expected_num_matches  like  guess_prob_liked  d_like  \\\n",
            "5546                  [3-5]   5.0               7.0   [0-5]   \n",
            "235                   [3-5]   7.0               6.0   [6-8]   \n",
            "7066                  [0-2]   9.0               NaN  [9-10]   \n",
            "7357                  [0-2]   5.0               4.0   [0-5]   \n",
            "1108                  [0-2]   8.0               8.0   [6-8]   \n",
            "\n",
            "      d_guess_prob_liked  met  \n",
            "5546              [7-10]  0.0  \n",
            "235                [5-6]  0.0  \n",
            "7066               [0-4]  0.0  \n",
            "7357               [0-4]  0.0  \n",
            "1108              [7-10]  0.0  \n",
            "\n",
            "[5 rows x 120 columns]\n",
            "The first 5 rows of y_train:\n",
            "5546    0\n",
            "235     1\n",
            "7066    1\n",
            "7357    0\n",
            "1108    1\n",
            "Name: match, dtype: category\n",
            "Categories (2, object): ['0' < '1']\n"
          ]
        }
      ],
      "source": [
        "from flaml.data import load_openml_dataset\n",
        "X_train, X_test, y_train, y_test = load_openml_dataset(dataset_id=40536, data_dir='./')\n",
        "print(\"Data type:\", type(X_train), type(y_train))\n",
        "print(\"The first 5 rows of X_train:\")\n",
        "print(X_train.head())\n",
        "print(\"The first 5 rows of y_train:\")\n",
        "print(y_train.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5389f5e2",
      "metadata": {
        "id": "5389f5e2"
      },
      "outputs": [],
      "source": [
        "#X_train = X_train.drop(['', 'Age', 'Tm'], axis=1)   THIS CAN BE USED TO FIX XGBOOST ERROR MAYBE?\n",
        "#X_train.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e81fe4e9",
      "metadata": {
        "id": "e81fe4e9"
      },
      "outputs": [],
      "source": [
        "from flaml import AutoML\n",
        "automl = AutoML()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63e6fe50",
      "metadata": {
        "id": "63e6fe50"
      },
      "outputs": [],
      "source": [
        "settings = {\n",
        "    \"time_budget\": 600,  # total running time in seconds\n",
        "    \"metric\": 'accuracy',  # can be: 'r2', 'rmse', 'mae', 'mse', 'accuracy', 'roc_auc', 'roc_auc_ovr',\n",
        "                           # 'roc_auc_ovo', 'log_loss', 'mape', 'f1', 'ap', 'ndcg', 'micro_f1', 'macro_f1'\n",
        "    \"task\": 'classification',  # task type\n",
        "    \"log_file_name\": 'airlines_experiment.log',  # flaml log file\n",
        "    \"seed\": 9458192,    # random seed\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d261137d",
      "metadata": {
        "id": "d261137d",
        "outputId": "f77c529f-f4ec-4323-b354-83578bc690df"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[flaml.automl: 10-15 21:32:56] {2540} INFO - task = classification\n",
            "[flaml.automl: 10-15 21:32:56] {2542} INFO - Data split method: stratified\n",
            "[flaml.automl: 10-15 21:32:56] {2545} INFO - Evaluation method: cv\n",
            "[flaml.automl: 10-15 21:32:56] {2664} INFO - Minimizing error metric: 1-accuracy\n",
            "[flaml.automl: 10-15 21:32:56] {2806} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'catboost', 'xgboost', 'extra_tree', 'xgb_limitdepth', 'lrl1']\n",
            "[flaml.automl: 10-15 21:32:56] {3108} INFO - iteration 0, current learner lgbm\n",
            "[flaml.automl: 10-15 21:32:57] {3241} INFO - Estimated sufficient time budget=14550s. Estimated necessary time budget=357s.\n",
            "[flaml.automl: 10-15 21:32:57] {3288} INFO -  at 1.8s,\testimator lgbm's best error=0.1623,\tbest estimator lgbm's best error=0.1623\n",
            "[flaml.automl: 10-15 21:32:57] {3108} INFO - iteration 1, current learner lgbm\n",
            "[flaml.automl: 10-15 21:32:59] {3288} INFO -  at 3.3s,\testimator lgbm's best error=0.1550,\tbest estimator lgbm's best error=0.1550\n",
            "[flaml.automl: 10-15 21:32:59] {3108} INFO - iteration 2, current learner lgbm\n",
            "[flaml.automl: 10-15 21:33:00] {3288} INFO -  at 4.8s,\testimator lgbm's best error=0.1550,\tbest estimator lgbm's best error=0.1550\n",
            "[flaml.automl: 10-15 21:33:00] {3108} INFO - iteration 3, current learner lgbm\n",
            "[flaml.automl: 10-15 21:33:02] {3288} INFO -  at 6.4s,\testimator lgbm's best error=0.1487,\tbest estimator lgbm's best error=0.1487\n",
            "[flaml.automl: 10-15 21:33:02] {3108} INFO - iteration 4, current learner xgboost\n",
            "[flaml.automl: 10-15 21:33:03] {3288} INFO -  at 7.9s,\testimator xgboost's best error=0.1490,\tbest estimator lgbm's best error=0.1487\n",
            "[flaml.automl: 10-15 21:33:03] {3108} INFO - iteration 5, current learner lgbm\n",
            "[flaml.automl: 10-15 21:33:05] {3288} INFO -  at 9.4s,\testimator lgbm's best error=0.1487,\tbest estimator lgbm's best error=0.1487\n",
            "[flaml.automl: 10-15 21:33:05] {3108} INFO - iteration 6, current learner lgbm\n",
            "[flaml.automl: 10-15 21:33:06] {3288} INFO -  at 10.9s,\testimator lgbm's best error=0.1455,\tbest estimator lgbm's best error=0.1455\n",
            "[flaml.automl: 10-15 21:33:06] {3108} INFO - iteration 7, current learner lgbm\n",
            "[flaml.automl: 10-15 21:33:08] {3288} INFO -  at 12.4s,\testimator lgbm's best error=0.1429,\tbest estimator lgbm's best error=0.1429\n",
            "[flaml.automl: 10-15 21:33:08] {3108} INFO - iteration 8, current learner lgbm\n",
            "[flaml.automl: 10-15 21:33:09] {3288} INFO -  at 13.9s,\testimator lgbm's best error=0.1429,\tbest estimator lgbm's best error=0.1429\n",
            "[flaml.automl: 10-15 21:33:09] {3108} INFO - iteration 9, current learner lgbm\n",
            "[flaml.automl: 10-15 21:33:11] {3288} INFO -  at 15.5s,\testimator lgbm's best error=0.1429,\tbest estimator lgbm's best error=0.1429\n",
            "[flaml.automl: 10-15 21:33:11] {3108} INFO - iteration 10, current learner xgboost\n",
            "[flaml.automl: 10-15 21:33:12] {3288} INFO -  at 17.0s,\testimator xgboost's best error=0.1488,\tbest estimator lgbm's best error=0.1429\n",
            "[flaml.automl: 10-15 21:33:12] {3108} INFO - iteration 11, current learner extra_tree\n",
            "[flaml.automl: 10-15 21:33:13] {3288} INFO -  at 18.1s,\testimator extra_tree's best error=0.1623,\tbest estimator lgbm's best error=0.1429\n",
            "[flaml.automl: 10-15 21:33:13] {3108} INFO - iteration 12, current learner extra_tree\n",
            "[flaml.automl: 10-15 21:33:14] {3288} INFO -  at 19.0s,\testimator extra_tree's best error=0.1617,\tbest estimator lgbm's best error=0.1429\n",
            "[flaml.automl: 10-15 21:33:14] {3108} INFO - iteration 13, current learner rf\n",
            "[flaml.automl: 10-15 21:33:15] {3288} INFO -  at 19.9s,\testimator rf's best error=0.1623,\tbest estimator lgbm's best error=0.1429\n",
            "[flaml.automl: 10-15 21:33:15] {3108} INFO - iteration 14, current learner rf\n",
            "[flaml.automl: 10-15 21:33:17] {3288} INFO -  at 21.3s,\testimator rf's best error=0.1579,\tbest estimator lgbm's best error=0.1429\n",
            "[flaml.automl: 10-15 21:33:17] {3108} INFO - iteration 15, current learner lgbm\n",
            "[flaml.automl: 10-15 21:33:18] {3288} INFO -  at 22.9s,\testimator lgbm's best error=0.1413,\tbest estimator lgbm's best error=0.1413\n",
            "[flaml.automl: 10-15 21:33:18] {3108} INFO - iteration 16, current learner lgbm\n",
            "[flaml.automl: 10-15 21:33:20] {3288} INFO -  at 24.8s,\testimator lgbm's best error=0.1348,\tbest estimator lgbm's best error=0.1348\n",
            "[flaml.automl: 10-15 21:33:20] {3108} INFO - iteration 17, current learner rf\n",
            "[flaml.automl: 10-15 21:33:21] {3288} INFO -  at 25.9s,\testimator rf's best error=0.1579,\tbest estimator lgbm's best error=0.1348\n",
            "[flaml.automl: 10-15 21:33:21] {3108} INFO - iteration 18, current learner lgbm\n",
            "[flaml.automl: 10-15 21:33:23] {3288} INFO -  at 27.5s,\testimator lgbm's best error=0.1348,\tbest estimator lgbm's best error=0.1348\n",
            "[flaml.automl: 10-15 21:33:23] {3108} INFO - iteration 19, current learner lgbm\n",
            "[flaml.automl: 10-15 21:33:25] {3288} INFO -  at 29.3s,\testimator lgbm's best error=0.1348,\tbest estimator lgbm's best error=0.1348\n",
            "[flaml.automl: 10-15 21:33:25] {3108} INFO - iteration 20, current learner lgbm\n",
            "[flaml.automl: 10-15 21:33:27] {3288} INFO -  at 31.2s,\testimator lgbm's best error=0.1348,\tbest estimator lgbm's best error=0.1348\n",
            "[flaml.automl: 10-15 21:33:27] {3108} INFO - iteration 21, current learner lgbm\n",
            "[flaml.automl: 10-15 21:33:29] {3288} INFO -  at 33.3s,\testimator lgbm's best error=0.1348,\tbest estimator lgbm's best error=0.1348\n",
            "[flaml.automl: 10-15 21:33:29] {3108} INFO - iteration 22, current learner lgbm\n",
            "[flaml.automl: 10-15 21:33:30] {3288} INFO -  at 35.0s,\testimator lgbm's best error=0.1348,\tbest estimator lgbm's best error=0.1348\n",
            "[flaml.automl: 10-15 21:33:30] {3108} INFO - iteration 23, current learner lgbm\n",
            "[flaml.automl: 10-15 21:33:32] {3288} INFO -  at 36.9s,\testimator lgbm's best error=0.1345,\tbest estimator lgbm's best error=0.1345\n",
            "[flaml.automl: 10-15 21:33:32] {3108} INFO - iteration 24, current learner rf\n",
            "[flaml.automl: 10-15 21:33:34] {3288} INFO -  at 38.1s,\testimator rf's best error=0.1579,\tbest estimator lgbm's best error=0.1345\n",
            "[flaml.automl: 10-15 21:33:34] {3108} INFO - iteration 25, current learner extra_tree\n",
            "[flaml.automl: 10-15 21:33:34] {3288} INFO -  at 39.1s,\testimator extra_tree's best error=0.1617,\tbest estimator lgbm's best error=0.1345\n",
            "[flaml.automl: 10-15 21:33:34] {3108} INFO - iteration 26, current learner lgbm\n",
            "[flaml.automl: 10-15 21:33:36] {3288} INFO -  at 40.8s,\testimator lgbm's best error=0.1305,\tbest estimator lgbm's best error=0.1305\n",
            "[flaml.automl: 10-15 21:33:36] {3108} INFO - iteration 27, current learner lgbm\n",
            "[flaml.automl: 10-15 21:33:38] {3288} INFO -  at 42.8s,\testimator lgbm's best error=0.1305,\tbest estimator lgbm's best error=0.1305\n",
            "[flaml.automl: 10-15 21:33:38] {3108} INFO - iteration 28, current learner lgbm\n",
            "[flaml.automl: 10-15 21:33:42] {3288} INFO -  at 46.3s,\testimator lgbm's best error=0.1300,\tbest estimator lgbm's best error=0.1300\n",
            "[flaml.automl: 10-15 21:33:42] {3108} INFO - iteration 29, current learner rf\n",
            "[flaml.automl: 10-15 21:33:43] {3288} INFO -  at 47.2s,\testimator rf's best error=0.1537,\tbest estimator lgbm's best error=0.1300\n",
            "[flaml.automl: 10-15 21:33:43] {3108} INFO - iteration 30, current learner lgbm\n",
            "[flaml.automl: 10-15 21:33:44] {3288} INFO -  at 49.0s,\testimator lgbm's best error=0.1300,\tbest estimator lgbm's best error=0.1300\n",
            "[flaml.automl: 10-15 21:33:44] {3108} INFO - iteration 31, current learner lgbm\n",
            "[flaml.automl: 10-15 21:33:47] {3288} INFO -  at 51.2s,\testimator lgbm's best error=0.1296,\tbest estimator lgbm's best error=0.1296\n",
            "[flaml.automl: 10-15 21:33:47] {3108} INFO - iteration 32, current learner lgbm\n",
            "[flaml.automl: 10-15 21:33:50] {3288} INFO -  at 54.7s,\testimator lgbm's best error=0.1294,\tbest estimator lgbm's best error=0.1294\n",
            "[flaml.automl: 10-15 21:33:50] {3108} INFO - iteration 33, current learner lgbm\n",
            "[flaml.automl: 10-15 21:33:53] {3288} INFO -  at 57.3s,\testimator lgbm's best error=0.1294,\tbest estimator lgbm's best error=0.1294\n",
            "[flaml.automl: 10-15 21:33:53] {3108} INFO - iteration 34, current learner lgbm\n",
            "[flaml.automl: 10-15 21:33:57] {3288} INFO -  at 62.0s,\testimator lgbm's best error=0.1294,\tbest estimator lgbm's best error=0.1294\n",
            "[flaml.automl: 10-15 21:33:57] {3108} INFO - iteration 35, current learner lgbm\n",
            "[flaml.automl: 10-15 21:34:00] {3288} INFO -  at 64.4s,\testimator lgbm's best error=0.1294,\tbest estimator lgbm's best error=0.1294\n",
            "[flaml.automl: 10-15 21:34:00] {3108} INFO - iteration 36, current learner xgboost\n",
            "[flaml.automl: 10-15 21:34:01] {3288} INFO -  at 65.9s,\testimator xgboost's best error=0.1488,\tbest estimator lgbm's best error=0.1294\n",
            "[flaml.automl: 10-15 21:34:01] {3108} INFO - iteration 37, current learner lgbm\n",
            "[flaml.automl: 10-15 21:34:07] {3288} INFO -  at 71.2s,\testimator lgbm's best error=0.1294,\tbest estimator lgbm's best error=0.1294\n",
            "[flaml.automl: 10-15 21:34:07] {3108} INFO - iteration 38, current learner rf\n",
            "[flaml.automl: 10-15 21:34:08] {3288} INFO -  at 72.3s,\testimator rf's best error=0.1507,\tbest estimator lgbm's best error=0.1294\n",
            "[flaml.automl: 10-15 21:34:08] {3108} INFO - iteration 39, current learner lgbm\n",
            "[flaml.automl: 10-15 21:34:14] {3288} INFO -  at 78.3s,\testimator lgbm's best error=0.1294,\tbest estimator lgbm's best error=0.1294\n",
            "[flaml.automl: 10-15 21:34:14] {3108} INFO - iteration 40, current learner rf\n",
            "[flaml.automl: 10-15 21:34:15] {3288} INFO -  at 79.3s,\testimator rf's best error=0.1501,\tbest estimator lgbm's best error=0.1294\n",
            "[flaml.automl: 10-15 21:34:15] {3108} INFO - iteration 41, current learner rf\n",
            "[flaml.automl: 10-15 21:34:16] {3288} INFO -  at 80.3s,\testimator rf's best error=0.1480,\tbest estimator lgbm's best error=0.1294\n",
            "[flaml.automl: 10-15 21:34:16] {3108} INFO - iteration 42, current learner lgbm\n",
            "[flaml.automl: 10-15 21:34:18] {3288} INFO -  at 82.6s,\testimator lgbm's best error=0.1294,\tbest estimator lgbm's best error=0.1294\n",
            "[flaml.automl: 10-15 21:34:18] {3108} INFO - iteration 43, current learner rf\n",
            "[flaml.automl: 10-15 21:34:19] {3288} INFO -  at 83.8s,\testimator rf's best error=0.1480,\tbest estimator lgbm's best error=0.1294\n",
            "[flaml.automl: 10-15 21:34:19] {3108} INFO - iteration 44, current learner catboost\n",
            "[flaml.automl: 10-15 21:34:30] {3288} INFO -  at 94.9s,\testimator catboost's best error=0.1386,\tbest estimator lgbm's best error=0.1294\n",
            "[flaml.automl: 10-15 21:34:30] {3108} INFO - iteration 45, current learner extra_tree\n",
            "[flaml.automl: 10-15 21:34:32] {3288} INFO -  at 96.3s,\testimator extra_tree's best error=0.1617,\tbest estimator lgbm's best error=0.1294\n",
            "[flaml.automl: 10-15 21:34:32] {3108} INFO - iteration 46, current learner catboost\n",
            "[flaml.automl: 10-15 21:34:47] {3288} INFO -  at 111.7s,\testimator catboost's best error=0.1372,\tbest estimator lgbm's best error=0.1294\n",
            "[flaml.automl: 10-15 21:34:47] {3108} INFO - iteration 47, current learner lgbm\n",
            "[flaml.automl: 10-15 21:34:54] {3288} INFO -  at 118.5s,\testimator lgbm's best error=0.1257,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:34:54] {3108} INFO - iteration 48, current learner rf\n",
            "[flaml.automl: 10-15 21:34:55] {3288} INFO -  at 120.1s,\testimator rf's best error=0.1480,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:34:55] {3108} INFO - iteration 49, current learner lgbm\n",
            "[flaml.automl: 10-15 21:34:58] {3288} INFO -  at 122.6s,\testimator lgbm's best error=0.1257,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:34:58] {3108} INFO - iteration 50, current learner lgbm\n",
            "[flaml.automl: 10-15 21:35:15] {3288} INFO -  at 139.5s,\testimator lgbm's best error=0.1257,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:35:15] {3108} INFO - iteration 51, current learner catboost\n",
            "[flaml.automl: 10-15 21:35:26] {3288} INFO -  at 150.8s,\testimator catboost's best error=0.1356,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:35:26] {3108} INFO - iteration 52, current learner lgbm\n",
            "[flaml.automl: 10-15 21:35:36] {3288} INFO -  at 160.8s,\testimator lgbm's best error=0.1257,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:35:36] {3108} INFO - iteration 53, current learner lgbm\n",
            "[flaml.automl: 10-15 21:35:42] {3288} INFO -  at 166.2s,\testimator lgbm's best error=0.1257,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:35:42] {3108} INFO - iteration 54, current learner lgbm\n",
            "[flaml.automl: 10-15 21:35:47] {3288} INFO -  at 171.4s,\testimator lgbm's best error=0.1257,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:35:47] {3108} INFO - iteration 55, current learner lgbm\n",
            "[flaml.automl: 10-15 21:35:56] {3288} INFO -  at 181.1s,\testimator lgbm's best error=0.1257,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:35:56] {3108} INFO - iteration 56, current learner rf\n",
            "[flaml.automl: 10-15 21:35:58] {3288} INFO -  at 182.4s,\testimator rf's best error=0.1464,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:35:58] {3108} INFO - iteration 57, current learner lgbm\n",
            "[flaml.automl: 10-15 21:36:03] {3288} INFO -  at 188.1s,\testimator lgbm's best error=0.1257,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:36:03] {3108} INFO - iteration 58, current learner lgbm\n",
            "[flaml.automl: 10-15 21:36:12] {3288} INFO -  at 197.0s,\testimator lgbm's best error=0.1257,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:36:12] {3108} INFO - iteration 59, current learner rf\n",
            "[flaml.automl: 10-15 21:36:14] {3288} INFO -  at 198.1s,\testimator rf's best error=0.1455,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:36:14] {3108} INFO - iteration 60, current learner lgbm\n",
            "[flaml.automl: 10-15 21:36:22] {3288} INFO -  at 206.8s,\testimator lgbm's best error=0.1257,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:36:22] {3108} INFO - iteration 61, current learner rf\n",
            "[flaml.automl: 10-15 21:36:23] {3288} INFO -  at 207.8s,\testimator rf's best error=0.1444,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:36:23] {3108} INFO - iteration 62, current learner lgbm\n",
            "[flaml.automl: 10-15 21:36:29] {3288} INFO -  at 213.3s,\testimator lgbm's best error=0.1257,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:36:29] {3108} INFO - iteration 63, current learner rf\n",
            "[flaml.automl: 10-15 21:36:30] {3288} INFO -  at 214.2s,\testimator rf's best error=0.1444,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:36:30] {3108} INFO - iteration 64, current learner rf\n",
            "[flaml.automl: 10-15 21:36:31] {3288} INFO -  at 215.3s,\testimator rf's best error=0.1421,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:36:31] {3108} INFO - iteration 65, current learner lgbm\n",
            "[flaml.automl: 10-15 21:36:40] {3288} INFO -  at 224.9s,\testimator lgbm's best error=0.1257,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:36:40] {3108} INFO - iteration 66, current learner rf\n",
            "[flaml.automl: 10-15 21:36:42] {3288} INFO -  at 226.8s,\testimator rf's best error=0.1420,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:36:42] {3108} INFO - iteration 67, current learner catboost\n",
            "[flaml.automl: 10-15 21:36:56] {3288} INFO -  at 240.2s,\testimator catboost's best error=0.1356,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:36:56] {3108} INFO - iteration 68, current learner lgbm\n",
            "[flaml.automl: 10-15 21:37:03] {3288} INFO -  at 247.3s,\testimator lgbm's best error=0.1257,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:37:03] {3108} INFO - iteration 69, current learner xgb_limitdepth\n",
            "[flaml.automl: 10-15 21:37:05] {3288} INFO -  at 249.3s,\testimator xgb_limitdepth's best error=0.1359,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:37:05] {3108} INFO - iteration 70, current learner xgb_limitdepth\n",
            "[flaml.automl: 10-15 21:37:07] {3288} INFO -  at 251.4s,\testimator xgb_limitdepth's best error=0.1359,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:37:07] {3108} INFO - iteration 71, current learner xgb_limitdepth\n",
            "[flaml.automl: 10-15 21:37:09] {3288} INFO -  at 253.4s,\testimator xgb_limitdepth's best error=0.1359,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:37:09] {3108} INFO - iteration 72, current learner xgb_limitdepth\n",
            "[flaml.automl: 10-15 21:37:11] {3288} INFO -  at 255.4s,\testimator xgb_limitdepth's best error=0.1359,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:37:11] {3108} INFO - iteration 73, current learner xgb_limitdepth\n",
            "[flaml.automl: 10-15 21:37:13] {3288} INFO -  at 257.6s,\testimator xgb_limitdepth's best error=0.1359,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:37:13] {3108} INFO - iteration 74, current learner xgb_limitdepth\n",
            "[flaml.automl: 10-15 21:37:15] {3288} INFO -  at 259.5s,\testimator xgb_limitdepth's best error=0.1359,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:37:15] {3108} INFO - iteration 75, current learner xgb_limitdepth\n",
            "[flaml.automl: 10-15 21:37:17] {3288} INFO -  at 261.5s,\testimator xgb_limitdepth's best error=0.1359,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:37:17] {3108} INFO - iteration 76, current learner xgb_limitdepth\n",
            "[flaml.automl: 10-15 21:37:19] {3288} INFO -  at 263.2s,\testimator xgb_limitdepth's best error=0.1359,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:37:19] {3108} INFO - iteration 77, current learner rf\n",
            "[flaml.automl: 10-15 21:37:20] {3288} INFO -  at 264.3s,\testimator rf's best error=0.1420,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:37:20] {3108} INFO - iteration 78, current learner catboost\n",
            "[flaml.automl: 10-15 21:37:37] {3288} INFO -  at 282.0s,\testimator catboost's best error=0.1343,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:37:37] {3108} INFO - iteration 79, current learner xgb_limitdepth\n",
            "[flaml.automl: 10-15 21:37:39] {3288} INFO -  at 284.0s,\testimator xgb_limitdepth's best error=0.1359,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:37:39] {3108} INFO - iteration 80, current learner xgb_limitdepth\n",
            "[flaml.automl: 10-15 21:37:41] {3288} INFO -  at 285.8s,\testimator xgb_limitdepth's best error=0.1331,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:37:41] {3108} INFO - iteration 81, current learner lgbm\n",
            "[flaml.automl: 10-15 21:37:54] {3288} INFO -  at 298.9s,\testimator lgbm's best error=0.1257,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:37:54] {3108} INFO - iteration 82, current learner xgb_limitdepth\n",
            "[flaml.automl: 10-15 21:37:56] {3288} INFO -  at 300.7s,\testimator xgb_limitdepth's best error=0.1331,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:37:56] {3108} INFO - iteration 83, current learner rf\n",
            "[flaml.automl: 10-15 21:37:58] {3288} INFO -  at 303.0s,\testimator rf's best error=0.1391,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:37:58] {3108} INFO - iteration 84, current learner catboost\n",
            "[flaml.automl: 10-15 21:38:28] {3288} INFO -  at 332.6s,\testimator catboost's best error=0.1340,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:38:28] {3108} INFO - iteration 85, current learner rf\n",
            "[flaml.automl: 10-15 21:38:30] {3288} INFO -  at 334.4s,\testimator rf's best error=0.1391,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:38:30] {3108} INFO - iteration 86, current learner xgb_limitdepth\n",
            "[flaml.automl: 10-15 21:38:31] {3288} INFO -  at 336.0s,\testimator xgb_limitdepth's best error=0.1331,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:38:31] {3108} INFO - iteration 87, current learner rf\n",
            "[flaml.automl: 10-15 21:38:33] {3288} INFO -  at 338.1s,\testimator rf's best error=0.1391,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:38:33] {3108} INFO - iteration 88, current learner extra_tree\n",
            "[flaml.automl: 10-15 21:38:34] {3288} INFO -  at 338.9s,\testimator extra_tree's best error=0.1611,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:38:34] {3108} INFO - iteration 89, current learner rf\n",
            "[flaml.automl: 10-15 21:38:35] {3288} INFO -  at 340.1s,\testimator rf's best error=0.1391,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:38:35] {3108} INFO - iteration 90, current learner rf\n",
            "[flaml.automl: 10-15 21:38:38] {3288} INFO -  at 342.5s,\testimator rf's best error=0.1391,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:38:38] {3108} INFO - iteration 91, current learner xgb_limitdepth\n",
            "[flaml.automl: 10-15 21:38:41] {3288} INFO -  at 345.2s,\testimator xgb_limitdepth's best error=0.1331,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:38:41] {3108} INFO - iteration 92, current learner rf\n",
            "[flaml.automl: 10-15 21:38:42] {3288} INFO -  at 346.5s,\testimator rf's best error=0.1391,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:38:42] {3108} INFO - iteration 93, current learner xgb_limitdepth\n",
            "[flaml.automl: 10-15 21:38:44] {3288} INFO -  at 348.7s,\testimator xgb_limitdepth's best error=0.1331,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:38:44] {3108} INFO - iteration 94, current learner extra_tree\n",
            "[flaml.automl: 10-15 21:38:46] {3288} INFO -  at 350.3s,\testimator extra_tree's best error=0.1595,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:38:46] {3108} INFO - iteration 95, current learner extra_tree\n",
            "[flaml.automl: 10-15 21:38:47] {3288} INFO -  at 351.4s,\testimator extra_tree's best error=0.1569,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:38:47] {3108} INFO - iteration 96, current learner lgbm\n",
            "[flaml.automl: 10-15 21:38:51] {3288} INFO -  at 355.3s,\testimator lgbm's best error=0.1257,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:38:51] {3108} INFO - iteration 97, current learner xgb_limitdepth\n",
            "[flaml.automl: 10-15 21:38:52] {3288} INFO -  at 356.9s,\testimator xgb_limitdepth's best error=0.1331,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:38:52] {3108} INFO - iteration 98, current learner extra_tree\n",
            "[flaml.automl: 10-15 21:38:53] {3288} INFO -  at 358.0s,\testimator extra_tree's best error=0.1569,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:38:53] {3108} INFO - iteration 99, current learner extra_tree\n",
            "[flaml.automl: 10-15 21:38:54] {3288} INFO -  at 359.0s,\testimator extra_tree's best error=0.1568,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:38:54] {3108} INFO - iteration 100, current learner rf\n",
            "[flaml.automl: 10-15 21:38:56] {3288} INFO -  at 361.0s,\testimator rf's best error=0.1391,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:38:56] {3108} INFO - iteration 101, current learner lgbm\n",
            "[flaml.automl: 10-15 21:39:08] {3288} INFO -  at 372.5s,\testimator lgbm's best error=0.1257,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:39:08] {3108} INFO - iteration 102, current learner xgb_limitdepth\n",
            "[flaml.automl: 10-15 21:39:10] {3288} INFO -  at 374.2s,\testimator xgb_limitdepth's best error=0.1331,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:39:10] {3108} INFO - iteration 103, current learner rf\n",
            "[flaml.automl: 10-15 21:39:11] {3288} INFO -  at 375.9s,\testimator rf's best error=0.1391,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:39:11] {3108} INFO - iteration 104, current learner lgbm\n",
            "[flaml.automl: 10-15 21:39:15] {3288} INFO -  at 380.1s,\testimator lgbm's best error=0.1257,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:39:15] {3108} INFO - iteration 105, current learner catboost\n",
            "[flaml.automl: 10-15 21:40:05] {3288} INFO -  at 429.1s,\testimator catboost's best error=0.1340,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:40:05] {3108} INFO - iteration 106, current learner lgbm\n",
            "[flaml.automl: 10-15 21:40:08] {3288} INFO -  at 432.3s,\testimator lgbm's best error=0.1257,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:40:08] {3108} INFO - iteration 107, current learner rf\n",
            "[flaml.automl: 10-15 21:40:09] {3288} INFO -  at 434.0s,\testimator rf's best error=0.1391,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:40:09] {3108} INFO - iteration 108, current learner xgb_limitdepth\n",
            "[flaml.automl: 10-15 21:40:11] {3288} INFO -  at 436.0s,\testimator xgb_limitdepth's best error=0.1331,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:40:11] {3108} INFO - iteration 109, current learner rf\n",
            "[flaml.automl: 10-15 21:40:13] {3288} INFO -  at 438.1s,\testimator rf's best error=0.1388,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:40:13] {3108} INFO - iteration 110, current learner xgb_limitdepth\n",
            "[flaml.automl: 10-15 21:40:15] {3288} INFO -  at 439.9s,\testimator xgb_limitdepth's best error=0.1331,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:40:15] {3108} INFO - iteration 111, current learner extra_tree\n",
            "[flaml.automl: 10-15 21:40:16] {3288} INFO -  at 441.0s,\testimator extra_tree's best error=0.1568,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:40:16] {3108} INFO - iteration 112, current learner lgbm\n",
            "[flaml.automl: 10-15 21:40:27] {3288} INFO -  at 451.8s,\testimator lgbm's best error=0.1257,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:40:27] {3108} INFO - iteration 113, current learner xgb_limitdepth\n",
            "[flaml.automl: 10-15 21:40:29] {3288} INFO -  at 453.7s,\testimator xgb_limitdepth's best error=0.1331,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:40:29] {3108} INFO - iteration 114, current learner xgb_limitdepth\n",
            "[flaml.automl: 10-15 21:40:32] {3288} INFO -  at 456.3s,\testimator xgb_limitdepth's best error=0.1331,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:40:32] {3108} INFO - iteration 115, current learner xgb_limitdepth\n",
            "[flaml.automl: 10-15 21:40:33] {3288} INFO -  at 457.9s,\testimator xgb_limitdepth's best error=0.1331,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:40:33] {3108} INFO - iteration 116, current learner lgbm\n",
            "[flaml.automl: 10-15 21:40:39] {3288} INFO -  at 463.8s,\testimator lgbm's best error=0.1257,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:40:39] {3108} INFO - iteration 117, current learner lgbm\n",
            "[flaml.automl: 10-15 21:40:44] {3288} INFO -  at 469.1s,\testimator lgbm's best error=0.1257,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:40:44] {3108} INFO - iteration 118, current learner xgb_limitdepth\n",
            "[flaml.automl: 10-15 21:40:47] {3288} INFO -  at 471.2s,\testimator xgb_limitdepth's best error=0.1331,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:40:47] {3108} INFO - iteration 119, current learner xgb_limitdepth\n",
            "[flaml.automl: 10-15 21:40:48] {3288} INFO -  at 472.9s,\testimator xgb_limitdepth's best error=0.1331,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:40:48] {3108} INFO - iteration 120, current learner lgbm\n",
            "[flaml.automl: 10-15 21:40:54] {3288} INFO -  at 478.4s,\testimator lgbm's best error=0.1257,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:40:54] {3108} INFO - iteration 121, current learner xgb_limitdepth\n",
            "[flaml.automl: 10-15 21:40:56] {3288} INFO -  at 480.9s,\testimator xgb_limitdepth's best error=0.1331,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:40:56] {3108} INFO - iteration 122, current learner xgb_limitdepth\n",
            "[flaml.automl: 10-15 21:40:58] {3288} INFO -  at 482.5s,\testimator xgb_limitdepth's best error=0.1331,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:40:58] {3108} INFO - iteration 123, current learner xgb_limitdepth\n",
            "[flaml.automl: 10-15 21:41:00] {3288} INFO -  at 484.4s,\testimator xgb_limitdepth's best error=0.1331,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:41:00] {3108} INFO - iteration 124, current learner xgb_limitdepth\n",
            "[flaml.automl: 10-15 21:41:02] {3288} INFO -  at 486.3s,\testimator xgb_limitdepth's best error=0.1331,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:41:02] {3108} INFO - iteration 125, current learner lgbm\n",
            "[flaml.automl: 10-15 21:41:10] {3288} INFO -  at 494.8s,\testimator lgbm's best error=0.1257,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:41:10] {3108} INFO - iteration 126, current learner lgbm\n",
            "[flaml.automl: 10-15 21:41:14] {3288} INFO -  at 499.1s,\testimator lgbm's best error=0.1257,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:41:14] {3108} INFO - iteration 127, current learner lgbm\n",
            "[flaml.automl: 10-15 21:41:25] {3288} INFO -  at 509.9s,\testimator lgbm's best error=0.1257,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:41:25] {3108} INFO - iteration 128, current learner lgbm\n",
            "[flaml.automl: 10-15 21:41:37] {3288} INFO -  at 521.4s,\testimator lgbm's best error=0.1257,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:41:37] {3108} INFO - iteration 129, current learner lgbm\n",
            "[flaml.automl: 10-15 21:41:40] {3288} INFO -  at 524.2s,\testimator lgbm's best error=0.1257,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:41:40] {3108} INFO - iteration 130, current learner xgb_limitdepth\n",
            "[flaml.automl: 10-15 21:41:42] {3288} INFO -  at 527.0s,\testimator xgb_limitdepth's best error=0.1331,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:41:42] {3108} INFO - iteration 131, current learner xgboost\n",
            "[flaml.automl: 10-15 21:41:44] {3288} INFO -  at 528.6s,\testimator xgboost's best error=0.1428,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:41:44] {3108} INFO - iteration 132, current learner xgboost\n",
            "[flaml.automl: 10-15 21:41:46] {3288} INFO -  at 530.3s,\testimator xgboost's best error=0.1428,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:41:46] {3108} INFO - iteration 133, current learner xgboost\n",
            "[flaml.automl: 10-15 21:41:47] {3288} INFO -  at 531.9s,\testimator xgboost's best error=0.1404,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:41:47] {3108} INFO - iteration 134, current learner lgbm\n",
            "[flaml.automl: 10-15 21:41:52] {3288} INFO -  at 536.9s,\testimator lgbm's best error=0.1257,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:41:52] {3108} INFO - iteration 135, current learner xgboost\n",
            "[flaml.automl: 10-15 21:41:54] {3288} INFO -  at 538.6s,\testimator xgboost's best error=0.1397,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:41:54] {3108} INFO - iteration 136, current learner xgboost\n",
            "[flaml.automl: 10-15 21:41:56] {3288} INFO -  at 540.2s,\testimator xgboost's best error=0.1397,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:41:56] {3108} INFO - iteration 137, current learner xgb_limitdepth\n",
            "[flaml.automl: 10-15 21:41:57] {3288} INFO -  at 541.9s,\testimator xgb_limitdepth's best error=0.1331,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:41:57] {3108} INFO - iteration 138, current learner xgboost\n",
            "[flaml.automl: 10-15 21:41:59] {3288} INFO -  at 543.7s,\testimator xgboost's best error=0.1397,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:41:59] {3108} INFO - iteration 139, current learner lgbm\n",
            "[flaml.automl: 10-15 21:42:07] {3288} INFO -  at 552.0s,\testimator lgbm's best error=0.1257,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:42:07] {3108} INFO - iteration 140, current learner xgb_limitdepth\n",
            "[flaml.automl: 10-15 21:42:09] {3288} INFO -  at 554.0s,\testimator xgb_limitdepth's best error=0.1331,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:42:09] {3108} INFO - iteration 141, current learner lgbm\n",
            "[flaml.automl: 10-15 21:42:13] {3288} INFO -  at 557.7s,\testimator lgbm's best error=0.1257,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:42:13] {3108} INFO - iteration 142, current learner xgb_limitdepth\n",
            "[flaml.automl: 10-15 21:42:15] {3288} INFO -  at 559.9s,\testimator xgb_limitdepth's best error=0.1331,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:42:15] {3108} INFO - iteration 143, current learner catboost\n",
            "[flaml.automl: 10-15 21:42:33] {3288} INFO -  at 577.9s,\testimator catboost's best error=0.1340,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:42:33] {3108} INFO - iteration 144, current learner xgb_limitdepth\n",
            "[flaml.automl: 10-15 21:42:35] {3288} INFO -  at 579.7s,\testimator xgb_limitdepth's best error=0.1331,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:42:35] {3108} INFO - iteration 145, current learner extra_tree\n",
            "[flaml.automl: 10-15 21:42:36] {3288} INFO -  at 580.6s,\testimator extra_tree's best error=0.1504,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:42:36] {3108} INFO - iteration 146, current learner extra_tree\n",
            "[flaml.automl: 10-15 21:42:37] {3288} INFO -  at 582.1s,\testimator extra_tree's best error=0.1504,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:42:37] {3108} INFO - iteration 147, current learner xgboost\n",
            "[flaml.automl: 10-15 21:42:39] {3288} INFO -  at 583.6s,\testimator xgboost's best error=0.1394,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:42:39] {3108} INFO - iteration 148, current learner lgbm\n",
            "[flaml.automl: 10-15 21:42:56] {3288} INFO -  at 600.2s,\testimator lgbm's best error=0.1257,\tbest estimator lgbm's best error=0.1257\n",
            "[flaml.automl: 10-15 21:42:57] {3552} INFO - retrain lgbm for 1.5s\n",
            "[flaml.automl: 10-15 21:42:57] {3559} INFO - retrained model: LGBMClassifier(colsample_bytree=0.7945324135347446,\n",
            "               learning_rate=0.07349456601711642, max_bin=511,\n",
            "               min_child_samples=81, n_estimators=383, num_leaves=148,\n",
            "               reg_alpha=0.0038090040724731134,\n",
            "               reg_lambda=0.0027820040646453358, verbose=-1)\n",
            "[flaml.automl: 10-15 21:42:57] {2837} INFO - fit succeeded\n",
            "[flaml.automl: 10-15 21:42:57] {2838} INFO - Time taken to find the best model: 118.51641654968262\n"
          ]
        }
      ],
      "source": [
        "automl.fit(X_train = X_train, y_train = y_train, **settings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab22c146",
      "metadata": {
        "scrolled": true,
        "id": "ab22c146",
        "outputId": "a61c45a1-283f-45be-8340-2cce87984d58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best ML leaner: lgbm\n",
            "Best hyperparmeter config: {'n_estimators': 383, 'num_leaves': 148, 'min_child_samples': 81, 'learning_rate': 0.07349456601711642, 'log_max_bin': 9, 'colsample_bytree': 0.7945324135347446, 'reg_alpha': 0.0038090040724731134, 'reg_lambda': 0.0027820040646453358}\n",
            "Best accuracy on validation data: 0.8743\n",
            "Training duration of best run: 1.497 s\n"
          ]
        }
      ],
      "source": [
        "print('Best ML leaner:', automl.best_estimator)\n",
        "print('Best hyperparmeter config:', automl.best_config)\n",
        "print('Best accuracy on validation data: {0:.4g}'.format(1-automl.best_loss))\n",
        "print('Training duration of best run: {0:.4g} s'.format(automl.best_config_train_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4381fb01",
      "metadata": {
        "id": "4381fb01",
        "outputId": "9facfca5-f24b-4de7-a7e5-fd41b4bf6fa8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LGBMClassifier(colsample_bytree=0.7945324135347446,\n",
              "               learning_rate=0.07349456601711642, max_bin=511,\n",
              "               min_child_samples=81, n_estimators=383, num_leaves=148,\n",
              "               reg_alpha=0.0038090040724731134,\n",
              "               reg_lambda=0.0027820040646453358, verbose=-1)"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "automl.model.estimator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f3ec619",
      "metadata": {
        "id": "5f3ec619",
        "outputId": "65641cda-ce91-4c54-b805-b079f6360230"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted labels ['0' '0' '0' ... '0' '0' '0']\n",
            "True labels 2265    0\n",
            "2851    0\n",
            "3655    0\n",
            "196     0\n",
            "3719    0\n",
            "       ..\n",
            "3791    0\n",
            "7913    0\n",
            "1790    0\n",
            "5318    0\n",
            "7318    0\n",
            "Name: match, Length: 2095, dtype: category\n",
            "Categories (2, object): ['0' < '1']\n"
          ]
        }
      ],
      "source": [
        "y_pred = automl.predict(X_test)\n",
        "print('Predicted labels', y_pred)\n",
        "print('True labels', y_test)\n",
        "y_pred_proba = automl.predict_proba(X_test)[:,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68441310",
      "metadata": {
        "id": "68441310",
        "outputId": "4e0b4974-40e0-46b2-e775-9ba765323ba0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy = 0.8706443914081146\n",
            "roc_auc = 0.8808645533141212\n",
            "log_loss = 0.399702410433201\n"
          ]
        }
      ],
      "source": [
        "from flaml.ml import sklearn_metric_loss_score\n",
        "print('accuracy', '=', 1 - sklearn_metric_loss_score('accuracy', y_pred, y_test))\n",
        "print('roc_auc', '=', 1 - sklearn_metric_loss_score('roc_auc', y_pred_proba, y_test))\n",
        "print('log_loss', '=', sklearn_metric_loss_score('log_loss', y_pred_proba, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39eef0ed",
      "metadata": {
        "id": "39eef0ed",
        "outputId": "94ddf6d2-a943-4ef7-fcf0-64d5995ffe3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Current Learner': 'lgbm', 'Current Sample': 6283, 'Current Hyper-parameters': {'n_estimators': 4, 'num_leaves': 4, 'min_child_samples': 20, 'learning_rate': 0.09999999999999995, 'log_max_bin': 8, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.0}, 'Best Learner': 'lgbm', 'Best Hyper-parameters': {'n_estimators': 4, 'num_leaves': 4, 'min_child_samples': 20, 'learning_rate': 0.09999999999999995, 'log_max_bin': 8, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.0}}\n",
            "{'Current Learner': 'lgbm', 'Current Sample': 6283, 'Current Hyper-parameters': {'n_estimators': 5, 'num_leaves': 4, 'min_child_samples': 35, 'learning_rate': 0.217390709783794, 'log_max_bin': 8, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.10260733108888935}, 'Best Learner': 'lgbm', 'Best Hyper-parameters': {'n_estimators': 5, 'num_leaves': 4, 'min_child_samples': 35, 'learning_rate': 0.217390709783794, 'log_max_bin': 8, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.10260733108888935}}\n",
            "{'Current Learner': 'lgbm', 'Current Sample': 6283, 'Current Hyper-parameters': {'n_estimators': 6, 'num_leaves': 4, 'min_child_samples': 47, 'learning_rate': 0.22896368654364246, 'log_max_bin': 8, 'colsample_bytree': 1.0, 'reg_alpha': 0.0011293633547972382, 'reg_lambda': 0.009223752143831209}, 'Best Learner': 'lgbm', 'Best Hyper-parameters': {'n_estimators': 6, 'num_leaves': 4, 'min_child_samples': 47, 'learning_rate': 0.22896368654364246, 'log_max_bin': 8, 'colsample_bytree': 1.0, 'reg_alpha': 0.0011293633547972382, 'reg_lambda': 0.009223752143831209}}\n",
            "{'Current Learner': 'lgbm', 'Current Sample': 6283, 'Current Hyper-parameters': {'n_estimators': 9, 'num_leaves': 4, 'min_child_samples': 34, 'learning_rate': 0.19075302418396065, 'log_max_bin': 9, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.11001674455590196}, 'Best Learner': 'lgbm', 'Best Hyper-parameters': {'n_estimators': 9, 'num_leaves': 4, 'min_child_samples': 34, 'learning_rate': 0.19075302418396065, 'log_max_bin': 9, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.11001674455590196}}\n",
            "{'Current Learner': 'lgbm', 'Current Sample': 6283, 'Current Hyper-parameters': {'n_estimators': 6, 'num_leaves': 10, 'min_child_samples': 46, 'learning_rate': 0.22896368654364246, 'log_max_bin': 8, 'colsample_bytree': 0.9151672901279894, 'reg_alpha': 0.0028201126607683698, 'reg_lambda': 0.009223752143831213}, 'Best Learner': 'lgbm', 'Best Hyper-parameters': {'n_estimators': 6, 'num_leaves': 10, 'min_child_samples': 46, 'learning_rate': 0.22896368654364246, 'log_max_bin': 8, 'colsample_bytree': 0.9151672901279894, 'reg_alpha': 0.0028201126607683698, 'reg_lambda': 0.009223752143831213}}\n",
            "{'Current Learner': 'lgbm', 'Current Sample': 6283, 'Current Hyper-parameters': {'n_estimators': 11, 'num_leaves': 53, 'min_child_samples': 33, 'learning_rate': 0.10638311711134216, 'log_max_bin': 8, 'colsample_bytree': 0.9504814804454289, 'reg_alpha': 0.0023411461336091946, 'reg_lambda': 0.01232910415374743}, 'Best Learner': 'lgbm', 'Best Hyper-parameters': {'n_estimators': 11, 'num_leaves': 53, 'min_child_samples': 33, 'learning_rate': 0.10638311711134216, 'log_max_bin': 8, 'colsample_bytree': 0.9504814804454289, 'reg_alpha': 0.0023411461336091946, 'reg_lambda': 0.01232910415374743}}\n",
            "{'Current Learner': 'lgbm', 'Current Sample': 6283, 'Current Hyper-parameters': {'n_estimators': 33, 'num_leaves': 28, 'min_child_samples': 49, 'learning_rate': 0.07219223346014582, 'log_max_bin': 9, 'colsample_bytree': 0.8632054869229117, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.004662880494997406}, 'Best Learner': 'lgbm', 'Best Hyper-parameters': {'n_estimators': 33, 'num_leaves': 28, 'min_child_samples': 49, 'learning_rate': 0.07219223346014582, 'log_max_bin': 9, 'colsample_bytree': 0.8632054869229117, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.004662880494997406}}\n",
            "{'Current Learner': 'lgbm', 'Current Sample': 6283, 'Current Hyper-parameters': {'n_estimators': 49, 'num_leaves': 24, 'min_child_samples': 126, 'learning_rate': 0.05129608013305185, 'log_max_bin': 9, 'colsample_bytree': 0.7479283884351631, 'reg_alpha': 0.0018291617742641451, 'reg_lambda': 0.001420292799258414}, 'Best Learner': 'lgbm', 'Best Hyper-parameters': {'n_estimators': 49, 'num_leaves': 24, 'min_child_samples': 126, 'learning_rate': 0.05129608013305185, 'log_max_bin': 9, 'colsample_bytree': 0.7479283884351631, 'reg_alpha': 0.0018291617742641451, 'reg_lambda': 0.001420292799258414}}\n",
            "{'Current Learner': 'lgbm', 'Current Sample': 6283, 'Current Hyper-parameters': {'n_estimators': 52, 'num_leaves': 11, 'min_child_samples': 93, 'learning_rate': 0.13906138125808948, 'log_max_bin': 8, 'colsample_bytree': 0.9022102592823722, 'reg_alpha': 0.00405473040064328, 'reg_lambda': 0.0019142031668109981}, 'Best Learner': 'lgbm', 'Best Hyper-parameters': {'n_estimators': 52, 'num_leaves': 11, 'min_child_samples': 93, 'learning_rate': 0.13906138125808948, 'log_max_bin': 8, 'colsample_bytree': 0.9022102592823722, 'reg_alpha': 0.00405473040064328, 'reg_lambda': 0.0019142031668109981}}\n",
            "{'Current Learner': 'lgbm', 'Current Sample': 6283, 'Current Hyper-parameters': {'n_estimators': 210, 'num_leaves': 27, 'min_child_samples': 101, 'learning_rate': 0.05869313565418056, 'log_max_bin': 9, 'colsample_bytree': 0.9284938408452321, 'reg_alpha': 0.006035818587147279, 'reg_lambda': 0.0009765625}, 'Best Learner': 'lgbm', 'Best Hyper-parameters': {'n_estimators': 210, 'num_leaves': 27, 'min_child_samples': 101, 'learning_rate': 0.05869313565418056, 'log_max_bin': 9, 'colsample_bytree': 0.9284938408452321, 'reg_alpha': 0.006035818587147279, 'reg_lambda': 0.0009765625}}\n",
            "{'Current Learner': 'lgbm', 'Current Sample': 6283, 'Current Hyper-parameters': {'n_estimators': 70, 'num_leaves': 32, 'min_child_samples': 119, 'learning_rate': 0.1305053207928878, 'log_max_bin': 8, 'colsample_bytree': 1.0, 'reg_alpha': 0.006654851923923542, 'reg_lambda': 0.002124411209590999}, 'Best Learner': 'lgbm', 'Best Hyper-parameters': {'n_estimators': 70, 'num_leaves': 32, 'min_child_samples': 119, 'learning_rate': 0.1305053207928878, 'log_max_bin': 8, 'colsample_bytree': 1.0, 'reg_alpha': 0.006654851923923542, 'reg_lambda': 0.002124411209590999}}\n",
            "{'Current Learner': 'lgbm', 'Current Sample': 6283, 'Current Hyper-parameters': {'n_estimators': 211, 'num_leaves': 27, 'min_child_samples': 101, 'learning_rate': 0.05869313565418051, 'log_max_bin': 8, 'colsample_bytree': 0.8104443262964631, 'reg_alpha': 0.006035818587147279, 'reg_lambda': 0.0009765625}, 'Best Learner': 'lgbm', 'Best Hyper-parameters': {'n_estimators': 211, 'num_leaves': 27, 'min_child_samples': 101, 'learning_rate': 0.05869313565418051, 'log_max_bin': 8, 'colsample_bytree': 0.8104443262964631, 'reg_alpha': 0.006035818587147279, 'reg_lambda': 0.0009765625}}\n",
            "{'Current Learner': 'lgbm', 'Current Sample': 6283, 'Current Hyper-parameters': {'n_estimators': 383, 'num_leaves': 148, 'min_child_samples': 81, 'learning_rate': 0.07349456601711642, 'log_max_bin': 9, 'colsample_bytree': 0.7945324135347446, 'reg_alpha': 0.0038090040724731134, 'reg_lambda': 0.0027820040646453358}, 'Best Learner': 'lgbm', 'Best Hyper-parameters': {'n_estimators': 383, 'num_leaves': 148, 'min_child_samples': 81, 'learning_rate': 0.07349456601711642, 'log_max_bin': 9, 'colsample_bytree': 0.7945324135347446, 'reg_alpha': 0.0038090040724731134, 'reg_lambda': 0.0027820040646453358}}\n"
          ]
        }
      ],
      "source": [
        "from flaml.data import get_output_from_log\n",
        "time_history, best_valid_loss_history, valid_loss_history, config_history, metric_history = \\\n",
        "    get_output_from_log(filename=settings['log_file_name'], time_budget=240)\n",
        "for config in config_history:\n",
        "    print(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3570ab7c",
      "metadata": {
        "id": "3570ab7c",
        "outputId": "4b1e942a-eec5-45fa-e244-36778acbc0b4"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "plt.title('Learning Curve')\n",
        "plt.xlabel('Wall Clock Time (s)')\n",
        "plt.ylabel('Validation Accuracy')\n",
        "plt.scatter(time_history, 1 - np.array(valid_loss_history))\n",
        "plt.step(time_history, 1 - np.array(best_valid_loss_history), where='post')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c2b6e33",
      "metadata": {
        "id": "1c2b6e33"
      },
      "outputs": [],
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "lgbm = LGBMClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe602ea9",
      "metadata": {
        "id": "fe602ea9",
        "outputId": "df53ff58-2250-4b83-fe79-0ceb384eca4f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LGBMClassifier()"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lgbm.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "330ce537",
      "metadata": {
        "id": "330ce537"
      },
      "outputs": [],
      "source": [
        "y_pred_lgbm = lgbm.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4e84429",
      "metadata": {
        "id": "d4e84429"
      },
      "outputs": [],
      "source": [
        "from xgboost import XGBClassifier\n",
        "xgb = XGBClassifier()\n",
        "cat_columns = X_train.select_dtypes(include=['category']).columns\n",
        "X = X_train.copy()\n",
        "X[cat_columns] = X[cat_columns].apply(lambda x: x.cat.codes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4cdc1bce",
      "metadata": {
        "id": "4cdc1bce"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder = label_encoder.fit(y_train)\n",
        "y_train = label_encoder.transform(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80f59e28",
      "metadata": {
        "id": "80f59e28",
        "outputId": "86fa0c11-4ce7-4c64-f992-f22a54cf4597"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
              "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
              "              early_stopping_rounds=None, enable_categorical=False,\n",
              "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
              "              importance_type=None, interaction_constraints='',\n",
              "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
              "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
              "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
              "              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=0,\n",
              "              reg_alpha=0, reg_lambda=1, ...)"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "xgb.fit(X, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c43e152a",
      "metadata": {
        "id": "c43e152a"
      },
      "outputs": [],
      "source": [
        "X = X_test.copy()\n",
        "X[cat_columns] = X[cat_columns].apply(lambda x: x.cat.codes)\n",
        "y_pred_xgb = xgb.predict(X)\n",
        "#label_encoded_y_test = label_encoder.transform(y_pred_xgb)\n",
        "#y_pred_xgb = label_encoder.transform(y_pred_xgb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dac4d447",
      "metadata": {
        "id": "dac4d447"
      },
      "outputs": [],
      "source": [
        "y_test = [int(x) for x in np.array(y_test)]\n",
        "y_pred_lgbm = [int(x) for x in np.array(y_pred_lgbm)]\n",
        "y_pred = [int(x) for x in np.array(y_pred)]\n",
        "# print(np.array(y_pred_xgb))\n",
        "# print(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7dbfb27",
      "metadata": {
        "id": "d7dbfb27"
      },
      "outputs": [],
      "source": [
        "from catboost import CatBoostClassifier, Pool\n",
        "cat = CatBoostClassifier()\n",
        "X_train = X_train.apply(lambda x: x.fillna(x.value_counts().index[0]))\n",
        "pool_train = Pool(X_train, y_train,\n",
        "                 cat_features = ['samerace', 'has_null', 'gender', 'd_d_age', 'race', 'race_o', 'd_importance_same_race', 'd_importance_same_religion', 'field', 'd_pref_o_attractive', 'd_pref_o_sincere', 'd_pref_o_intelligence', 'd_pref_o_funny', 'd_pref_o_ambitious', 'd_pref_o_shared_interests', 'd_attractive_o', 'd_sinsere_o', 'd_intelligence_o', 'd_funny_o', 'd_ambitous_o', 'd_shared_interests_o', 'd_attractive_important', 'd_sincere_important', 'd_intellicence_important', 'd_funny_important', 'd_ambtition_important', 'd_shared_interests_important', 'd_attractive', 'd_sincere', 'd_intelligence', 'd_funny', 'd_ambition', 'd_attractive_partner', 'd_sincere_partner', 'd_intelligence_partner', 'd_funny_partner', 'd_ambition_partner', 'd_shared_interests_partner', 'd_sports', 'd_tvsports', 'd_exercise', 'd_dining', 'd_museums', 'd_art', 'd_hiking', 'd_gaming', 'd_clubbing', 'd_reading', 'd_tv', 'd_theater', 'd_movies', 'd_concerts', 'd_music', 'd_shopping', 'd_yoga', 'd_interests_correlate', 'd_expected_happy_with_sd_people', 'd_expected_num_interested_in_me', 'd_expected_num_matches', 'd_like', 'd_guess_prob_liked'])\n",
        "#pool_train = Pool(X_train, y_train,\n",
        "                # cat_features = ['has_null, gender, d_d_age, race, race_o'])    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be5999c1",
      "metadata": {
        "id": "be5999c1"
      },
      "outputs": [],
      "source": [
        "X_test = X_test.apply(lambda x: x.fillna(x.value_counts().index[0]))\n",
        "y_pred_cat = cat.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "084bda9e",
      "metadata": {
        "id": "084bda9e"
      },
      "outputs": [],
      "source": [
        "##X_train['has_null'] = X_train['has_null'].astype(str)\n",
        "#X_train['gender'] = X_train['gender'].astype(str)\n",
        "#X_train['race'] = X_train['race'].astype(str)\n",
        "#X_train['race_o'] = X_train['race_o'].astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91a5d728",
      "metadata": {
        "id": "91a5d728",
        "outputId": "277d7442-8e14-4859-f9a9-6864f835f948"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Learning rate set to 0.022581\n",
            "0:\tlearn: 0.6767318\ttotal: 16.7ms\tremaining: 16.7s\n",
            "1:\tlearn: 0.6604394\ttotal: 88.2ms\tremaining: 44s\n",
            "2:\tlearn: 0.6444996\ttotal: 166ms\tremaining: 55.3s\n",
            "3:\tlearn: 0.6271804\ttotal: 241ms\tremaining: 59.9s\n",
            "4:\tlearn: 0.6136201\ttotal: 330ms\tremaining: 1m 5s\n",
            "5:\tlearn: 0.5979485\ttotal: 392ms\tremaining: 1m 4s\n",
            "6:\tlearn: 0.5834228\ttotal: 476ms\tremaining: 1m 7s\n",
            "7:\tlearn: 0.5710384\ttotal: 559ms\tremaining: 1m 9s\n",
            "8:\tlearn: 0.5598423\ttotal: 610ms\tremaining: 1m 7s\n",
            "9:\tlearn: 0.5491349\ttotal: 693ms\tremaining: 1m 8s\n",
            "10:\tlearn: 0.5376392\ttotal: 763ms\tremaining: 1m 8s\n",
            "11:\tlearn: 0.5281121\ttotal: 848ms\tremaining: 1m 9s\n",
            "12:\tlearn: 0.5185099\ttotal: 927ms\tremaining: 1m 10s\n",
            "13:\tlearn: 0.5110905\ttotal: 988ms\tremaining: 1m 9s\n",
            "14:\tlearn: 0.5023732\ttotal: 1.06s\tremaining: 1m 9s\n",
            "15:\tlearn: 0.4935596\ttotal: 1.14s\tremaining: 1m 10s\n",
            "16:\tlearn: 0.4849720\ttotal: 1.23s\tremaining: 1m 11s\n",
            "17:\tlearn: 0.4793515\ttotal: 1.3s\tremaining: 1m 11s\n",
            "18:\tlearn: 0.4731174\ttotal: 1.38s\tremaining: 1m 11s\n",
            "19:\tlearn: 0.4658219\ttotal: 1.44s\tremaining: 1m 10s\n",
            "20:\tlearn: 0.4593880\ttotal: 1.51s\tremaining: 1m 10s\n",
            "21:\tlearn: 0.4529375\ttotal: 1.59s\tremaining: 1m 10s\n",
            "22:\tlearn: 0.4471023\ttotal: 1.66s\tremaining: 1m 10s\n",
            "23:\tlearn: 0.4413487\ttotal: 1.75s\tremaining: 1m 11s\n",
            "24:\tlearn: 0.4362898\ttotal: 1.81s\tremaining: 1m 10s\n",
            "25:\tlearn: 0.4319560\ttotal: 1.86s\tremaining: 1m 9s\n",
            "26:\tlearn: 0.4270907\ttotal: 1.93s\tremaining: 1m 9s\n",
            "27:\tlearn: 0.4228555\ttotal: 1.99s\tremaining: 1m 9s\n",
            "28:\tlearn: 0.4185898\ttotal: 2.07s\tremaining: 1m 9s\n",
            "29:\tlearn: 0.4144237\ttotal: 2.12s\tremaining: 1m 8s\n",
            "30:\tlearn: 0.4106096\ttotal: 2.2s\tremaining: 1m 8s\n",
            "31:\tlearn: 0.4074138\ttotal: 2.27s\tremaining: 1m 8s\n",
            "32:\tlearn: 0.4042558\ttotal: 2.3s\tremaining: 1m 7s\n",
            "33:\tlearn: 0.4001874\ttotal: 2.37s\tremaining: 1m 7s\n",
            "34:\tlearn: 0.3975822\ttotal: 2.41s\tremaining: 1m 6s\n",
            "35:\tlearn: 0.3941400\ttotal: 2.47s\tremaining: 1m 6s\n",
            "36:\tlearn: 0.3917438\ttotal: 2.5s\tremaining: 1m 5s\n",
            "37:\tlearn: 0.3884749\ttotal: 2.57s\tremaining: 1m 5s\n",
            "38:\tlearn: 0.3854942\ttotal: 2.62s\tremaining: 1m 4s\n",
            "39:\tlearn: 0.3826747\ttotal: 2.7s\tremaining: 1m 4s\n",
            "40:\tlearn: 0.3799936\ttotal: 2.77s\tremaining: 1m 4s\n",
            "41:\tlearn: 0.3779530\ttotal: 2.84s\tremaining: 1m 4s\n",
            "42:\tlearn: 0.3756334\ttotal: 2.92s\tremaining: 1m 4s\n",
            "43:\tlearn: 0.3739222\ttotal: 2.97s\tremaining: 1m 4s\n",
            "44:\tlearn: 0.3719245\ttotal: 3.03s\tremaining: 1m 4s\n",
            "45:\tlearn: 0.3696286\ttotal: 3.1s\tremaining: 1m 4s\n",
            "46:\tlearn: 0.3671831\ttotal: 3.17s\tremaining: 1m 4s\n",
            "47:\tlearn: 0.3659588\ttotal: 3.19s\tremaining: 1m 3s\n",
            "48:\tlearn: 0.3642880\ttotal: 3.27s\tremaining: 1m 3s\n",
            "49:\tlearn: 0.3623788\ttotal: 3.35s\tremaining: 1m 3s\n",
            "50:\tlearn: 0.3609122\ttotal: 3.41s\tremaining: 1m 3s\n",
            "51:\tlearn: 0.3593112\ttotal: 3.48s\tremaining: 1m 3s\n",
            "52:\tlearn: 0.3577715\ttotal: 3.55s\tremaining: 1m 3s\n",
            "53:\tlearn: 0.3565755\ttotal: 3.62s\tremaining: 1m 3s\n",
            "54:\tlearn: 0.3554510\ttotal: 3.66s\tremaining: 1m 2s\n",
            "55:\tlearn: 0.3539318\ttotal: 3.74s\tremaining: 1m 3s\n",
            "56:\tlearn: 0.3525301\ttotal: 3.8s\tremaining: 1m 2s\n",
            "57:\tlearn: 0.3516426\ttotal: 3.85s\tremaining: 1m 2s\n",
            "58:\tlearn: 0.3504412\ttotal: 3.92s\tremaining: 1m 2s\n",
            "59:\tlearn: 0.3488585\ttotal: 3.99s\tremaining: 1m 2s\n",
            "60:\tlearn: 0.3479336\ttotal: 4.02s\tremaining: 1m 1s\n",
            "61:\tlearn: 0.3465210\ttotal: 4.08s\tremaining: 1m 1s\n",
            "62:\tlearn: 0.3460956\ttotal: 4.11s\tremaining: 1m 1s\n",
            "63:\tlearn: 0.3453558\ttotal: 4.14s\tremaining: 1m\n",
            "64:\tlearn: 0.3441371\ttotal: 4.22s\tremaining: 1m\n",
            "65:\tlearn: 0.3431535\ttotal: 4.29s\tremaining: 1m\n",
            "66:\tlearn: 0.3421069\ttotal: 4.36s\tremaining: 1m\n",
            "67:\tlearn: 0.3411695\ttotal: 4.45s\tremaining: 1m\n",
            "68:\tlearn: 0.3402901\ttotal: 4.51s\tremaining: 1m\n",
            "69:\tlearn: 0.3390295\ttotal: 4.58s\tremaining: 1m\n",
            "70:\tlearn: 0.3382535\ttotal: 4.65s\tremaining: 1m\n",
            "71:\tlearn: 0.3376183\ttotal: 4.73s\tremaining: 1m 1s\n",
            "72:\tlearn: 0.3365017\ttotal: 4.82s\tremaining: 1m 1s\n",
            "73:\tlearn: 0.3357605\ttotal: 4.89s\tremaining: 1m 1s\n",
            "74:\tlearn: 0.3348117\ttotal: 4.97s\tremaining: 1m 1s\n",
            "75:\tlearn: 0.3343849\ttotal: 5.01s\tremaining: 1m\n",
            "76:\tlearn: 0.3335234\ttotal: 5.08s\tremaining: 1m\n",
            "77:\tlearn: 0.3328070\ttotal: 5.17s\tremaining: 1m 1s\n",
            "78:\tlearn: 0.3319089\ttotal: 5.25s\tremaining: 1m 1s\n",
            "79:\tlearn: 0.3312333\ttotal: 5.33s\tremaining: 1m 1s\n",
            "80:\tlearn: 0.3304364\ttotal: 5.42s\tremaining: 1m 1s\n",
            "81:\tlearn: 0.3297751\ttotal: 5.49s\tremaining: 1m 1s\n",
            "82:\tlearn: 0.3294418\ttotal: 5.57s\tremaining: 1m 1s\n",
            "83:\tlearn: 0.3288076\ttotal: 5.62s\tremaining: 1m 1s\n",
            "84:\tlearn: 0.3282682\ttotal: 5.69s\tremaining: 1m 1s\n",
            "85:\tlearn: 0.3274645\ttotal: 5.76s\tremaining: 1m 1s\n",
            "86:\tlearn: 0.3267684\ttotal: 5.83s\tremaining: 1m 1s\n",
            "87:\tlearn: 0.3261529\ttotal: 5.9s\tremaining: 1m 1s\n",
            "88:\tlearn: 0.3255162\ttotal: 5.97s\tremaining: 1m 1s\n",
            "89:\tlearn: 0.3249147\ttotal: 6.04s\tremaining: 1m 1s\n",
            "90:\tlearn: 0.3243401\ttotal: 6.12s\tremaining: 1m 1s\n",
            "91:\tlearn: 0.3239928\ttotal: 6.16s\tremaining: 1m\n",
            "92:\tlearn: 0.3234652\ttotal: 6.25s\tremaining: 1m 1s\n",
            "93:\tlearn: 0.3229115\ttotal: 6.34s\tremaining: 1m 1s\n",
            "94:\tlearn: 0.3226257\ttotal: 6.39s\tremaining: 1m\n",
            "95:\tlearn: 0.3222834\ttotal: 6.46s\tremaining: 1m\n",
            "96:\tlearn: 0.3218784\ttotal: 6.54s\tremaining: 1m\n",
            "97:\tlearn: 0.3213376\ttotal: 6.61s\tremaining: 1m\n",
            "98:\tlearn: 0.3209766\ttotal: 6.67s\tremaining: 1m\n",
            "99:\tlearn: 0.3203870\ttotal: 6.75s\tremaining: 1m\n",
            "100:\tlearn: 0.3197158\ttotal: 6.82s\tremaining: 1m\n",
            "101:\tlearn: 0.3191465\ttotal: 6.91s\tremaining: 1m\n",
            "102:\tlearn: 0.3186841\ttotal: 6.98s\tremaining: 1m\n",
            "103:\tlearn: 0.3184664\ttotal: 7.04s\tremaining: 1m\n",
            "104:\tlearn: 0.3181020\ttotal: 7.12s\tremaining: 1m\n",
            "105:\tlearn: 0.3174396\ttotal: 7.19s\tremaining: 1m\n",
            "106:\tlearn: 0.3171175\ttotal: 7.28s\tremaining: 1m\n",
            "107:\tlearn: 0.3167349\ttotal: 7.35s\tremaining: 1m\n",
            "108:\tlearn: 0.3164282\ttotal: 7.43s\tremaining: 1m\n",
            "109:\tlearn: 0.3160221\ttotal: 7.5s\tremaining: 1m\n",
            "110:\tlearn: 0.3156468\ttotal: 7.57s\tremaining: 1m\n",
            "111:\tlearn: 0.3154389\ttotal: 7.6s\tremaining: 1m\n",
            "112:\tlearn: 0.3152192\ttotal: 7.65s\tremaining: 1m\n",
            "113:\tlearn: 0.3149444\ttotal: 7.73s\tremaining: 1m\n",
            "114:\tlearn: 0.3145553\ttotal: 7.8s\tremaining: 1m\n",
            "115:\tlearn: 0.3141743\ttotal: 7.88s\tremaining: 1m\n",
            "116:\tlearn: 0.3137287\ttotal: 7.95s\tremaining: 60s\n",
            "117:\tlearn: 0.3132725\ttotal: 8.03s\tremaining: 1m\n",
            "118:\tlearn: 0.3130670\ttotal: 8.1s\tremaining: 59.9s\n",
            "119:\tlearn: 0.3126233\ttotal: 8.17s\tremaining: 59.9s\n",
            "120:\tlearn: 0.3123757\ttotal: 8.26s\tremaining: 1m\n",
            "121:\tlearn: 0.3119420\ttotal: 8.34s\tremaining: 1m\n",
            "122:\tlearn: 0.3115352\ttotal: 8.43s\tremaining: 1m\n",
            "123:\tlearn: 0.3112243\ttotal: 8.51s\tremaining: 1m\n",
            "124:\tlearn: 0.3109151\ttotal: 8.58s\tremaining: 1m\n",
            "125:\tlearn: 0.3106574\ttotal: 8.65s\tremaining: 60s\n",
            "126:\tlearn: 0.3103827\ttotal: 8.73s\tremaining: 60s\n",
            "127:\tlearn: 0.3101376\ttotal: 8.8s\tremaining: 60s\n",
            "128:\tlearn: 0.3099990\ttotal: 8.89s\tremaining: 1m\n",
            "129:\tlearn: 0.3096034\ttotal: 8.96s\tremaining: 1m\n",
            "130:\tlearn: 0.3091709\ttotal: 9.03s\tremaining: 59.9s\n",
            "131:\tlearn: 0.3088518\ttotal: 9.11s\tremaining: 59.9s\n",
            "132:\tlearn: 0.3085846\ttotal: 9.19s\tremaining: 59.9s\n",
            "133:\tlearn: 0.3082343\ttotal: 9.27s\tremaining: 59.9s\n",
            "134:\tlearn: 0.3078789\ttotal: 9.35s\tremaining: 59.9s\n",
            "135:\tlearn: 0.3075709\ttotal: 9.43s\tremaining: 59.9s\n",
            "136:\tlearn: 0.3072561\ttotal: 9.51s\tremaining: 59.9s\n",
            "137:\tlearn: 0.3069631\ttotal: 9.59s\tremaining: 59.9s\n",
            "138:\tlearn: 0.3067832\ttotal: 9.69s\tremaining: 60s\n",
            "139:\tlearn: 0.3064537\ttotal: 9.78s\tremaining: 1m\n",
            "140:\tlearn: 0.3060034\ttotal: 9.86s\tremaining: 1m\n",
            "141:\tlearn: 0.3057305\ttotal: 9.94s\tremaining: 1m\n",
            "142:\tlearn: 0.3054917\ttotal: 10s\tremaining: 1m\n",
            "143:\tlearn: 0.3050189\ttotal: 10.1s\tremaining: 1m\n",
            "144:\tlearn: 0.3050184\ttotal: 10.1s\tremaining: 59.7s\n",
            "145:\tlearn: 0.3047365\ttotal: 10.2s\tremaining: 59.7s\n",
            "146:\tlearn: 0.3046308\ttotal: 10.3s\tremaining: 59.6s\n",
            "147:\tlearn: 0.3044872\ttotal: 10.4s\tremaining: 59.6s\n",
            "148:\tlearn: 0.3042575\ttotal: 10.4s\tremaining: 59.6s\n",
            "149:\tlearn: 0.3041588\ttotal: 10.5s\tremaining: 59.4s\n",
            "150:\tlearn: 0.3040187\ttotal: 10.6s\tremaining: 59.4s\n",
            "151:\tlearn: 0.3038233\ttotal: 10.6s\tremaining: 59.4s\n",
            "152:\tlearn: 0.3036065\ttotal: 10.7s\tremaining: 59.4s\n",
            "153:\tlearn: 0.3033365\ttotal: 10.8s\tremaining: 59.3s\n",
            "154:\tlearn: 0.3030943\ttotal: 10.9s\tremaining: 59.3s\n",
            "155:\tlearn: 0.3028079\ttotal: 10.9s\tremaining: 59.2s\n",
            "156:\tlearn: 0.3023679\ttotal: 11s\tremaining: 59.1s\n",
            "157:\tlearn: 0.3022041\ttotal: 11.1s\tremaining: 59s\n",
            "158:\tlearn: 0.3019343\ttotal: 11.1s\tremaining: 58.9s\n",
            "159:\tlearn: 0.3013981\ttotal: 11.2s\tremaining: 58.8s\n",
            "160:\tlearn: 0.3013174\ttotal: 11.2s\tremaining: 58.5s\n",
            "161:\tlearn: 0.3012055\ttotal: 11.3s\tremaining: 58.5s\n",
            "162:\tlearn: 0.3010808\ttotal: 11.4s\tremaining: 58.4s\n",
            "163:\tlearn: 0.3009142\ttotal: 11.5s\tremaining: 58.4s\n",
            "164:\tlearn: 0.3006794\ttotal: 11.5s\tremaining: 58.4s\n",
            "165:\tlearn: 0.3004498\ttotal: 11.6s\tremaining: 58.4s\n",
            "166:\tlearn: 0.3001564\ttotal: 11.7s\tremaining: 58.3s\n",
            "167:\tlearn: 0.2999017\ttotal: 11.8s\tremaining: 58.2s\n",
            "168:\tlearn: 0.2997003\ttotal: 11.8s\tremaining: 58.2s\n",
            "169:\tlearn: 0.2995260\ttotal: 11.9s\tremaining: 58.1s\n",
            "170:\tlearn: 0.2990993\ttotal: 12s\tremaining: 58.1s\n",
            "171:\tlearn: 0.2990867\ttotal: 12s\tremaining: 57.8s\n",
            "172:\tlearn: 0.2989016\ttotal: 12.1s\tremaining: 57.8s\n",
            "173:\tlearn: 0.2986736\ttotal: 12.2s\tremaining: 57.7s\n",
            "174:\tlearn: 0.2986116\ttotal: 12.2s\tremaining: 57.5s\n",
            "175:\tlearn: 0.2983823\ttotal: 12.3s\tremaining: 57.4s\n",
            "176:\tlearn: 0.2980846\ttotal: 12.3s\tremaining: 57.3s\n",
            "177:\tlearn: 0.2978035\ttotal: 12.4s\tremaining: 57.3s\n",
            "178:\tlearn: 0.2975945\ttotal: 12.5s\tremaining: 57.3s\n",
            "179:\tlearn: 0.2973604\ttotal: 12.6s\tremaining: 57.2s\n",
            "180:\tlearn: 0.2971747\ttotal: 12.6s\tremaining: 57.2s\n",
            "181:\tlearn: 0.2966604\ttotal: 12.7s\tremaining: 57.1s\n",
            "182:\tlearn: 0.2965119\ttotal: 12.8s\tremaining: 57.1s\n",
            "183:\tlearn: 0.2963451\ttotal: 12.9s\tremaining: 57s\n",
            "184:\tlearn: 0.2961895\ttotal: 12.9s\tremaining: 56.9s\n",
            "185:\tlearn: 0.2957993\ttotal: 13s\tremaining: 56.8s\n",
            "186:\tlearn: 0.2956446\ttotal: 13.1s\tremaining: 56.8s\n",
            "187:\tlearn: 0.2953851\ttotal: 13.1s\tremaining: 56.7s\n",
            "188:\tlearn: 0.2951942\ttotal: 13.2s\tremaining: 56.7s\n",
            "189:\tlearn: 0.2949451\ttotal: 13.3s\tremaining: 56.6s\n",
            "190:\tlearn: 0.2948008\ttotal: 13.4s\tremaining: 56.6s\n",
            "191:\tlearn: 0.2946265\ttotal: 13.4s\tremaining: 56.5s\n",
            "192:\tlearn: 0.2944944\ttotal: 13.5s\tremaining: 56.4s\n",
            "193:\tlearn: 0.2941520\ttotal: 13.6s\tremaining: 56.4s\n",
            "194:\tlearn: 0.2940275\ttotal: 13.6s\tremaining: 56.3s\n",
            "195:\tlearn: 0.2937594\ttotal: 13.7s\tremaining: 56.2s\n",
            "196:\tlearn: 0.2936016\ttotal: 13.8s\tremaining: 56.1s\n",
            "197:\tlearn: 0.2934323\ttotal: 13.8s\tremaining: 56s\n",
            "198:\tlearn: 0.2932812\ttotal: 13.9s\tremaining: 56s\n",
            "199:\tlearn: 0.2928942\ttotal: 14s\tremaining: 55.9s\n",
            "200:\tlearn: 0.2927812\ttotal: 14s\tremaining: 55.8s\n",
            "201:\tlearn: 0.2925787\ttotal: 14.1s\tremaining: 55.7s\n",
            "202:\tlearn: 0.2923460\ttotal: 14.2s\tremaining: 55.7s\n",
            "203:\tlearn: 0.2919446\ttotal: 14.3s\tremaining: 55.6s\n",
            "204:\tlearn: 0.2916075\ttotal: 14.3s\tremaining: 55.5s\n",
            "205:\tlearn: 0.2915271\ttotal: 14.4s\tremaining: 55.4s\n",
            "206:\tlearn: 0.2913185\ttotal: 14.5s\tremaining: 55.4s\n",
            "207:\tlearn: 0.2911410\ttotal: 14.5s\tremaining: 55.3s\n",
            "208:\tlearn: 0.2908251\ttotal: 14.6s\tremaining: 55.3s\n",
            "209:\tlearn: 0.2906238\ttotal: 14.7s\tremaining: 55.2s\n",
            "210:\tlearn: 0.2904761\ttotal: 14.7s\tremaining: 55.1s\n",
            "211:\tlearn: 0.2903741\ttotal: 14.8s\tremaining: 55.1s\n",
            "212:\tlearn: 0.2902403\ttotal: 14.9s\tremaining: 55s\n",
            "213:\tlearn: 0.2901366\ttotal: 15s\tremaining: 54.9s\n",
            "214:\tlearn: 0.2899550\ttotal: 15s\tremaining: 54.9s\n",
            "215:\tlearn: 0.2899547\ttotal: 15.1s\tremaining: 54.7s\n",
            "216:\tlearn: 0.2897403\ttotal: 15.1s\tremaining: 54.6s\n",
            "217:\tlearn: 0.2896932\ttotal: 15.2s\tremaining: 54.6s\n",
            "218:\tlearn: 0.2895250\ttotal: 15.3s\tremaining: 54.5s\n",
            "219:\tlearn: 0.2892273\ttotal: 15.4s\tremaining: 54.5s\n",
            "220:\tlearn: 0.2891518\ttotal: 15.4s\tremaining: 54.4s\n",
            "221:\tlearn: 0.2889373\ttotal: 15.5s\tremaining: 54.4s\n",
            "222:\tlearn: 0.2886927\ttotal: 15.6s\tremaining: 54.3s\n",
            "223:\tlearn: 0.2883648\ttotal: 15.6s\tremaining: 54.2s\n",
            "224:\tlearn: 0.2882053\ttotal: 15.7s\tremaining: 54.1s\n",
            "225:\tlearn: 0.2880587\ttotal: 15.8s\tremaining: 54s\n",
            "226:\tlearn: 0.2877810\ttotal: 15.8s\tremaining: 54s\n",
            "227:\tlearn: 0.2875594\ttotal: 15.9s\tremaining: 54s\n",
            "228:\tlearn: 0.2873003\ttotal: 16s\tremaining: 53.9s\n",
            "229:\tlearn: 0.2871013\ttotal: 16.1s\tremaining: 53.8s\n",
            "230:\tlearn: 0.2869452\ttotal: 16.1s\tremaining: 53.8s\n",
            "231:\tlearn: 0.2868795\ttotal: 16.2s\tremaining: 53.7s\n",
            "232:\tlearn: 0.2867760\ttotal: 16.3s\tremaining: 53.6s\n",
            "233:\tlearn: 0.2866281\ttotal: 16.4s\tremaining: 53.6s\n",
            "234:\tlearn: 0.2864850\ttotal: 16.4s\tremaining: 53.5s\n",
            "235:\tlearn: 0.2864055\ttotal: 16.5s\tremaining: 53.4s\n",
            "236:\tlearn: 0.2862962\ttotal: 16.6s\tremaining: 53.4s\n",
            "237:\tlearn: 0.2862245\ttotal: 16.6s\tremaining: 53.3s\n",
            "238:\tlearn: 0.2860359\ttotal: 16.7s\tremaining: 53.2s\n",
            "239:\tlearn: 0.2859522\ttotal: 16.8s\tremaining: 53.1s\n",
            "240:\tlearn: 0.2859338\ttotal: 16.8s\tremaining: 52.9s\n",
            "241:\tlearn: 0.2858118\ttotal: 16.9s\tremaining: 52.9s\n",
            "242:\tlearn: 0.2857888\ttotal: 16.9s\tremaining: 52.7s\n",
            "243:\tlearn: 0.2856848\ttotal: 17s\tremaining: 52.7s\n",
            "244:\tlearn: 0.2855533\ttotal: 17.1s\tremaining: 52.6s\n",
            "245:\tlearn: 0.2854472\ttotal: 17.2s\tremaining: 52.6s\n",
            "246:\tlearn: 0.2851901\ttotal: 17.2s\tremaining: 52.6s\n",
            "247:\tlearn: 0.2850234\ttotal: 17.3s\tremaining: 52.5s\n",
            "248:\tlearn: 0.2848056\ttotal: 17.4s\tremaining: 52.5s\n",
            "249:\tlearn: 0.2845519\ttotal: 17.5s\tremaining: 52.4s\n",
            "250:\tlearn: 0.2843830\ttotal: 17.5s\tremaining: 52.3s\n",
            "251:\tlearn: 0.2842849\ttotal: 17.6s\tremaining: 52.3s\n",
            "252:\tlearn: 0.2840249\ttotal: 17.7s\tremaining: 52.2s\n",
            "253:\tlearn: 0.2839009\ttotal: 17.8s\tremaining: 52.2s\n",
            "254:\tlearn: 0.2836903\ttotal: 17.8s\tremaining: 52.1s\n",
            "255:\tlearn: 0.2834468\ttotal: 17.9s\tremaining: 52.1s\n",
            "256:\tlearn: 0.2832256\ttotal: 18s\tremaining: 52.2s\n",
            "257:\tlearn: 0.2828097\ttotal: 18.1s\tremaining: 52.1s\n",
            "258:\tlearn: 0.2826227\ttotal: 18.2s\tremaining: 52s\n",
            "259:\tlearn: 0.2825815\ttotal: 18.3s\tremaining: 52s\n",
            "260:\tlearn: 0.2823821\ttotal: 18.3s\tremaining: 52s\n",
            "261:\tlearn: 0.2822118\ttotal: 18.4s\tremaining: 52s\n",
            "262:\tlearn: 0.2821163\ttotal: 18.5s\tremaining: 51.9s\n",
            "263:\tlearn: 0.2819207\ttotal: 18.6s\tremaining: 51.9s\n",
            "264:\tlearn: 0.2817985\ttotal: 18.7s\tremaining: 51.8s\n",
            "265:\tlearn: 0.2816357\ttotal: 18.7s\tremaining: 51.7s\n",
            "266:\tlearn: 0.2814711\ttotal: 18.8s\tremaining: 51.6s\n",
            "267:\tlearn: 0.2814462\ttotal: 18.9s\tremaining: 51.6s\n",
            "268:\tlearn: 0.2813171\ttotal: 18.9s\tremaining: 51.5s\n",
            "269:\tlearn: 0.2811394\ttotal: 19s\tremaining: 51.4s\n",
            "270:\tlearn: 0.2810094\ttotal: 19.1s\tremaining: 51.4s\n",
            "271:\tlearn: 0.2809361\ttotal: 19.2s\tremaining: 51.3s\n",
            "272:\tlearn: 0.2806754\ttotal: 19.3s\tremaining: 51.3s\n",
            "273:\tlearn: 0.2804584\ttotal: 19.3s\tremaining: 51.2s\n",
            "274:\tlearn: 0.2802747\ttotal: 19.4s\tremaining: 51.2s\n",
            "275:\tlearn: 0.2801968\ttotal: 19.5s\tremaining: 51.1s\n",
            "276:\tlearn: 0.2800943\ttotal: 19.6s\tremaining: 51s\n",
            "277:\tlearn: 0.2798856\ttotal: 19.6s\tremaining: 51s\n",
            "278:\tlearn: 0.2796429\ttotal: 19.7s\tremaining: 50.9s\n",
            "279:\tlearn: 0.2793520\ttotal: 19.8s\tremaining: 50.8s\n",
            "280:\tlearn: 0.2792600\ttotal: 19.9s\tremaining: 50.8s\n",
            "281:\tlearn: 0.2790707\ttotal: 19.9s\tremaining: 50.8s\n",
            "282:\tlearn: 0.2789643\ttotal: 20s\tremaining: 50.7s\n",
            "283:\tlearn: 0.2788143\ttotal: 20.1s\tremaining: 50.6s\n",
            "284:\tlearn: 0.2787085\ttotal: 20.1s\tremaining: 50.5s\n",
            "285:\tlearn: 0.2785200\ttotal: 20.2s\tremaining: 50.5s\n",
            "286:\tlearn: 0.2783745\ttotal: 20.3s\tremaining: 50.4s\n",
            "287:\tlearn: 0.2782976\ttotal: 20.4s\tremaining: 50.4s\n",
            "288:\tlearn: 0.2780746\ttotal: 20.5s\tremaining: 50.3s\n",
            "289:\tlearn: 0.2779073\ttotal: 20.5s\tremaining: 50.3s\n",
            "290:\tlearn: 0.2777373\ttotal: 20.6s\tremaining: 50.2s\n",
            "291:\tlearn: 0.2776718\ttotal: 20.7s\tremaining: 50.2s\n",
            "292:\tlearn: 0.2775210\ttotal: 20.8s\tremaining: 50.1s\n",
            "293:\tlearn: 0.2773067\ttotal: 20.9s\tremaining: 50.1s\n",
            "294:\tlearn: 0.2771311\ttotal: 20.9s\tremaining: 50s\n",
            "295:\tlearn: 0.2770048\ttotal: 21s\tremaining: 49.9s\n",
            "296:\tlearn: 0.2769889\ttotal: 21s\tremaining: 49.8s\n",
            "297:\tlearn: 0.2769539\ttotal: 21.1s\tremaining: 49.7s\n",
            "298:\tlearn: 0.2768215\ttotal: 21.2s\tremaining: 49.6s\n",
            "299:\tlearn: 0.2766678\ttotal: 21.2s\tremaining: 49.6s\n",
            "300:\tlearn: 0.2764855\ttotal: 21.3s\tremaining: 49.5s\n",
            "301:\tlearn: 0.2763902\ttotal: 21.4s\tremaining: 49.4s\n",
            "302:\tlearn: 0.2762586\ttotal: 21.5s\tremaining: 49.4s\n",
            "303:\tlearn: 0.2760806\ttotal: 21.5s\tremaining: 49.3s\n",
            "304:\tlearn: 0.2759780\ttotal: 21.6s\tremaining: 49.2s\n",
            "305:\tlearn: 0.2759168\ttotal: 21.7s\tremaining: 49.1s\n",
            "306:\tlearn: 0.2758398\ttotal: 21.7s\tremaining: 49.1s\n",
            "307:\tlearn: 0.2756509\ttotal: 21.8s\tremaining: 49s\n",
            "308:\tlearn: 0.2753611\ttotal: 21.9s\tremaining: 49s\n",
            "309:\tlearn: 0.2752690\ttotal: 22s\tremaining: 48.9s\n",
            "310:\tlearn: 0.2751356\ttotal: 22s\tremaining: 48.8s\n",
            "311:\tlearn: 0.2749518\ttotal: 22.1s\tremaining: 48.8s\n",
            "312:\tlearn: 0.2749159\ttotal: 22.2s\tremaining: 48.6s\n",
            "313:\tlearn: 0.2747687\ttotal: 22.2s\tremaining: 48.6s\n",
            "314:\tlearn: 0.2745728\ttotal: 22.3s\tremaining: 48.5s\n",
            "315:\tlearn: 0.2744843\ttotal: 22.4s\tremaining: 48.4s\n",
            "316:\tlearn: 0.2743087\ttotal: 22.5s\tremaining: 48.4s\n",
            "317:\tlearn: 0.2741889\ttotal: 22.5s\tremaining: 48.3s\n",
            "318:\tlearn: 0.2740934\ttotal: 22.6s\tremaining: 48.3s\n",
            "319:\tlearn: 0.2739944\ttotal: 22.7s\tremaining: 48.2s\n",
            "320:\tlearn: 0.2738576\ttotal: 22.8s\tremaining: 48.1s\n",
            "321:\tlearn: 0.2736863\ttotal: 22.8s\tremaining: 48.1s\n",
            "322:\tlearn: 0.2735189\ttotal: 22.9s\tremaining: 48.1s\n",
            "323:\tlearn: 0.2732143\ttotal: 23s\tremaining: 48s\n",
            "324:\tlearn: 0.2731054\ttotal: 23.1s\tremaining: 47.9s\n",
            "325:\tlearn: 0.2728173\ttotal: 23.1s\tremaining: 47.9s\n",
            "326:\tlearn: 0.2727536\ttotal: 23.2s\tremaining: 47.8s\n",
            "327:\tlearn: 0.2725189\ttotal: 23.3s\tremaining: 47.7s\n",
            "328:\tlearn: 0.2724620\ttotal: 23.4s\tremaining: 47.7s\n",
            "329:\tlearn: 0.2723728\ttotal: 23.4s\tremaining: 47.6s\n",
            "330:\tlearn: 0.2722485\ttotal: 23.5s\tremaining: 47.5s\n",
            "331:\tlearn: 0.2720841\ttotal: 23.6s\tremaining: 47.5s\n",
            "332:\tlearn: 0.2719939\ttotal: 23.7s\tremaining: 47.4s\n",
            "333:\tlearn: 0.2719163\ttotal: 23.7s\tremaining: 47.3s\n",
            "334:\tlearn: 0.2718075\ttotal: 23.8s\tremaining: 47.2s\n",
            "335:\tlearn: 0.2717315\ttotal: 23.9s\tremaining: 47.2s\n",
            "336:\tlearn: 0.2715997\ttotal: 24s\tremaining: 47.1s\n",
            "337:\tlearn: 0.2713672\ttotal: 24s\tremaining: 47.1s\n",
            "338:\tlearn: 0.2711988\ttotal: 24.1s\tremaining: 47s\n",
            "339:\tlearn: 0.2709965\ttotal: 24.2s\tremaining: 46.9s\n",
            "340:\tlearn: 0.2708395\ttotal: 24.3s\tremaining: 46.9s\n",
            "341:\tlearn: 0.2706806\ttotal: 24.3s\tremaining: 46.8s\n",
            "342:\tlearn: 0.2705588\ttotal: 24.4s\tremaining: 46.8s\n",
            "343:\tlearn: 0.2704105\ttotal: 24.5s\tremaining: 46.7s\n",
            "344:\tlearn: 0.2702436\ttotal: 24.6s\tremaining: 46.6s\n",
            "345:\tlearn: 0.2700363\ttotal: 24.6s\tremaining: 46.6s\n",
            "346:\tlearn: 0.2700015\ttotal: 24.7s\tremaining: 46.5s\n",
            "347:\tlearn: 0.2697960\ttotal: 24.8s\tremaining: 46.4s\n",
            "348:\tlearn: 0.2696503\ttotal: 24.8s\tremaining: 46.3s\n",
            "349:\tlearn: 0.2694472\ttotal: 24.9s\tremaining: 46.3s\n",
            "350:\tlearn: 0.2692765\ttotal: 25s\tremaining: 46.2s\n",
            "351:\tlearn: 0.2691865\ttotal: 25.1s\tremaining: 46.2s\n",
            "352:\tlearn: 0.2690543\ttotal: 25.2s\tremaining: 46.1s\n",
            "353:\tlearn: 0.2688142\ttotal: 25.2s\tremaining: 46.1s\n",
            "354:\tlearn: 0.2686526\ttotal: 25.3s\tremaining: 46s\n",
            "355:\tlearn: 0.2685927\ttotal: 25.4s\tremaining: 46s\n",
            "356:\tlearn: 0.2684242\ttotal: 25.5s\tremaining: 45.9s\n",
            "357:\tlearn: 0.2683232\ttotal: 25.6s\tremaining: 45.9s\n",
            "358:\tlearn: 0.2681737\ttotal: 25.7s\tremaining: 45.9s\n",
            "359:\tlearn: 0.2679874\ttotal: 25.8s\tremaining: 45.8s\n",
            "360:\tlearn: 0.2677836\ttotal: 25.8s\tremaining: 45.7s\n",
            "361:\tlearn: 0.2676151\ttotal: 25.9s\tremaining: 45.7s\n",
            "362:\tlearn: 0.2674950\ttotal: 26s\tremaining: 45.6s\n",
            "363:\tlearn: 0.2673375\ttotal: 26.1s\tremaining: 45.6s\n",
            "364:\tlearn: 0.2672468\ttotal: 26.2s\tremaining: 45.5s\n",
            "365:\tlearn: 0.2672465\ttotal: 26.2s\tremaining: 45.4s\n",
            "366:\tlearn: 0.2672216\ttotal: 26.2s\tremaining: 45.3s\n",
            "367:\tlearn: 0.2670635\ttotal: 26.3s\tremaining: 45.2s\n",
            "368:\tlearn: 0.2669013\ttotal: 26.4s\tremaining: 45.1s\n",
            "369:\tlearn: 0.2667050\ttotal: 26.5s\tremaining: 45.1s\n",
            "370:\tlearn: 0.2665070\ttotal: 26.5s\tremaining: 45s\n",
            "371:\tlearn: 0.2663090\ttotal: 26.6s\tremaining: 45s\n",
            "372:\tlearn: 0.2662586\ttotal: 26.7s\tremaining: 44.9s\n",
            "373:\tlearn: 0.2661509\ttotal: 26.8s\tremaining: 44.9s\n",
            "374:\tlearn: 0.2658261\ttotal: 26.9s\tremaining: 44.8s\n",
            "375:\tlearn: 0.2655799\ttotal: 27s\tremaining: 44.7s\n",
            "376:\tlearn: 0.2654019\ttotal: 27s\tremaining: 44.7s\n",
            "377:\tlearn: 0.2652486\ttotal: 27.1s\tremaining: 44.6s\n",
            "378:\tlearn: 0.2650946\ttotal: 27.2s\tremaining: 44.6s\n",
            "379:\tlearn: 0.2649880\ttotal: 27.3s\tremaining: 44.5s\n",
            "380:\tlearn: 0.2648924\ttotal: 27.4s\tremaining: 44.4s\n",
            "381:\tlearn: 0.2647460\ttotal: 27.4s\tremaining: 44.4s\n",
            "382:\tlearn: 0.2645748\ttotal: 27.5s\tremaining: 44.3s\n",
            "383:\tlearn: 0.2644415\ttotal: 27.6s\tremaining: 44.3s\n",
            "384:\tlearn: 0.2642637\ttotal: 27.7s\tremaining: 44.3s\n",
            "385:\tlearn: 0.2642039\ttotal: 27.8s\tremaining: 44.2s\n",
            "386:\tlearn: 0.2640792\ttotal: 27.9s\tremaining: 44.2s\n",
            "387:\tlearn: 0.2637617\ttotal: 28s\tremaining: 44.1s\n",
            "388:\tlearn: 0.2637108\ttotal: 28s\tremaining: 44.1s\n",
            "389:\tlearn: 0.2634223\ttotal: 28.1s\tremaining: 44s\n",
            "390:\tlearn: 0.2632959\ttotal: 28.2s\tremaining: 43.9s\n",
            "391:\tlearn: 0.2631397\ttotal: 28.3s\tremaining: 43.8s\n",
            "392:\tlearn: 0.2629956\ttotal: 28.3s\tremaining: 43.8s\n",
            "393:\tlearn: 0.2628341\ttotal: 28.4s\tremaining: 43.7s\n",
            "394:\tlearn: 0.2627497\ttotal: 28.5s\tremaining: 43.6s\n",
            "395:\tlearn: 0.2626242\ttotal: 28.6s\tremaining: 43.6s\n",
            "396:\tlearn: 0.2625336\ttotal: 28.6s\tremaining: 43.5s\n",
            "397:\tlearn: 0.2624260\ttotal: 28.7s\tremaining: 43.5s\n",
            "398:\tlearn: 0.2622886\ttotal: 28.8s\tremaining: 43.4s\n",
            "399:\tlearn: 0.2621288\ttotal: 28.9s\tremaining: 43.3s\n",
            "400:\tlearn: 0.2619709\ttotal: 29s\tremaining: 43.3s\n",
            "401:\tlearn: 0.2617623\ttotal: 29s\tremaining: 43.2s\n",
            "402:\tlearn: 0.2615993\ttotal: 29.1s\tremaining: 43.1s\n",
            "403:\tlearn: 0.2612970\ttotal: 29.2s\tremaining: 43s\n",
            "404:\tlearn: 0.2611288\ttotal: 29.2s\tremaining: 43s\n",
            "405:\tlearn: 0.2610412\ttotal: 29.3s\tremaining: 42.9s\n",
            "406:\tlearn: 0.2608390\ttotal: 29.4s\tremaining: 42.8s\n",
            "407:\tlearn: 0.2607237\ttotal: 29.5s\tremaining: 42.7s\n",
            "408:\tlearn: 0.2605002\ttotal: 29.5s\tremaining: 42.7s\n",
            "409:\tlearn: 0.2602426\ttotal: 29.6s\tremaining: 42.6s\n",
            "410:\tlearn: 0.2599783\ttotal: 29.7s\tremaining: 42.5s\n",
            "411:\tlearn: 0.2598390\ttotal: 29.8s\tremaining: 42.5s\n",
            "412:\tlearn: 0.2597424\ttotal: 29.8s\tremaining: 42.4s\n",
            "413:\tlearn: 0.2596350\ttotal: 29.9s\tremaining: 42.3s\n",
            "414:\tlearn: 0.2595293\ttotal: 30s\tremaining: 42.3s\n",
            "415:\tlearn: 0.2593142\ttotal: 30s\tremaining: 42.2s\n",
            "416:\tlearn: 0.2590824\ttotal: 30.1s\tremaining: 42.1s\n",
            "417:\tlearn: 0.2587771\ttotal: 30.2s\tremaining: 42s\n",
            "418:\tlearn: 0.2585812\ttotal: 30.3s\tremaining: 42s\n",
            "419:\tlearn: 0.2583554\ttotal: 30.3s\tremaining: 41.9s\n",
            "420:\tlearn: 0.2582658\ttotal: 30.4s\tremaining: 41.8s\n",
            "421:\tlearn: 0.2581066\ttotal: 30.5s\tremaining: 41.8s\n",
            "422:\tlearn: 0.2580386\ttotal: 30.6s\tremaining: 41.7s\n",
            "423:\tlearn: 0.2578760\ttotal: 30.6s\tremaining: 41.6s\n",
            "424:\tlearn: 0.2577621\ttotal: 30.7s\tremaining: 41.5s\n",
            "425:\tlearn: 0.2576324\ttotal: 30.8s\tremaining: 41.5s\n",
            "426:\tlearn: 0.2574894\ttotal: 30.8s\tremaining: 41.4s\n",
            "427:\tlearn: 0.2573858\ttotal: 30.9s\tremaining: 41.3s\n",
            "428:\tlearn: 0.2573162\ttotal: 31s\tremaining: 41.2s\n",
            "429:\tlearn: 0.2571678\ttotal: 31.1s\tremaining: 41.2s\n",
            "430:\tlearn: 0.2570943\ttotal: 31.1s\tremaining: 41.1s\n",
            "431:\tlearn: 0.2570627\ttotal: 31.2s\tremaining: 41s\n",
            "432:\tlearn: 0.2569672\ttotal: 31.3s\tremaining: 41s\n",
            "433:\tlearn: 0.2569544\ttotal: 31.4s\tremaining: 40.9s\n",
            "434:\tlearn: 0.2568680\ttotal: 31.4s\tremaining: 40.8s\n",
            "435:\tlearn: 0.2567118\ttotal: 31.5s\tremaining: 40.7s\n",
            "436:\tlearn: 0.2567039\ttotal: 31.6s\tremaining: 40.7s\n",
            "437:\tlearn: 0.2566313\ttotal: 31.6s\tremaining: 40.6s\n",
            "438:\tlearn: 0.2565176\ttotal: 31.7s\tremaining: 40.5s\n",
            "439:\tlearn: 0.2563902\ttotal: 31.8s\tremaining: 40.5s\n",
            "440:\tlearn: 0.2562642\ttotal: 31.9s\tremaining: 40.4s\n",
            "441:\tlearn: 0.2561506\ttotal: 31.9s\tremaining: 40.3s\n",
            "442:\tlearn: 0.2560209\ttotal: 32s\tremaining: 40.3s\n",
            "443:\tlearn: 0.2558599\ttotal: 32.1s\tremaining: 40.2s\n",
            "444:\tlearn: 0.2556210\ttotal: 32.2s\tremaining: 40.1s\n",
            "445:\tlearn: 0.2555337\ttotal: 32.2s\tremaining: 40s\n",
            "446:\tlearn: 0.2554656\ttotal: 32.3s\tremaining: 40s\n",
            "447:\tlearn: 0.2553201\ttotal: 32.4s\tremaining: 39.9s\n",
            "448:\tlearn: 0.2551008\ttotal: 32.4s\tremaining: 39.8s\n",
            "449:\tlearn: 0.2549188\ttotal: 32.5s\tremaining: 39.7s\n",
            "450:\tlearn: 0.2548615\ttotal: 32.6s\tremaining: 39.6s\n",
            "451:\tlearn: 0.2547514\ttotal: 32.6s\tremaining: 39.6s\n",
            "452:\tlearn: 0.2546593\ttotal: 32.7s\tremaining: 39.5s\n",
            "453:\tlearn: 0.2545864\ttotal: 32.8s\tremaining: 39.4s\n",
            "454:\tlearn: 0.2544244\ttotal: 32.8s\tremaining: 39.3s\n",
            "455:\tlearn: 0.2543952\ttotal: 32.9s\tremaining: 39.3s\n",
            "456:\tlearn: 0.2543562\ttotal: 33s\tremaining: 39.2s\n",
            "457:\tlearn: 0.2542164\ttotal: 33.1s\tremaining: 39.1s\n",
            "458:\tlearn: 0.2540962\ttotal: 33.1s\tremaining: 39.1s\n",
            "459:\tlearn: 0.2539554\ttotal: 33.2s\tremaining: 39s\n",
            "460:\tlearn: 0.2538493\ttotal: 33.3s\tremaining: 38.9s\n",
            "461:\tlearn: 0.2537349\ttotal: 33.4s\tremaining: 38.9s\n",
            "462:\tlearn: 0.2536138\ttotal: 33.4s\tremaining: 38.8s\n",
            "463:\tlearn: 0.2533528\ttotal: 33.5s\tremaining: 38.7s\n",
            "464:\tlearn: 0.2531888\ttotal: 33.6s\tremaining: 38.6s\n",
            "465:\tlearn: 0.2530808\ttotal: 33.7s\tremaining: 38.6s\n",
            "466:\tlearn: 0.2530363\ttotal: 33.7s\tremaining: 38.5s\n",
            "467:\tlearn: 0.2529431\ttotal: 33.8s\tremaining: 38.4s\n",
            "468:\tlearn: 0.2528570\ttotal: 33.9s\tremaining: 38.4s\n",
            "469:\tlearn: 0.2527273\ttotal: 34s\tremaining: 38.3s\n",
            "470:\tlearn: 0.2526714\ttotal: 34s\tremaining: 38.2s\n",
            "471:\tlearn: 0.2525279\ttotal: 34.1s\tremaining: 38.2s\n",
            "472:\tlearn: 0.2524417\ttotal: 34.2s\tremaining: 38.1s\n",
            "473:\tlearn: 0.2521657\ttotal: 34.3s\tremaining: 38s\n",
            "474:\tlearn: 0.2519352\ttotal: 34.3s\tremaining: 37.9s\n",
            "475:\tlearn: 0.2516694\ttotal: 34.4s\tremaining: 37.9s\n",
            "476:\tlearn: 0.2515449\ttotal: 34.5s\tremaining: 37.8s\n",
            "477:\tlearn: 0.2513789\ttotal: 34.5s\tremaining: 37.7s\n",
            "478:\tlearn: 0.2513208\ttotal: 34.6s\tremaining: 37.7s\n",
            "479:\tlearn: 0.2512512\ttotal: 34.7s\tremaining: 37.6s\n",
            "480:\tlearn: 0.2510040\ttotal: 34.7s\tremaining: 37.5s\n",
            "481:\tlearn: 0.2508945\ttotal: 34.8s\tremaining: 37.4s\n",
            "482:\tlearn: 0.2507469\ttotal: 34.9s\tremaining: 37.3s\n",
            "483:\tlearn: 0.2505803\ttotal: 35s\tremaining: 37.3s\n",
            "484:\tlearn: 0.2505173\ttotal: 35s\tremaining: 37.2s\n",
            "485:\tlearn: 0.2503823\ttotal: 35.1s\tremaining: 37.1s\n",
            "486:\tlearn: 0.2502297\ttotal: 35.2s\tremaining: 37.1s\n",
            "487:\tlearn: 0.2500154\ttotal: 35.3s\tremaining: 37s\n",
            "488:\tlearn: 0.2497795\ttotal: 35.3s\tremaining: 36.9s\n",
            "489:\tlearn: 0.2495454\ttotal: 35.4s\tremaining: 36.8s\n",
            "490:\tlearn: 0.2494554\ttotal: 35.5s\tremaining: 36.8s\n",
            "491:\tlearn: 0.2493429\ttotal: 35.6s\tremaining: 36.7s\n",
            "492:\tlearn: 0.2492769\ttotal: 35.6s\tremaining: 36.6s\n",
            "493:\tlearn: 0.2491481\ttotal: 35.7s\tremaining: 36.6s\n",
            "494:\tlearn: 0.2490714\ttotal: 35.8s\tremaining: 36.5s\n",
            "495:\tlearn: 0.2489601\ttotal: 35.8s\tremaining: 36.4s\n",
            "496:\tlearn: 0.2488820\ttotal: 35.9s\tremaining: 36.3s\n",
            "497:\tlearn: 0.2487187\ttotal: 36s\tremaining: 36.3s\n",
            "498:\tlearn: 0.2486707\ttotal: 36s\tremaining: 36.2s\n",
            "499:\tlearn: 0.2485014\ttotal: 36.1s\tremaining: 36.1s\n",
            "500:\tlearn: 0.2483904\ttotal: 36.2s\tremaining: 36s\n",
            "501:\tlearn: 0.2482964\ttotal: 36.3s\tremaining: 36s\n",
            "502:\tlearn: 0.2482210\ttotal: 36.3s\tremaining: 35.9s\n",
            "503:\tlearn: 0.2481691\ttotal: 36.4s\tremaining: 35.8s\n",
            "504:\tlearn: 0.2480398\ttotal: 36.5s\tremaining: 35.8s\n",
            "505:\tlearn: 0.2479456\ttotal: 36.6s\tremaining: 35.7s\n",
            "506:\tlearn: 0.2477046\ttotal: 36.7s\tremaining: 35.7s\n",
            "507:\tlearn: 0.2473526\ttotal: 36.8s\tremaining: 35.6s\n",
            "508:\tlearn: 0.2469960\ttotal: 36.9s\tremaining: 35.6s\n",
            "509:\tlearn: 0.2469049\ttotal: 37s\tremaining: 35.5s\n",
            "510:\tlearn: 0.2468522\ttotal: 37s\tremaining: 35.4s\n",
            "511:\tlearn: 0.2467881\ttotal: 37.1s\tremaining: 35.4s\n",
            "512:\tlearn: 0.2465662\ttotal: 37.2s\tremaining: 35.3s\n",
            "513:\tlearn: 0.2464787\ttotal: 37.3s\tremaining: 35.2s\n",
            "514:\tlearn: 0.2463842\ttotal: 37.3s\tremaining: 35.2s\n",
            "515:\tlearn: 0.2462585\ttotal: 37.4s\tremaining: 35.1s\n",
            "516:\tlearn: 0.2460686\ttotal: 37.5s\tremaining: 35s\n",
            "517:\tlearn: 0.2459870\ttotal: 37.5s\tremaining: 34.9s\n",
            "518:\tlearn: 0.2457632\ttotal: 37.6s\tremaining: 34.9s\n",
            "519:\tlearn: 0.2457055\ttotal: 37.7s\tremaining: 34.8s\n",
            "520:\tlearn: 0.2455776\ttotal: 37.8s\tremaining: 34.7s\n",
            "521:\tlearn: 0.2455515\ttotal: 37.8s\tremaining: 34.6s\n",
            "522:\tlearn: 0.2454772\ttotal: 37.9s\tremaining: 34.6s\n",
            "523:\tlearn: 0.2453485\ttotal: 38s\tremaining: 34.5s\n",
            "524:\tlearn: 0.2452340\ttotal: 38.1s\tremaining: 34.5s\n",
            "525:\tlearn: 0.2451289\ttotal: 38.2s\tremaining: 34.4s\n",
            "526:\tlearn: 0.2450070\ttotal: 38.2s\tremaining: 34.3s\n",
            "527:\tlearn: 0.2449464\ttotal: 38.3s\tremaining: 34.2s\n",
            "528:\tlearn: 0.2447863\ttotal: 38.4s\tremaining: 34.2s\n",
            "529:\tlearn: 0.2446912\ttotal: 38.5s\tremaining: 34.1s\n",
            "530:\tlearn: 0.2446117\ttotal: 38.5s\tremaining: 34s\n",
            "531:\tlearn: 0.2444763\ttotal: 38.6s\tremaining: 34s\n",
            "532:\tlearn: 0.2442725\ttotal: 38.7s\tremaining: 33.9s\n",
            "533:\tlearn: 0.2440761\ttotal: 38.8s\tremaining: 33.8s\n",
            "534:\tlearn: 0.2439598\ttotal: 38.8s\tremaining: 33.8s\n",
            "535:\tlearn: 0.2438888\ttotal: 38.9s\tremaining: 33.7s\n",
            "536:\tlearn: 0.2438147\ttotal: 39s\tremaining: 33.6s\n",
            "537:\tlearn: 0.2437431\ttotal: 39s\tremaining: 33.5s\n",
            "538:\tlearn: 0.2436058\ttotal: 39.1s\tremaining: 33.5s\n",
            "539:\tlearn: 0.2434622\ttotal: 39.2s\tremaining: 33.4s\n",
            "540:\tlearn: 0.2431982\ttotal: 39.3s\tremaining: 33.3s\n",
            "541:\tlearn: 0.2430380\ttotal: 39.3s\tremaining: 33.2s\n",
            "542:\tlearn: 0.2429612\ttotal: 39.4s\tremaining: 33.2s\n",
            "543:\tlearn: 0.2427775\ttotal: 39.5s\tremaining: 33.1s\n",
            "544:\tlearn: 0.2426103\ttotal: 39.6s\tremaining: 33s\n",
            "545:\tlearn: 0.2424678\ttotal: 39.6s\tremaining: 32.9s\n",
            "546:\tlearn: 0.2423437\ttotal: 39.7s\tremaining: 32.9s\n",
            "547:\tlearn: 0.2422404\ttotal: 39.8s\tremaining: 32.8s\n",
            "548:\tlearn: 0.2420854\ttotal: 39.8s\tremaining: 32.7s\n",
            "549:\tlearn: 0.2420112\ttotal: 39.9s\tremaining: 32.6s\n",
            "550:\tlearn: 0.2418268\ttotal: 40s\tremaining: 32.6s\n",
            "551:\tlearn: 0.2417942\ttotal: 40.1s\tremaining: 32.5s\n",
            "552:\tlearn: 0.2417399\ttotal: 40.1s\tremaining: 32.5s\n",
            "553:\tlearn: 0.2416093\ttotal: 40.2s\tremaining: 32.4s\n",
            "554:\tlearn: 0.2415918\ttotal: 40.3s\tremaining: 32.3s\n",
            "555:\tlearn: 0.2414501\ttotal: 40.4s\tremaining: 32.3s\n",
            "556:\tlearn: 0.2411534\ttotal: 40.5s\tremaining: 32.2s\n",
            "557:\tlearn: 0.2409685\ttotal: 40.6s\tremaining: 32.1s\n",
            "558:\tlearn: 0.2408044\ttotal: 40.7s\tremaining: 32.1s\n",
            "559:\tlearn: 0.2406364\ttotal: 40.7s\tremaining: 32s\n",
            "560:\tlearn: 0.2404328\ttotal: 40.8s\tremaining: 31.9s\n",
            "561:\tlearn: 0.2402487\ttotal: 40.9s\tremaining: 31.9s\n",
            "562:\tlearn: 0.2402086\ttotal: 41s\tremaining: 31.8s\n",
            "563:\tlearn: 0.2400948\ttotal: 41.1s\tremaining: 31.8s\n",
            "564:\tlearn: 0.2399930\ttotal: 41.2s\tremaining: 31.7s\n",
            "565:\tlearn: 0.2398198\ttotal: 41.2s\tremaining: 31.6s\n",
            "566:\tlearn: 0.2397459\ttotal: 41.3s\tremaining: 31.5s\n",
            "567:\tlearn: 0.2396410\ttotal: 41.4s\tremaining: 31.5s\n",
            "568:\tlearn: 0.2395173\ttotal: 41.5s\tremaining: 31.4s\n",
            "569:\tlearn: 0.2393136\ttotal: 41.6s\tremaining: 31.3s\n",
            "570:\tlearn: 0.2390450\ttotal: 41.6s\tremaining: 31.3s\n",
            "571:\tlearn: 0.2389758\ttotal: 41.7s\tremaining: 31.2s\n",
            "572:\tlearn: 0.2388814\ttotal: 41.8s\tremaining: 31.2s\n",
            "573:\tlearn: 0.2387929\ttotal: 41.9s\tremaining: 31.1s\n",
            "574:\tlearn: 0.2386947\ttotal: 42s\tremaining: 31s\n",
            "575:\tlearn: 0.2385746\ttotal: 42.1s\tremaining: 31s\n",
            "576:\tlearn: 0.2385416\ttotal: 42.1s\tremaining: 30.9s\n",
            "577:\tlearn: 0.2383788\ttotal: 42.2s\tremaining: 30.8s\n",
            "578:\tlearn: 0.2382826\ttotal: 42.3s\tremaining: 30.8s\n",
            "579:\tlearn: 0.2381950\ttotal: 42.4s\tremaining: 30.7s\n",
            "580:\tlearn: 0.2381083\ttotal: 42.5s\tremaining: 30.6s\n",
            "581:\tlearn: 0.2379938\ttotal: 42.5s\tremaining: 30.6s\n",
            "582:\tlearn: 0.2379389\ttotal: 42.6s\tremaining: 30.5s\n",
            "583:\tlearn: 0.2376974\ttotal: 42.7s\tremaining: 30.4s\n",
            "584:\tlearn: 0.2375546\ttotal: 42.8s\tremaining: 30.3s\n",
            "585:\tlearn: 0.2374296\ttotal: 42.8s\tremaining: 30.3s\n",
            "586:\tlearn: 0.2372705\ttotal: 42.9s\tremaining: 30.2s\n",
            "587:\tlearn: 0.2371453\ttotal: 43s\tremaining: 30.1s\n",
            "588:\tlearn: 0.2370732\ttotal: 43s\tremaining: 30s\n",
            "589:\tlearn: 0.2369691\ttotal: 43.1s\tremaining: 30s\n",
            "590:\tlearn: 0.2368858\ttotal: 43.2s\tremaining: 29.9s\n",
            "591:\tlearn: 0.2367910\ttotal: 43.2s\tremaining: 29.8s\n",
            "592:\tlearn: 0.2366664\ttotal: 43.3s\tremaining: 29.7s\n",
            "593:\tlearn: 0.2365480\ttotal: 43.4s\tremaining: 29.6s\n",
            "594:\tlearn: 0.2362632\ttotal: 43.4s\tremaining: 29.6s\n",
            "595:\tlearn: 0.2361517\ttotal: 43.5s\tremaining: 29.5s\n",
            "596:\tlearn: 0.2360428\ttotal: 43.6s\tremaining: 29.4s\n",
            "597:\tlearn: 0.2357140\ttotal: 43.6s\tremaining: 29.3s\n",
            "598:\tlearn: 0.2356743\ttotal: 43.7s\tremaining: 29.3s\n",
            "599:\tlearn: 0.2355338\ttotal: 43.8s\tremaining: 29.2s\n",
            "600:\tlearn: 0.2354295\ttotal: 43.9s\tremaining: 29.1s\n",
            "601:\tlearn: 0.2353910\ttotal: 43.9s\tremaining: 29s\n",
            "602:\tlearn: 0.2353602\ttotal: 44s\tremaining: 29s\n",
            "603:\tlearn: 0.2352426\ttotal: 44.1s\tremaining: 28.9s\n",
            "604:\tlearn: 0.2351251\ttotal: 44.1s\tremaining: 28.8s\n",
            "605:\tlearn: 0.2348214\ttotal: 44.2s\tremaining: 28.7s\n",
            "606:\tlearn: 0.2347570\ttotal: 44.3s\tremaining: 28.7s\n",
            "607:\tlearn: 0.2346839\ttotal: 44.3s\tremaining: 28.6s\n",
            "608:\tlearn: 0.2346227\ttotal: 44.4s\tremaining: 28.5s\n",
            "609:\tlearn: 0.2345043\ttotal: 44.5s\tremaining: 28.4s\n",
            "610:\tlearn: 0.2344675\ttotal: 44.6s\tremaining: 28.4s\n",
            "611:\tlearn: 0.2343169\ttotal: 44.6s\tremaining: 28.3s\n",
            "612:\tlearn: 0.2341522\ttotal: 44.7s\tremaining: 28.2s\n",
            "613:\tlearn: 0.2340218\ttotal: 44.8s\tremaining: 28.2s\n",
            "614:\tlearn: 0.2339454\ttotal: 44.8s\tremaining: 28.1s\n",
            "615:\tlearn: 0.2338625\ttotal: 44.9s\tremaining: 28s\n",
            "616:\tlearn: 0.2337571\ttotal: 45s\tremaining: 27.9s\n",
            "617:\tlearn: 0.2336588\ttotal: 45.1s\tremaining: 27.9s\n",
            "618:\tlearn: 0.2335709\ttotal: 45.2s\tremaining: 27.8s\n",
            "619:\tlearn: 0.2334546\ttotal: 45.3s\tremaining: 27.7s\n",
            "620:\tlearn: 0.2333202\ttotal: 45.3s\tremaining: 27.7s\n",
            "621:\tlearn: 0.2331892\ttotal: 45.4s\tremaining: 27.6s\n",
            "622:\tlearn: 0.2330284\ttotal: 45.5s\tremaining: 27.5s\n",
            "623:\tlearn: 0.2329332\ttotal: 45.5s\tremaining: 27.4s\n",
            "624:\tlearn: 0.2328871\ttotal: 45.6s\tremaining: 27.4s\n",
            "625:\tlearn: 0.2328411\ttotal: 45.7s\tremaining: 27.3s\n",
            "626:\tlearn: 0.2328059\ttotal: 45.8s\tremaining: 27.2s\n",
            "627:\tlearn: 0.2326519\ttotal: 45.8s\tremaining: 27.1s\n",
            "628:\tlearn: 0.2325550\ttotal: 45.9s\tremaining: 27.1s\n",
            "629:\tlearn: 0.2324385\ttotal: 46s\tremaining: 27s\n",
            "630:\tlearn: 0.2323226\ttotal: 46s\tremaining: 26.9s\n",
            "631:\tlearn: 0.2321346\ttotal: 46.1s\tremaining: 26.8s\n",
            "632:\tlearn: 0.2321014\ttotal: 46.2s\tremaining: 26.8s\n",
            "633:\tlearn: 0.2320195\ttotal: 46.2s\tremaining: 26.7s\n",
            "634:\tlearn: 0.2318918\ttotal: 46.3s\tremaining: 26.6s\n",
            "635:\tlearn: 0.2316619\ttotal: 46.4s\tremaining: 26.5s\n",
            "636:\tlearn: 0.2315263\ttotal: 46.5s\tremaining: 26.5s\n",
            "637:\tlearn: 0.2314554\ttotal: 46.5s\tremaining: 26.4s\n",
            "638:\tlearn: 0.2313663\ttotal: 46.6s\tremaining: 26.3s\n",
            "639:\tlearn: 0.2313293\ttotal: 46.7s\tremaining: 26.2s\n",
            "640:\tlearn: 0.2312304\ttotal: 46.7s\tremaining: 26.2s\n",
            "641:\tlearn: 0.2310851\ttotal: 46.8s\tremaining: 26.1s\n",
            "642:\tlearn: 0.2309623\ttotal: 46.9s\tremaining: 26s\n",
            "643:\tlearn: 0.2307803\ttotal: 47s\tremaining: 26s\n",
            "644:\tlearn: 0.2306484\ttotal: 47s\tremaining: 25.9s\n",
            "645:\tlearn: 0.2304127\ttotal: 47.1s\tremaining: 25.8s\n",
            "646:\tlearn: 0.2303042\ttotal: 47.2s\tremaining: 25.7s\n",
            "647:\tlearn: 0.2302079\ttotal: 47.3s\tremaining: 25.7s\n",
            "648:\tlearn: 0.2301074\ttotal: 47.3s\tremaining: 25.6s\n",
            "649:\tlearn: 0.2300148\ttotal: 47.4s\tremaining: 25.5s\n",
            "650:\tlearn: 0.2298571\ttotal: 47.5s\tremaining: 25.4s\n",
            "651:\tlearn: 0.2297765\ttotal: 47.5s\tremaining: 25.4s\n",
            "652:\tlearn: 0.2296710\ttotal: 47.6s\tremaining: 25.3s\n",
            "653:\tlearn: 0.2295685\ttotal: 47.7s\tremaining: 25.2s\n",
            "654:\tlearn: 0.2294515\ttotal: 47.7s\tremaining: 25.1s\n",
            "655:\tlearn: 0.2293634\ttotal: 47.8s\tremaining: 25.1s\n",
            "656:\tlearn: 0.2292414\ttotal: 47.9s\tremaining: 25s\n",
            "657:\tlearn: 0.2291492\ttotal: 48s\tremaining: 25s\n",
            "658:\tlearn: 0.2289161\ttotal: 48.1s\tremaining: 24.9s\n",
            "659:\tlearn: 0.2288337\ttotal: 48.1s\tremaining: 24.8s\n",
            "660:\tlearn: 0.2287969\ttotal: 48.2s\tremaining: 24.7s\n",
            "661:\tlearn: 0.2287084\ttotal: 48.3s\tremaining: 24.7s\n",
            "662:\tlearn: 0.2283817\ttotal: 48.3s\tremaining: 24.6s\n",
            "663:\tlearn: 0.2281999\ttotal: 48.4s\tremaining: 24.5s\n",
            "664:\tlearn: 0.2280307\ttotal: 48.5s\tremaining: 24.4s\n",
            "665:\tlearn: 0.2279672\ttotal: 48.6s\tremaining: 24.4s\n",
            "666:\tlearn: 0.2278767\ttotal: 48.6s\tremaining: 24.3s\n",
            "667:\tlearn: 0.2278003\ttotal: 48.7s\tremaining: 24.2s\n",
            "668:\tlearn: 0.2275834\ttotal: 48.8s\tremaining: 24.1s\n",
            "669:\tlearn: 0.2274407\ttotal: 48.8s\tremaining: 24.1s\n",
            "670:\tlearn: 0.2274132\ttotal: 48.9s\tremaining: 24s\n",
            "671:\tlearn: 0.2272967\ttotal: 49s\tremaining: 23.9s\n",
            "672:\tlearn: 0.2272161\ttotal: 49.1s\tremaining: 23.8s\n",
            "673:\tlearn: 0.2271237\ttotal: 49.1s\tremaining: 23.8s\n",
            "674:\tlearn: 0.2270668\ttotal: 49.2s\tremaining: 23.7s\n",
            "675:\tlearn: 0.2268865\ttotal: 49.3s\tremaining: 23.6s\n",
            "676:\tlearn: 0.2265508\ttotal: 49.3s\tremaining: 23.5s\n",
            "677:\tlearn: 0.2264060\ttotal: 49.4s\tremaining: 23.5s\n",
            "678:\tlearn: 0.2262844\ttotal: 49.5s\tremaining: 23.4s\n",
            "679:\tlearn: 0.2262272\ttotal: 49.5s\tremaining: 23.3s\n",
            "680:\tlearn: 0.2261082\ttotal: 49.6s\tremaining: 23.2s\n",
            "681:\tlearn: 0.2260110\ttotal: 49.7s\tremaining: 23.2s\n",
            "682:\tlearn: 0.2259186\ttotal: 49.8s\tremaining: 23.1s\n",
            "683:\tlearn: 0.2258949\ttotal: 49.8s\tremaining: 23s\n",
            "684:\tlearn: 0.2258181\ttotal: 49.9s\tremaining: 22.9s\n",
            "685:\tlearn: 0.2258086\ttotal: 50s\tremaining: 22.9s\n",
            "686:\tlearn: 0.2257666\ttotal: 50s\tremaining: 22.8s\n",
            "687:\tlearn: 0.2256917\ttotal: 50.1s\tremaining: 22.7s\n",
            "688:\tlearn: 0.2256126\ttotal: 50.2s\tremaining: 22.7s\n",
            "689:\tlearn: 0.2255661\ttotal: 50.3s\tremaining: 22.6s\n",
            "690:\tlearn: 0.2254143\ttotal: 50.3s\tremaining: 22.5s\n",
            "691:\tlearn: 0.2252446\ttotal: 50.4s\tremaining: 22.4s\n",
            "692:\tlearn: 0.2252006\ttotal: 50.5s\tremaining: 22.4s\n",
            "693:\tlearn: 0.2251324\ttotal: 50.6s\tremaining: 22.3s\n",
            "694:\tlearn: 0.2250653\ttotal: 50.7s\tremaining: 22.2s\n",
            "695:\tlearn: 0.2249997\ttotal: 50.7s\tremaining: 22.2s\n",
            "696:\tlearn: 0.2248286\ttotal: 50.8s\tremaining: 22.1s\n",
            "697:\tlearn: 0.2247257\ttotal: 50.9s\tremaining: 22s\n",
            "698:\tlearn: 0.2246887\ttotal: 51s\tremaining: 21.9s\n",
            "699:\tlearn: 0.2245657\ttotal: 51s\tremaining: 21.9s\n",
            "700:\tlearn: 0.2244001\ttotal: 51.1s\tremaining: 21.8s\n",
            "701:\tlearn: 0.2243631\ttotal: 51.2s\tremaining: 21.7s\n",
            "702:\tlearn: 0.2241591\ttotal: 51.2s\tremaining: 21.6s\n",
            "703:\tlearn: 0.2240361\ttotal: 51.3s\tremaining: 21.6s\n",
            "704:\tlearn: 0.2239506\ttotal: 51.4s\tremaining: 21.5s\n",
            "705:\tlearn: 0.2238496\ttotal: 51.4s\tremaining: 21.4s\n",
            "706:\tlearn: 0.2237358\ttotal: 51.5s\tremaining: 21.3s\n",
            "707:\tlearn: 0.2236900\ttotal: 51.6s\tremaining: 21.3s\n",
            "708:\tlearn: 0.2235886\ttotal: 51.6s\tremaining: 21.2s\n",
            "709:\tlearn: 0.2235155\ttotal: 51.7s\tremaining: 21.1s\n",
            "710:\tlearn: 0.2234782\ttotal: 51.8s\tremaining: 21.1s\n",
            "711:\tlearn: 0.2234079\ttotal: 51.9s\tremaining: 21s\n",
            "712:\tlearn: 0.2232589\ttotal: 52s\tremaining: 20.9s\n",
            "713:\tlearn: 0.2232264\ttotal: 52s\tremaining: 20.8s\n",
            "714:\tlearn: 0.2231306\ttotal: 52.1s\tremaining: 20.8s\n",
            "715:\tlearn: 0.2230146\ttotal: 52.2s\tremaining: 20.7s\n",
            "716:\tlearn: 0.2229355\ttotal: 52.3s\tremaining: 20.6s\n",
            "717:\tlearn: 0.2226135\ttotal: 52.3s\tremaining: 20.6s\n",
            "718:\tlearn: 0.2224928\ttotal: 52.4s\tremaining: 20.5s\n",
            "719:\tlearn: 0.2223154\ttotal: 52.4s\tremaining: 20.4s\n",
            "720:\tlearn: 0.2222689\ttotal: 52.5s\tremaining: 20.3s\n",
            "721:\tlearn: 0.2221698\ttotal: 52.6s\tremaining: 20.2s\n",
            "722:\tlearn: 0.2220675\ttotal: 52.7s\tremaining: 20.2s\n",
            "723:\tlearn: 0.2220332\ttotal: 52.7s\tremaining: 20.1s\n",
            "724:\tlearn: 0.2219966\ttotal: 52.8s\tremaining: 20s\n",
            "725:\tlearn: 0.2218661\ttotal: 52.9s\tremaining: 20s\n",
            "726:\tlearn: 0.2216690\ttotal: 52.9s\tremaining: 19.9s\n",
            "727:\tlearn: 0.2216155\ttotal: 53s\tremaining: 19.8s\n",
            "728:\tlearn: 0.2213451\ttotal: 53.1s\tremaining: 19.7s\n",
            "729:\tlearn: 0.2212397\ttotal: 53.1s\tremaining: 19.7s\n",
            "730:\tlearn: 0.2211822\ttotal: 53.2s\tremaining: 19.6s\n",
            "731:\tlearn: 0.2210732\ttotal: 53.3s\tremaining: 19.5s\n",
            "732:\tlearn: 0.2210041\ttotal: 53.4s\tremaining: 19.4s\n",
            "733:\tlearn: 0.2209436\ttotal: 53.4s\tremaining: 19.4s\n",
            "734:\tlearn: 0.2207769\ttotal: 53.5s\tremaining: 19.3s\n",
            "735:\tlearn: 0.2207483\ttotal: 53.6s\tremaining: 19.2s\n",
            "736:\tlearn: 0.2207126\ttotal: 53.6s\tremaining: 19.1s\n",
            "737:\tlearn: 0.2206184\ttotal: 53.7s\tremaining: 19.1s\n",
            "738:\tlearn: 0.2204301\ttotal: 53.8s\tremaining: 19s\n",
            "739:\tlearn: 0.2203193\ttotal: 53.8s\tremaining: 18.9s\n",
            "740:\tlearn: 0.2202278\ttotal: 53.9s\tremaining: 18.8s\n",
            "741:\tlearn: 0.2201530\ttotal: 54s\tremaining: 18.8s\n",
            "742:\tlearn: 0.2200806\ttotal: 54s\tremaining: 18.7s\n",
            "743:\tlearn: 0.2200001\ttotal: 54.1s\tremaining: 18.6s\n",
            "744:\tlearn: 0.2199093\ttotal: 54.2s\tremaining: 18.5s\n",
            "745:\tlearn: 0.2198366\ttotal: 54.2s\tremaining: 18.5s\n",
            "746:\tlearn: 0.2197841\ttotal: 54.3s\tremaining: 18.4s\n",
            "747:\tlearn: 0.2195272\ttotal: 54.4s\tremaining: 18.3s\n",
            "748:\tlearn: 0.2193605\ttotal: 54.4s\tremaining: 18.2s\n",
            "749:\tlearn: 0.2192940\ttotal: 54.5s\tremaining: 18.2s\n",
            "750:\tlearn: 0.2192699\ttotal: 54.6s\tremaining: 18.1s\n",
            "751:\tlearn: 0.2191361\ttotal: 54.7s\tremaining: 18s\n",
            "752:\tlearn: 0.2190532\ttotal: 54.8s\tremaining: 18s\n",
            "753:\tlearn: 0.2188531\ttotal: 54.8s\tremaining: 17.9s\n",
            "754:\tlearn: 0.2185767\ttotal: 54.9s\tremaining: 17.8s\n",
            "755:\tlearn: 0.2184244\ttotal: 55s\tremaining: 17.7s\n",
            "756:\tlearn: 0.2183393\ttotal: 55s\tremaining: 17.7s\n",
            "757:\tlearn: 0.2183094\ttotal: 55.1s\tremaining: 17.6s\n",
            "758:\tlearn: 0.2182457\ttotal: 55.2s\tremaining: 17.5s\n",
            "759:\tlearn: 0.2181088\ttotal: 55.3s\tremaining: 17.5s\n",
            "760:\tlearn: 0.2180102\ttotal: 55.4s\tremaining: 17.4s\n",
            "761:\tlearn: 0.2179902\ttotal: 55.4s\tremaining: 17.3s\n",
            "762:\tlearn: 0.2179406\ttotal: 55.5s\tremaining: 17.2s\n",
            "763:\tlearn: 0.2178191\ttotal: 55.6s\tremaining: 17.2s\n",
            "764:\tlearn: 0.2177686\ttotal: 55.6s\tremaining: 17.1s\n",
            "765:\tlearn: 0.2176986\ttotal: 55.7s\tremaining: 17s\n",
            "766:\tlearn: 0.2175661\ttotal: 55.8s\tremaining: 17s\n",
            "767:\tlearn: 0.2175035\ttotal: 55.9s\tremaining: 16.9s\n",
            "768:\tlearn: 0.2174367\ttotal: 55.9s\tremaining: 16.8s\n",
            "769:\tlearn: 0.2173071\ttotal: 56s\tremaining: 16.7s\n",
            "770:\tlearn: 0.2172204\ttotal: 56.1s\tremaining: 16.7s\n",
            "771:\tlearn: 0.2171613\ttotal: 56.1s\tremaining: 16.6s\n",
            "772:\tlearn: 0.2171224\ttotal: 56.2s\tremaining: 16.5s\n",
            "773:\tlearn: 0.2170285\ttotal: 56.3s\tremaining: 16.4s\n",
            "774:\tlearn: 0.2167902\ttotal: 56.4s\tremaining: 16.4s\n",
            "775:\tlearn: 0.2166888\ttotal: 56.5s\tremaining: 16.3s\n",
            "776:\tlearn: 0.2165346\ttotal: 56.5s\tremaining: 16.2s\n",
            "777:\tlearn: 0.2164343\ttotal: 56.6s\tremaining: 16.2s\n",
            "778:\tlearn: 0.2163650\ttotal: 56.7s\tremaining: 16.1s\n",
            "779:\tlearn: 0.2162746\ttotal: 56.8s\tremaining: 16s\n",
            "780:\tlearn: 0.2160533\ttotal: 56.8s\tremaining: 15.9s\n",
            "781:\tlearn: 0.2159649\ttotal: 56.9s\tremaining: 15.9s\n",
            "782:\tlearn: 0.2159552\ttotal: 57s\tremaining: 15.8s\n",
            "783:\tlearn: 0.2158599\ttotal: 57s\tremaining: 15.7s\n",
            "784:\tlearn: 0.2156284\ttotal: 57.1s\tremaining: 15.6s\n",
            "785:\tlearn: 0.2155528\ttotal: 57.2s\tremaining: 15.6s\n",
            "786:\tlearn: 0.2155032\ttotal: 57.3s\tremaining: 15.5s\n",
            "787:\tlearn: 0.2154285\ttotal: 57.4s\tremaining: 15.4s\n",
            "788:\tlearn: 0.2152439\ttotal: 57.5s\tremaining: 15.4s\n",
            "789:\tlearn: 0.2151963\ttotal: 57.5s\tremaining: 15.3s\n",
            "790:\tlearn: 0.2151441\ttotal: 57.6s\tremaining: 15.2s\n",
            "791:\tlearn: 0.2150680\ttotal: 57.7s\tremaining: 15.2s\n",
            "792:\tlearn: 0.2149777\ttotal: 57.8s\tremaining: 15.1s\n",
            "793:\tlearn: 0.2148896\ttotal: 57.9s\tremaining: 15s\n",
            "794:\tlearn: 0.2148082\ttotal: 58s\tremaining: 15s\n",
            "795:\tlearn: 0.2147314\ttotal: 58.1s\tremaining: 14.9s\n",
            "796:\tlearn: 0.2146204\ttotal: 58.2s\tremaining: 14.8s\n",
            "797:\tlearn: 0.2145633\ttotal: 58.2s\tremaining: 14.7s\n",
            "798:\tlearn: 0.2144702\ttotal: 58.3s\tremaining: 14.7s\n",
            "799:\tlearn: 0.2142576\ttotal: 58.4s\tremaining: 14.6s\n",
            "800:\tlearn: 0.2142225\ttotal: 58.5s\tremaining: 14.5s\n",
            "801:\tlearn: 0.2141617\ttotal: 58.5s\tremaining: 14.5s\n",
            "802:\tlearn: 0.2139827\ttotal: 58.6s\tremaining: 14.4s\n",
            "803:\tlearn: 0.2138809\ttotal: 58.7s\tremaining: 14.3s\n",
            "804:\tlearn: 0.2137337\ttotal: 58.8s\tremaining: 14.2s\n",
            "805:\tlearn: 0.2136366\ttotal: 58.9s\tremaining: 14.2s\n",
            "806:\tlearn: 0.2135816\ttotal: 58.9s\tremaining: 14.1s\n",
            "807:\tlearn: 0.2134789\ttotal: 59s\tremaining: 14s\n",
            "808:\tlearn: 0.2134043\ttotal: 59.1s\tremaining: 14s\n",
            "809:\tlearn: 0.2133033\ttotal: 59.2s\tremaining: 13.9s\n",
            "810:\tlearn: 0.2131890\ttotal: 59.3s\tremaining: 13.8s\n",
            "811:\tlearn: 0.2130978\ttotal: 59.3s\tremaining: 13.7s\n",
            "812:\tlearn: 0.2130618\ttotal: 59.4s\tremaining: 13.7s\n",
            "813:\tlearn: 0.2129212\ttotal: 59.5s\tremaining: 13.6s\n",
            "814:\tlearn: 0.2126993\ttotal: 59.5s\tremaining: 13.5s\n",
            "815:\tlearn: 0.2126588\ttotal: 59.6s\tremaining: 13.4s\n",
            "816:\tlearn: 0.2125735\ttotal: 59.7s\tremaining: 13.4s\n",
            "817:\tlearn: 0.2124865\ttotal: 59.8s\tremaining: 13.3s\n",
            "818:\tlearn: 0.2124523\ttotal: 59.8s\tremaining: 13.2s\n",
            "819:\tlearn: 0.2122585\ttotal: 59.9s\tremaining: 13.2s\n",
            "820:\tlearn: 0.2120221\ttotal: 60s\tremaining: 13.1s\n",
            "821:\tlearn: 0.2118708\ttotal: 1m\tremaining: 13s\n",
            "822:\tlearn: 0.2116805\ttotal: 1m\tremaining: 12.9s\n",
            "823:\tlearn: 0.2114532\ttotal: 1m\tremaining: 12.9s\n",
            "824:\tlearn: 0.2112468\ttotal: 1m\tremaining: 12.8s\n",
            "825:\tlearn: 0.2111746\ttotal: 1m\tremaining: 12.7s\n",
            "826:\tlearn: 0.2110135\ttotal: 1m\tremaining: 12.6s\n",
            "827:\tlearn: 0.2109009\ttotal: 1m\tremaining: 12.6s\n",
            "828:\tlearn: 0.2108441\ttotal: 1m\tremaining: 12.5s\n",
            "829:\tlearn: 0.2107911\ttotal: 1m\tremaining: 12.4s\n",
            "830:\tlearn: 0.2106991\ttotal: 1m\tremaining: 12.4s\n",
            "831:\tlearn: 0.2106441\ttotal: 1m\tremaining: 12.3s\n",
            "832:\tlearn: 0.2104938\ttotal: 1m\tremaining: 12.2s\n",
            "833:\tlearn: 0.2104057\ttotal: 1m\tremaining: 12.1s\n",
            "834:\tlearn: 0.2102667\ttotal: 1m 1s\tremaining: 12.1s\n",
            "835:\tlearn: 0.2101769\ttotal: 1m 1s\tremaining: 12s\n",
            "836:\tlearn: 0.2100075\ttotal: 1m 1s\tremaining: 11.9s\n",
            "837:\tlearn: 0.2099317\ttotal: 1m 1s\tremaining: 11.8s\n",
            "838:\tlearn: 0.2096620\ttotal: 1m 1s\tremaining: 11.8s\n",
            "839:\tlearn: 0.2096281\ttotal: 1m 1s\tremaining: 11.7s\n",
            "840:\tlearn: 0.2095530\ttotal: 1m 1s\tremaining: 11.6s\n",
            "841:\tlearn: 0.2095286\ttotal: 1m 1s\tremaining: 11.6s\n",
            "842:\tlearn: 0.2093499\ttotal: 1m 1s\tremaining: 11.5s\n",
            "843:\tlearn: 0.2092638\ttotal: 1m 1s\tremaining: 11.4s\n",
            "844:\tlearn: 0.2091164\ttotal: 1m 1s\tremaining: 11.3s\n",
            "845:\tlearn: 0.2091005\ttotal: 1m 1s\tremaining: 11.3s\n",
            "846:\tlearn: 0.2090502\ttotal: 1m 1s\tremaining: 11.2s\n",
            "847:\tlearn: 0.2089689\ttotal: 1m 2s\tremaining: 11.1s\n",
            "848:\tlearn: 0.2086971\ttotal: 1m 2s\tremaining: 11s\n",
            "849:\tlearn: 0.2086661\ttotal: 1m 2s\tremaining: 11s\n",
            "850:\tlearn: 0.2083939\ttotal: 1m 2s\tremaining: 10.9s\n",
            "851:\tlearn: 0.2081779\ttotal: 1m 2s\tremaining: 10.8s\n",
            "852:\tlearn: 0.2080359\ttotal: 1m 2s\tremaining: 10.7s\n",
            "853:\tlearn: 0.2079559\ttotal: 1m 2s\tremaining: 10.7s\n",
            "854:\tlearn: 0.2079245\ttotal: 1m 2s\tremaining: 10.6s\n",
            "855:\tlearn: 0.2078639\ttotal: 1m 2s\tremaining: 10.5s\n",
            "856:\tlearn: 0.2078172\ttotal: 1m 2s\tremaining: 10.5s\n",
            "857:\tlearn: 0.2078064\ttotal: 1m 2s\tremaining: 10.4s\n",
            "858:\tlearn: 0.2077464\ttotal: 1m 2s\tremaining: 10.3s\n",
            "859:\tlearn: 0.2076494\ttotal: 1m 2s\tremaining: 10.2s\n",
            "860:\tlearn: 0.2076416\ttotal: 1m 2s\tremaining: 10.2s\n",
            "861:\tlearn: 0.2075349\ttotal: 1m 3s\tremaining: 10.1s\n",
            "862:\tlearn: 0.2074289\ttotal: 1m 3s\tremaining: 10s\n",
            "863:\tlearn: 0.2073400\ttotal: 1m 3s\tremaining: 9.95s\n",
            "864:\tlearn: 0.2071924\ttotal: 1m 3s\tremaining: 9.88s\n",
            "865:\tlearn: 0.2071780\ttotal: 1m 3s\tremaining: 9.8s\n",
            "866:\tlearn: 0.2071353\ttotal: 1m 3s\tremaining: 9.73s\n",
            "867:\tlearn: 0.2070743\ttotal: 1m 3s\tremaining: 9.66s\n",
            "868:\tlearn: 0.2070496\ttotal: 1m 3s\tremaining: 9.58s\n",
            "869:\tlearn: 0.2069883\ttotal: 1m 3s\tremaining: 9.51s\n",
            "870:\tlearn: 0.2068753\ttotal: 1m 3s\tremaining: 9.44s\n",
            "871:\tlearn: 0.2067851\ttotal: 1m 3s\tremaining: 9.37s\n",
            "872:\tlearn: 0.2067336\ttotal: 1m 3s\tremaining: 9.29s\n",
            "873:\tlearn: 0.2066562\ttotal: 1m 3s\tremaining: 9.22s\n",
            "874:\tlearn: 0.2065385\ttotal: 1m 4s\tremaining: 9.15s\n",
            "875:\tlearn: 0.2063241\ttotal: 1m 4s\tremaining: 9.08s\n",
            "876:\tlearn: 0.2061383\ttotal: 1m 4s\tremaining: 9s\n",
            "877:\tlearn: 0.2060751\ttotal: 1m 4s\tremaining: 8.93s\n",
            "878:\tlearn: 0.2060113\ttotal: 1m 4s\tremaining: 8.86s\n",
            "879:\tlearn: 0.2059875\ttotal: 1m 4s\tremaining: 8.78s\n",
            "880:\tlearn: 0.2057239\ttotal: 1m 4s\tremaining: 8.71s\n",
            "881:\tlearn: 0.2056373\ttotal: 1m 4s\tremaining: 8.64s\n",
            "882:\tlearn: 0.2055594\ttotal: 1m 4s\tremaining: 8.56s\n",
            "883:\tlearn: 0.2054987\ttotal: 1m 4s\tremaining: 8.49s\n",
            "884:\tlearn: 0.2054897\ttotal: 1m 4s\tremaining: 8.42s\n",
            "885:\tlearn: 0.2054699\ttotal: 1m 4s\tremaining: 8.34s\n",
            "886:\tlearn: 0.2054320\ttotal: 1m 4s\tremaining: 8.27s\n",
            "887:\tlearn: 0.2053352\ttotal: 1m 5s\tremaining: 8.2s\n",
            "888:\tlearn: 0.2051934\ttotal: 1m 5s\tremaining: 8.13s\n",
            "889:\tlearn: 0.2051635\ttotal: 1m 5s\tremaining: 8.05s\n",
            "890:\tlearn: 0.2050022\ttotal: 1m 5s\tremaining: 7.98s\n",
            "891:\tlearn: 0.2049584\ttotal: 1m 5s\tremaining: 7.91s\n",
            "892:\tlearn: 0.2048919\ttotal: 1m 5s\tremaining: 7.83s\n",
            "893:\tlearn: 0.2046651\ttotal: 1m 5s\tremaining: 7.76s\n",
            "894:\tlearn: 0.2044700\ttotal: 1m 5s\tremaining: 7.69s\n",
            "895:\tlearn: 0.2044107\ttotal: 1m 5s\tremaining: 7.61s\n",
            "896:\tlearn: 0.2043221\ttotal: 1m 5s\tremaining: 7.54s\n",
            "897:\tlearn: 0.2042524\ttotal: 1m 5s\tremaining: 7.47s\n",
            "898:\tlearn: 0.2040802\ttotal: 1m 5s\tremaining: 7.4s\n",
            "899:\tlearn: 0.2039723\ttotal: 1m 5s\tremaining: 7.32s\n",
            "900:\tlearn: 0.2037134\ttotal: 1m 5s\tremaining: 7.25s\n",
            "901:\tlearn: 0.2036383\ttotal: 1m 6s\tremaining: 7.18s\n",
            "902:\tlearn: 0.2034999\ttotal: 1m 6s\tremaining: 7.1s\n",
            "903:\tlearn: 0.2032673\ttotal: 1m 6s\tremaining: 7.03s\n",
            "904:\tlearn: 0.2031847\ttotal: 1m 6s\tremaining: 6.96s\n",
            "905:\tlearn: 0.2031176\ttotal: 1m 6s\tremaining: 6.88s\n",
            "906:\tlearn: 0.2030297\ttotal: 1m 6s\tremaining: 6.81s\n",
            "907:\tlearn: 0.2029795\ttotal: 1m 6s\tremaining: 6.74s\n",
            "908:\tlearn: 0.2028644\ttotal: 1m 6s\tremaining: 6.66s\n",
            "909:\tlearn: 0.2027617\ttotal: 1m 6s\tremaining: 6.59s\n",
            "910:\tlearn: 0.2026714\ttotal: 1m 6s\tremaining: 6.52s\n",
            "911:\tlearn: 0.2026355\ttotal: 1m 6s\tremaining: 6.44s\n",
            "912:\tlearn: 0.2025883\ttotal: 1m 6s\tremaining: 6.37s\n",
            "913:\tlearn: 0.2024296\ttotal: 1m 6s\tremaining: 6.3s\n",
            "914:\tlearn: 0.2023870\ttotal: 1m 7s\tremaining: 6.23s\n",
            "915:\tlearn: 0.2023486\ttotal: 1m 7s\tremaining: 6.15s\n",
            "916:\tlearn: 0.2022493\ttotal: 1m 7s\tremaining: 6.08s\n",
            "917:\tlearn: 0.2021948\ttotal: 1m 7s\tremaining: 6.01s\n",
            "918:\tlearn: 0.2021441\ttotal: 1m 7s\tremaining: 5.93s\n",
            "919:\tlearn: 0.2020447\ttotal: 1m 7s\tremaining: 5.86s\n",
            "920:\tlearn: 0.2019756\ttotal: 1m 7s\tremaining: 5.79s\n",
            "921:\tlearn: 0.2018623\ttotal: 1m 7s\tremaining: 5.71s\n",
            "922:\tlearn: 0.2018154\ttotal: 1m 7s\tremaining: 5.64s\n",
            "923:\tlearn: 0.2017361\ttotal: 1m 7s\tremaining: 5.57s\n",
            "924:\tlearn: 0.2015587\ttotal: 1m 7s\tremaining: 5.5s\n",
            "925:\tlearn: 0.2014495\ttotal: 1m 7s\tremaining: 5.42s\n",
            "926:\tlearn: 0.2013020\ttotal: 1m 7s\tremaining: 5.35s\n",
            "927:\tlearn: 0.2012293\ttotal: 1m 8s\tremaining: 5.28s\n",
            "928:\tlearn: 0.2010321\ttotal: 1m 8s\tremaining: 5.2s\n",
            "929:\tlearn: 0.2009604\ttotal: 1m 8s\tremaining: 5.13s\n",
            "930:\tlearn: 0.2009221\ttotal: 1m 8s\tremaining: 5.06s\n",
            "931:\tlearn: 0.2008259\ttotal: 1m 8s\tremaining: 4.99s\n",
            "932:\tlearn: 0.2007802\ttotal: 1m 8s\tremaining: 4.91s\n",
            "933:\tlearn: 0.2006664\ttotal: 1m 8s\tremaining: 4.84s\n",
            "934:\tlearn: 0.2005707\ttotal: 1m 8s\tremaining: 4.77s\n",
            "935:\tlearn: 0.2005087\ttotal: 1m 8s\tremaining: 4.69s\n",
            "936:\tlearn: 0.2004776\ttotal: 1m 8s\tremaining: 4.62s\n",
            "937:\tlearn: 0.2003009\ttotal: 1m 8s\tremaining: 4.55s\n",
            "938:\tlearn: 0.2002423\ttotal: 1m 8s\tremaining: 4.47s\n",
            "939:\tlearn: 0.2001652\ttotal: 1m 8s\tremaining: 4.4s\n",
            "940:\tlearn: 0.2001384\ttotal: 1m 9s\tremaining: 4.33s\n",
            "941:\tlearn: 0.2000927\ttotal: 1m 9s\tremaining: 4.25s\n",
            "942:\tlearn: 0.1999674\ttotal: 1m 9s\tremaining: 4.18s\n",
            "943:\tlearn: 0.1999047\ttotal: 1m 9s\tremaining: 4.11s\n",
            "944:\tlearn: 0.1998967\ttotal: 1m 9s\tremaining: 4.04s\n",
            "945:\tlearn: 0.1998218\ttotal: 1m 9s\tremaining: 3.96s\n",
            "946:\tlearn: 0.1996580\ttotal: 1m 9s\tremaining: 3.89s\n",
            "947:\tlearn: 0.1995864\ttotal: 1m 9s\tremaining: 3.82s\n",
            "948:\tlearn: 0.1994857\ttotal: 1m 9s\tremaining: 3.75s\n",
            "949:\tlearn: 0.1992991\ttotal: 1m 9s\tremaining: 3.67s\n",
            "950:\tlearn: 0.1992333\ttotal: 1m 9s\tremaining: 3.6s\n",
            "951:\tlearn: 0.1991765\ttotal: 1m 9s\tremaining: 3.53s\n",
            "952:\tlearn: 0.1990870\ttotal: 1m 10s\tremaining: 3.45s\n",
            "953:\tlearn: 0.1989913\ttotal: 1m 10s\tremaining: 3.38s\n",
            "954:\tlearn: 0.1989279\ttotal: 1m 10s\tremaining: 3.31s\n",
            "955:\tlearn: 0.1988783\ttotal: 1m 10s\tremaining: 3.23s\n",
            "956:\tlearn: 0.1988151\ttotal: 1m 10s\tremaining: 3.16s\n",
            "957:\tlearn: 0.1987502\ttotal: 1m 10s\tremaining: 3.09s\n",
            "958:\tlearn: 0.1985132\ttotal: 1m 10s\tremaining: 3.01s\n",
            "959:\tlearn: 0.1984721\ttotal: 1m 10s\tremaining: 2.94s\n",
            "960:\tlearn: 0.1981895\ttotal: 1m 10s\tremaining: 2.87s\n",
            "961:\tlearn: 0.1981052\ttotal: 1m 10s\tremaining: 2.79s\n",
            "962:\tlearn: 0.1980161\ttotal: 1m 10s\tremaining: 2.72s\n",
            "963:\tlearn: 0.1978757\ttotal: 1m 10s\tremaining: 2.65s\n",
            "964:\tlearn: 0.1976811\ttotal: 1m 10s\tremaining: 2.58s\n",
            "965:\tlearn: 0.1976083\ttotal: 1m 11s\tremaining: 2.5s\n",
            "966:\tlearn: 0.1974925\ttotal: 1m 11s\tremaining: 2.43s\n",
            "967:\tlearn: 0.1973331\ttotal: 1m 11s\tremaining: 2.35s\n",
            "968:\tlearn: 0.1972935\ttotal: 1m 11s\tremaining: 2.28s\n",
            "969:\tlearn: 0.1971801\ttotal: 1m 11s\tremaining: 2.21s\n",
            "970:\tlearn: 0.1971544\ttotal: 1m 11s\tremaining: 2.13s\n",
            "971:\tlearn: 0.1970758\ttotal: 1m 11s\tremaining: 2.06s\n",
            "972:\tlearn: 0.1969873\ttotal: 1m 11s\tremaining: 1.99s\n",
            "973:\tlearn: 0.1969809\ttotal: 1m 11s\tremaining: 1.91s\n",
            "974:\tlearn: 0.1968100\ttotal: 1m 11s\tremaining: 1.84s\n",
            "975:\tlearn: 0.1967013\ttotal: 1m 11s\tremaining: 1.77s\n",
            "976:\tlearn: 0.1966728\ttotal: 1m 11s\tremaining: 1.69s\n",
            "977:\tlearn: 0.1966153\ttotal: 1m 12s\tremaining: 1.62s\n",
            "978:\tlearn: 0.1965136\ttotal: 1m 12s\tremaining: 1.55s\n",
            "979:\tlearn: 0.1964365\ttotal: 1m 12s\tremaining: 1.47s\n",
            "980:\tlearn: 0.1962279\ttotal: 1m 12s\tremaining: 1.4s\n",
            "981:\tlearn: 0.1961714\ttotal: 1m 12s\tremaining: 1.32s\n",
            "982:\tlearn: 0.1961026\ttotal: 1m 12s\tremaining: 1.25s\n",
            "983:\tlearn: 0.1960653\ttotal: 1m 12s\tremaining: 1.18s\n",
            "984:\tlearn: 0.1958886\ttotal: 1m 12s\tremaining: 1.1s\n",
            "985:\tlearn: 0.1957539\ttotal: 1m 12s\tremaining: 1.03s\n",
            "986:\tlearn: 0.1956863\ttotal: 1m 12s\tremaining: 958ms\n",
            "987:\tlearn: 0.1956574\ttotal: 1m 12s\tremaining: 884ms\n",
            "988:\tlearn: 0.1956098\ttotal: 1m 12s\tremaining: 811ms\n",
            "989:\tlearn: 0.1955917\ttotal: 1m 12s\tremaining: 737ms\n",
            "990:\tlearn: 0.1955011\ttotal: 1m 13s\tremaining: 664ms\n",
            "991:\tlearn: 0.1954397\ttotal: 1m 13s\tremaining: 590ms\n",
            "992:\tlearn: 0.1953978\ttotal: 1m 13s\tremaining: 516ms\n",
            "993:\tlearn: 0.1953636\ttotal: 1m 13s\tremaining: 443ms\n",
            "994:\tlearn: 0.1952938\ttotal: 1m 13s\tremaining: 369ms\n",
            "995:\tlearn: 0.1951601\ttotal: 1m 13s\tremaining: 295ms\n",
            "996:\tlearn: 0.1948850\ttotal: 1m 13s\tremaining: 221ms\n",
            "997:\tlearn: 0.1948448\ttotal: 1m 13s\tremaining: 148ms\n",
            "998:\tlearn: 0.1947553\ttotal: 1m 13s\tremaining: 73.8ms\n",
            "999:\tlearn: 0.1946993\ttotal: 1m 13s\tremaining: 0us\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<catboost.core.CatBoostClassifier at 0x1c5da389850>"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cat.fit(pool_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9f5cd39",
      "metadata": {
        "id": "b9f5cd39",
        "outputId": "ac641cac-e7b3-494b-8688-4aba76f2a256"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "default xgboost accuracy = 0.8692124105011934\n",
            "default lgbm accuracy = 0.863961813842482\n",
            "default catboost accuracy = 0.8663484486873508\n",
            "flaml (5 min) accuracy = 0.8706443914081146\n",
            "r2 = 0.09102625680435461\n",
            "mse = 0.12935560859188544\n",
            "mae = 0.12935560859188544\n"
          ]
        }
      ],
      "source": [
        "print('default xgboost accuracy', '=', 1 - sklearn_metric_loss_score('accuracy', y_pred_xgb, y_test))\n",
        "print('default lgbm accuracy', '=', 1 - sklearn_metric_loss_score('accuracy', y_pred_lgbm, y_test))\n",
        "print('default catboost accuracy', '=', 1 - sklearn_metric_loss_score('accuracy', y_pred_cat, y_test))\n",
        "print('flaml (10 min) accuracy', '=', 1 - sklearn_metric_loss_score('accuracy', y_pred, y_test))\n",
        "print('r2', '=', 1 - sklearn_metric_loss_score('r2', y_pred, y_test))\n",
        "print('mse', '=', sklearn_metric_loss_score('mse', y_pred, y_test))\n",
        "print('mae', '=', sklearn_metric_loss_score('mae', y_pred, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdf3b1e7",
      "metadata": {
        "id": "cdf3b1e7",
        "outputId": "55fc6436-83fd-4f28-fb44-016acfe14a86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.96      0.93      1735\n",
            "           1       0.71      0.42      0.53       360\n",
            "\n",
            "    accuracy                           0.87      2095\n",
            "   macro avg       0.80      0.69      0.73      2095\n",
            "weighted avg       0.86      0.87      0.86      2095\n",
            "\n"
          ]
        }
      ],
      "source": [
        "predict = automl.predict(X_test)\n",
        "predict = [int(x) for x in np.array(predict)]\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51c63f80",
      "metadata": {
        "id": "51c63f80"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('SpeedDate.pkl', 'wb') as f:\n",
        "    pickle.dump(automl, f, pickle.HIGHEST_PROTOCOL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8c6c9c8",
      "metadata": {
        "id": "b8c6c9c8"
      },
      "outputs": [],
      "source": [
        "#from sklearn.metrics import roc_curve, auc\n",
        "#Xbin_train, Xbin_test, ybin_train, ybin_test = train_test_split(X, ybin, test_size=0.3)\n",
        "\n",
        "#poly_clf2.fit(Xbin_train, ybin_train)\n",
        "#ybin_test_pred = poly_clf2.decision_function(Xbin_test)\n",
        "#fpr1, tpr1, te_thresholds1 = roc_curve(ybin_test, ybin_test_pred)\n",
        "\n",
        "#xgb_clf2.fit(Xbin_train, ybin_train)\n",
        "#ybin_test_pred2 = xgb_clf2.predict_proba(Xbin_test)[:,1]\n",
        "#fpr2, tpr2, te_thresholds2 = roc_curve(ybin_test, ybin_test_pred2)\n",
        "\n",
        "#log_reg1.fit(Xbin_train, ybin_train)\n",
        "#ybin_test_pred3 = log_reg1.predict_proba(Xbin_test)[:,1]\n",
        "#fpr3, tpr3, te_thresholds3 = roc_curve(ybin_test, ybin_test_pred3)\n",
        "\n",
        "#plt.figure(figsize=(10,7))\n",
        "#plt.grid()\n",
        "#plt.plot(fpr1, tpr1, label='Poly_SVM')\n",
        "#plt.plot(fpr2, tpr2, label='XGBoost_clf')\n",
        "#plt.plot(fpr3, tpr3, label='Logistic_reg')\n",
        "#plt.legend(loc='lower right')\n",
        "#plt.plot([0,1],[0,1], 'k--')\n",
        "#plt.xlabel('False Positive Rate')\n",
        "#plt.ylabel('True Positive Rate')\n",
        "#plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6dd0305",
      "metadata": {
        "id": "b6dd0305"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "#import pandas as pd\n",
        "#import numpy as np\n",
        "#from sklearn.model_selection import train_test_split\n",
        "#from flaml import AutoML\n",
        "#from sklearn.metrics import accuracy_score\n",
        "#from sklearn.datasets import load_boston\n",
        "#from sklearn.metrics import max_error, mean_absolute_error, mean_squared_log_error, mean_squared_error, r2_score\n",
        "# Classification with FLAML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "461fb901",
      "metadata": {
        "id": "461fb901"
      },
      "outputs": [],
      "source": [
        "#x = dataset.data\n",
        "#y = dataset.target\n",
        "#x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=100)\n",
        "#automl_clf = AutoML()\n",
        "#automl_clf.fit(x_train, y_train, task=\"classification\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80b319eb",
      "metadata": {
        "id": "80b319eb"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}