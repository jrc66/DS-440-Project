{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b198e7c1",
      "metadata": {
        "id": "b198e7c1",
        "outputId": "4db991ec-ef52-4a99-bead-f82ebd3cd3b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting flaml[notebook]==1.0.10\n",
            "  Downloading FLAML-1.0.10-py3-none-any.whl (205 kB)\n",
            "\u001b[K     |████████████████████████████████| 205 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.7/dist-packages (from flaml[notebook]==1.0.10) (1.3.5)\n",
            "Requirement already satisfied: NumPy>=1.17.0rc1 in /usr/local/lib/python3.7/dist-packages (from flaml[notebook]==1.0.10) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from flaml[notebook]==1.0.10) (1.7.3)\n",
            "Requirement already satisfied: scikit-learn>=0.24 in /usr/local/lib/python3.7/dist-packages (from flaml[notebook]==1.0.10) (1.0.2)\n",
            "Requirement already satisfied: xgboost>=0.90 in /usr/local/lib/python3.7/dist-packages (from flaml[notebook]==1.0.10) (0.90)\n",
            "Collecting lightgbm>=2.3.1\n",
            "  Downloading lightgbm-3.3.3-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 25.4 MB/s \n",
            "\u001b[?25hCollecting catboost>=0.26\n",
            "  Downloading catboost-1.1.1-cp37-none-manylinux1_x86_64.whl (76.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 76.6 MB 1.3 MB/s \n",
            "\u001b[?25hCollecting rgf-python\n",
            "  Downloading rgf_python-3.12.0-py3-none-manylinux1_x86_64.whl (757 kB)\n",
            "\u001b[K     |████████████████████████████████| 757 kB 55.1 MB/s \n",
            "\u001b[?25hCollecting jupyter\n",
            "  Downloading jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
            "Collecting openml==0.10.2\n",
            "  Downloading openml-0.10.2.tar.gz (158 kB)\n",
            "\u001b[K     |████████████████████████████████| 158 kB 65.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from flaml[notebook]==1.0.10) (3.2.2)\n",
            "Collecting liac-arff>=2.4.0\n",
            "  Downloading liac-arff-2.5.0.tar.gz (13 kB)\n",
            "Collecting xmltodict\n",
            "  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from openml==0.10.2->flaml[notebook]==1.0.10) (2.23.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from openml==0.10.2->flaml[notebook]==1.0.10) (2.8.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost>=0.26->flaml[notebook]==1.0.10) (5.5.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost>=0.26->flaml[notebook]==1.0.10) (0.10.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost>=0.26->flaml[notebook]==1.0.10) (1.15.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from lightgbm>=2.3.1->flaml[notebook]==1.0.10) (0.38.3)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.4->flaml[notebook]==1.0.10) (2022.6)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24->flaml[notebook]==1.0.10) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24->flaml[notebook]==1.0.10) (1.2.0)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from jupyter->flaml[notebook]==1.0.10) (5.3.4)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter->flaml[notebook]==1.0.10) (6.1.0)\n",
            "Collecting qtconsole\n",
            "  Downloading qtconsole-5.4.0-py3-none-any.whl (121 kB)\n",
            "\u001b[K     |████████████████████████████████| 121 kB 52.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter->flaml[notebook]==1.0.10) (5.7.16)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter->flaml[notebook]==1.0.10) (5.6.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from jupyter->flaml[notebook]==1.0.10) (7.7.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->flaml[notebook]==1.0.10) (6.1.12)\n",
            "Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->flaml[notebook]==1.0.10) (7.9.0)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->flaml[notebook]==1.0.10) (5.1.1)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->flaml[notebook]==1.0.10) (6.0.4)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->flaml[notebook]==1.0.10) (2.0.10)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 50.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->flaml[notebook]==1.0.10) (2.6.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->flaml[notebook]==1.0.10) (4.4.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->flaml[notebook]==1.0.10) (0.2.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->flaml[notebook]==1.0.10) (0.7.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->flaml[notebook]==1.0.10) (57.4.0)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->flaml[notebook]==1.0.10) (4.8.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->ipython>=5.0.0->ipykernel->jupyter->flaml[notebook]==1.0.10) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=5.0.0->ipykernel->jupyter->flaml[notebook]==1.0.10) (0.2.5)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->flaml[notebook]==1.0.10) (0.2.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->flaml[notebook]==1.0.10) (3.0.3)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->flaml[notebook]==1.0.10) (3.6.1)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->flaml[notebook]==1.0.10) (0.13.3)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->flaml[notebook]==1.0.10) (1.8.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->flaml[notebook]==1.0.10) (5.7.0)\n",
            "Requirement already satisfied: jinja2<=3.0.0 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->flaml[notebook]==1.0.10) (2.11.3)\n",
            "Requirement already satisfied: jupyter-core>=4.4.0 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->flaml[notebook]==1.0.10) (4.11.2)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->flaml[notebook]==1.0.10) (23.2.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->flaml[notebook]==1.0.10) (0.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2<=3.0.0->notebook->jupyter->flaml[notebook]==1.0.10) (2.0.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->flaml[notebook]==1.0.10) (5.0.1)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->flaml[notebook]==1.0.10) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->flaml[notebook]==1.0.10) (0.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->flaml[notebook]==1.0.10) (1.5.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->flaml[notebook]==1.0.10) (0.6.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->flaml[notebook]==1.0.10) (0.8.4)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook->jupyter->flaml[notebook]==1.0.10) (2.16.2)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook->jupyter->flaml[notebook]==1.0.10) (4.3.3)\n",
            "Requirement already satisfied: importlib-metadata>=3.6 in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook->jupyter->flaml[notebook]==1.0.10) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=3.6->nbformat->notebook->jupyter->flaml[notebook]==1.0.10) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=3.6->nbformat->notebook->jupyter->flaml[notebook]==1.0.10) (4.1.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook->jupyter->flaml[notebook]==1.0.10) (22.1.0)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook->jupyter->flaml[notebook]==1.0.10) (5.10.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook->jupyter->flaml[notebook]==1.0.10) (0.19.2)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->jupyter->flaml[notebook]==1.0.10) (0.7.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter->flaml[notebook]==1.0.10) (0.5.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flaml[notebook]==1.0.10) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flaml[notebook]==1.0.10) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flaml[notebook]==1.0.10) (1.4.4)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost>=0.26->flaml[notebook]==1.0.10) (8.1.0)\n",
            "Collecting qtpy>=2.0.1\n",
            "  Downloading QtPy-2.3.0-py3-none-any.whl (83 kB)\n",
            "\u001b[K     |████████████████████████████████| 83 kB 1.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from qtpy>=2.0.1->qtconsole->jupyter->flaml[notebook]==1.0.10) (21.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->openml==0.10.2->flaml[notebook]==1.0.10) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->openml==0.10.2->flaml[notebook]==1.0.10) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->openml==0.10.2->flaml[notebook]==1.0.10) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->openml==0.10.2->flaml[notebook]==1.0.10) (2022.9.24)\n",
            "Building wheels for collected packages: openml, liac-arff\n",
            "  Building wheel for openml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openml: filename=openml-0.10.2-py3-none-any.whl size=190340 sha256=fba4aea7010ea020f347a27d1718472ac77037626a7a0fdfcb086d43d35ac7d7\n",
            "  Stored in directory: /root/.cache/pip/wheels/9c/9e/f3/6a5ebf16527d7fe22d9bc1652bc9beb5dc9fcfdeb75e805400\n",
            "  Building wheel for liac-arff (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for liac-arff: filename=liac_arff-2.5.0-py3-none-any.whl size=11730 sha256=b67fe48b7c55ee26fc23d32aff5d36cbb9e9deb69c18f9989a4859f4a0927fb9\n",
            "  Stored in directory: /root/.cache/pip/wheels/1f/0f/15/332ca86cbebf25ddf98518caaf887945fbe1712b97a0f2493b\n",
            "Successfully built openml liac-arff\n",
            "Installing collected packages: jedi, qtpy, xmltodict, qtconsole, lightgbm, liac-arff, rgf-python, openml, jupyter, flaml, catboost\n",
            "  Attempting uninstall: lightgbm\n",
            "    Found existing installation: lightgbm 2.2.3\n",
            "    Uninstalling lightgbm-2.2.3:\n",
            "      Successfully uninstalled lightgbm-2.2.3\n",
            "Successfully installed catboost-1.1.1 flaml-1.0.10 jedi-0.18.1 jupyter-1.0.0 liac-arff-2.5.0 lightgbm-3.3.3 openml-0.10.2 qtconsole-5.4.0 qtpy-2.3.0 rgf-python-3.12.0 xmltodict-0.13.0\n"
          ]
        }
      ],
      "source": [
        "%pip install flaml[notebook]==1.0.10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63a48f81",
      "metadata": {
        "id": "63a48f81",
        "outputId": "4549c0d5-0c43-4f91-a8cd-99c4c18522e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "download dataset from openml\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/openml/_api_calls.py:105: UserWarning: Received uncompressed content from OpenML for https://api.openml.org/data/v1/download/22103119/california.arff.\n",
            "  .format(url))\n",
            "DEBUG:openml.datasets.dataset:Saved dataset 44031: california to file /root/.openml/cache/org/openml/www/datasets/44031/dataset.pkl.py3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset name: california\n",
            "X_train.shape: (15480, 8), y_train.shape: (15480,);\n",
            "X_test.shape: (5160, 8), y_test.shape: (5160,)\n",
            "Data type: <class 'pandas.core.frame.DataFrame'> <class 'pandas.core.series.Series'>\n",
            "The first 5 rows of X_train:\n",
            "       MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
            "19226  7.3003      19.0  7.961600   1.137600      1926.0  3.081600     38.46   \n",
            "14549  5.9547      18.0  6.547325   1.102881       547.0  2.251029     32.95   \n",
            "9093   3.2125      19.0  5.207547   1.216981       314.0  2.962264     34.68   \n",
            "12213  6.9930      13.0  6.428571   1.000000       120.0  2.857143     33.51   \n",
            "12765  2.5162      21.0  4.429348   1.036685      1735.0  2.357337     38.62   \n",
            "\n",
            "       Longitude  \n",
            "19226    -122.68  \n",
            "14549    -117.24  \n",
            "9093     -118.27  \n",
            "12213    -117.18  \n",
            "12765    -121.41  \n",
            "The first 5 rows of y_train:\n",
            "19226    1.571321\n",
            "14549    1.456986\n",
            "9093     1.048722\n",
            "12213    1.791761\n",
            "12765    0.680568\n",
            "Name: price, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "from flaml.data import load_openml_dataset\n",
        "X_train, X_test, y_train, y_test = load_openml_dataset(dataset_id=44031, data_dir='./')\n",
        "print(\"Data type:\", type(X_train), type(y_train))\n",
        "print(\"The first 5 rows of X_train:\")\n",
        "print(X_train.head())\n",
        "print(\"The first 5 rows of y_train:\")\n",
        "print(y_train.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca1b9330",
      "metadata": {
        "id": "ca1b9330"
      },
      "outputs": [],
      "source": [
        "from flaml import AutoML\n",
        "automl = AutoML()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb29dfb4",
      "metadata": {
        "id": "fb29dfb4"
      },
      "outputs": [],
      "source": [
        "settings = {\n",
        "    \"time_budget\": 300,  # total running time in seconds\n",
        "    \"metric\": 'r2',  # can be: 'r2', 'rmse', 'mae', 'mse', 'accuracy', 'roc_auc', 'roc_auc_ovr',\n",
        "                           # 'roc_auc_ovo', 'log_loss', 'mape', 'f1', 'ap', 'ndcg', 'micro_f1', 'macro_f1'\n",
        "    \"estimator_list\": ['xgboost', 'lgbm', 'catboost', 'rf'],\n",
        "    \"task\": 'regression',  # task type\n",
        "    \"log_file_name\": 'houses.log',  # flaml log file\n",
        "    \"seed\": 423874,    # random seed\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a55973e6",
      "metadata": {
        "id": "a55973e6",
        "outputId": "7ed1946e-5028-4002-82ad-678181bd03d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[flaml.automl: 11-10 19:00:08] {2540} INFO - task = regression\n",
            "INFO:flaml.automl:task = regression\n",
            "[flaml.automl: 11-10 19:00:09] {2542} INFO - Data split method: uniform\n",
            "INFO:flaml.automl:Data split method: uniform\n",
            "[flaml.automl: 11-10 19:00:09] {2545} INFO - Evaluation method: cv\n",
            "INFO:flaml.automl:Evaluation method: cv\n",
            "[flaml.automl: 11-10 19:00:09] {2664} INFO - Minimizing error metric: 1-r2\n",
            "INFO:flaml.automl:Minimizing error metric: 1-r2\n",
            "[flaml.automl: 11-10 19:00:09] {2806} INFO - List of ML learners in AutoML Run: ['xgboost', 'lgbm', 'catboost', 'rf']\n",
            "INFO:flaml.automl:List of ML learners in AutoML Run: ['xgboost', 'lgbm', 'catboost', 'rf']\n",
            "[flaml.automl: 11-10 19:00:09] {3108} INFO - iteration 0, current learner xgboost\n",
            "INFO:flaml.automl:iteration 0, current learner xgboost\n",
            "[flaml.automl: 11-10 19:00:09] {3242} INFO - Estimated sufficient time budget=6130s. Estimated necessary time budget=8s.\n",
            "INFO:flaml.automl:Estimated sufficient time budget=6130s. Estimated necessary time budget=8s.\n",
            "[flaml.automl: 11-10 19:00:09] {3294} INFO -  at 0.8s,\testimator xgboost's best error=1.7959,\tbest estimator xgboost's best error=1.7959\n",
            "INFO:flaml.automl: at 0.8s,\testimator xgboost's best error=1.7959,\tbest estimator xgboost's best error=1.7959\n",
            "[flaml.automl: 11-10 19:00:09] {3108} INFO - iteration 1, current learner lgbm\n",
            "INFO:flaml.automl:iteration 1, current learner lgbm\n",
            "[flaml.automl: 11-10 19:00:09] {3294} INFO -  at 1.0s,\testimator lgbm's best error=0.7368,\tbest estimator lgbm's best error=0.7368\n",
            "INFO:flaml.automl: at 1.0s,\testimator lgbm's best error=0.7368,\tbest estimator lgbm's best error=0.7368\n",
            "[flaml.automl: 11-10 19:00:09] {3108} INFO - iteration 2, current learner lgbm\n",
            "INFO:flaml.automl:iteration 2, current learner lgbm\n",
            "[flaml.automl: 11-10 19:00:10] {3294} INFO -  at 1.3s,\testimator lgbm's best error=0.7368,\tbest estimator lgbm's best error=0.7368\n",
            "INFO:flaml.automl: at 1.3s,\testimator lgbm's best error=0.7368,\tbest estimator lgbm's best error=0.7368\n",
            "[flaml.automl: 11-10 19:00:10] {3108} INFO - iteration 3, current learner lgbm\n",
            "INFO:flaml.automl:iteration 3, current learner lgbm\n",
            "[flaml.automl: 11-10 19:00:10] {3294} INFO -  at 1.5s,\testimator lgbm's best error=0.4305,\tbest estimator lgbm's best error=0.4305\n",
            "INFO:flaml.automl: at 1.5s,\testimator lgbm's best error=0.4305,\tbest estimator lgbm's best error=0.4305\n",
            "[flaml.automl: 11-10 19:00:10] {3108} INFO - iteration 4, current learner xgboost\n",
            "INFO:flaml.automl:iteration 4, current learner xgboost\n",
            "[flaml.automl: 11-10 19:00:10] {3294} INFO -  at 2.0s,\testimator xgboost's best error=1.7959,\tbest estimator lgbm's best error=0.4305\n",
            "INFO:flaml.automl: at 2.0s,\testimator xgboost's best error=1.7959,\tbest estimator lgbm's best error=0.4305\n",
            "[flaml.automl: 11-10 19:00:10] {3108} INFO - iteration 5, current learner lgbm\n",
            "INFO:flaml.automl:iteration 5, current learner lgbm\n",
            "[flaml.automl: 11-10 19:00:11] {3294} INFO -  at 2.2s,\testimator lgbm's best error=0.3847,\tbest estimator lgbm's best error=0.3847\n",
            "INFO:flaml.automl: at 2.2s,\testimator lgbm's best error=0.3847,\tbest estimator lgbm's best error=0.3847\n",
            "[flaml.automl: 11-10 19:00:11] {3108} INFO - iteration 6, current learner lgbm\n",
            "INFO:flaml.automl:iteration 6, current learner lgbm\n",
            "[flaml.automl: 11-10 19:00:11] {3294} INFO -  at 2.7s,\testimator lgbm's best error=0.3390,\tbest estimator lgbm's best error=0.3390\n",
            "INFO:flaml.automl: at 2.7s,\testimator lgbm's best error=0.3390,\tbest estimator lgbm's best error=0.3390\n",
            "[flaml.automl: 11-10 19:00:11] {3108} INFO - iteration 7, current learner xgboost\n",
            "INFO:flaml.automl:iteration 7, current learner xgboost\n",
            "[flaml.automl: 11-10 19:00:12] {3294} INFO -  at 3.8s,\testimator xgboost's best error=0.4621,\tbest estimator lgbm's best error=0.3390\n",
            "INFO:flaml.automl: at 3.8s,\testimator xgboost's best error=0.4621,\tbest estimator lgbm's best error=0.3390\n",
            "[flaml.automl: 11-10 19:00:12] {3108} INFO - iteration 8, current learner xgboost\n",
            "INFO:flaml.automl:iteration 8, current learner xgboost\n",
            "[flaml.automl: 11-10 19:00:13] {3294} INFO -  at 5.0s,\testimator xgboost's best error=0.2545,\tbest estimator xgboost's best error=0.2545\n",
            "INFO:flaml.automl: at 5.0s,\testimator xgboost's best error=0.2545,\tbest estimator xgboost's best error=0.2545\n",
            "[flaml.automl: 11-10 19:00:13] {3108} INFO - iteration 9, current learner rf\n",
            "INFO:flaml.automl:iteration 9, current learner rf\n",
            "[flaml.automl: 11-10 19:00:15] {3294} INFO -  at 6.8s,\testimator rf's best error=0.5406,\tbest estimator xgboost's best error=0.2545\n",
            "INFO:flaml.automl: at 6.8s,\testimator rf's best error=0.5406,\tbest estimator xgboost's best error=0.2545\n",
            "[flaml.automl: 11-10 19:00:15] {3108} INFO - iteration 10, current learner xgboost\n",
            "INFO:flaml.automl:iteration 10, current learner xgboost\n",
            "[flaml.automl: 11-10 19:00:18] {3294} INFO -  at 9.5s,\testimator xgboost's best error=0.2545,\tbest estimator xgboost's best error=0.2545\n",
            "INFO:flaml.automl: at 9.5s,\testimator xgboost's best error=0.2545,\tbest estimator xgboost's best error=0.2545\n",
            "[flaml.automl: 11-10 19:00:18] {3108} INFO - iteration 11, current learner lgbm\n",
            "INFO:flaml.automl:iteration 11, current learner lgbm\n",
            "[flaml.automl: 11-10 19:00:18] {3294} INFO -  at 10.1s,\testimator lgbm's best error=0.2937,\tbest estimator xgboost's best error=0.2545\n",
            "INFO:flaml.automl: at 10.1s,\testimator lgbm's best error=0.2937,\tbest estimator xgboost's best error=0.2545\n",
            "[flaml.automl: 11-10 19:00:19] {3108} INFO - iteration 12, current learner lgbm\n",
            "INFO:flaml.automl:iteration 12, current learner lgbm\n",
            "[flaml.automl: 11-10 19:00:19] {3294} INFO -  at 10.9s,\testimator lgbm's best error=0.2937,\tbest estimator xgboost's best error=0.2545\n",
            "INFO:flaml.automl: at 10.9s,\testimator lgbm's best error=0.2937,\tbest estimator xgboost's best error=0.2545\n",
            "[flaml.automl: 11-10 19:00:19] {3108} INFO - iteration 13, current learner lgbm\n",
            "INFO:flaml.automl:iteration 13, current learner lgbm\n",
            "[flaml.automl: 11-10 19:00:21] {3294} INFO -  at 12.9s,\testimator lgbm's best error=0.1880,\tbest estimator lgbm's best error=0.1880\n",
            "INFO:flaml.automl: at 12.9s,\testimator lgbm's best error=0.1880,\tbest estimator lgbm's best error=0.1880\n",
            "[flaml.automl: 11-10 19:00:21] {3108} INFO - iteration 14, current learner rf\n",
            "INFO:flaml.automl:iteration 14, current learner rf\n",
            "[flaml.automl: 11-10 19:00:24] {3294} INFO -  at 16.0s,\testimator rf's best error=0.4186,\tbest estimator lgbm's best error=0.1880\n",
            "INFO:flaml.automl: at 16.0s,\testimator rf's best error=0.4186,\tbest estimator lgbm's best error=0.1880\n",
            "[flaml.automl: 11-10 19:00:24] {3108} INFO - iteration 15, current learner xgboost\n",
            "INFO:flaml.automl:iteration 15, current learner xgboost\n",
            "[flaml.automl: 11-10 19:00:27] {3294} INFO -  at 18.3s,\testimator xgboost's best error=0.2439,\tbest estimator lgbm's best error=0.1880\n",
            "INFO:flaml.automl: at 18.3s,\testimator xgboost's best error=0.2439,\tbest estimator lgbm's best error=0.1880\n",
            "[flaml.automl: 11-10 19:00:27] {3108} INFO - iteration 16, current learner rf\n",
            "INFO:flaml.automl:iteration 16, current learner rf\n",
            "[flaml.automl: 11-10 19:00:30] {3294} INFO -  at 21.3s,\testimator rf's best error=0.3876,\tbest estimator lgbm's best error=0.1880\n",
            "INFO:flaml.automl: at 21.3s,\testimator rf's best error=0.3876,\tbest estimator lgbm's best error=0.1880\n",
            "[flaml.automl: 11-10 19:00:30] {3108} INFO - iteration 17, current learner xgboost\n",
            "INFO:flaml.automl:iteration 17, current learner xgboost\n",
            "[flaml.automl: 11-10 19:00:31] {3294} INFO -  at 22.9s,\testimator xgboost's best error=0.2439,\tbest estimator lgbm's best error=0.1880\n",
            "INFO:flaml.automl: at 22.9s,\testimator xgboost's best error=0.2439,\tbest estimator lgbm's best error=0.1880\n",
            "[flaml.automl: 11-10 19:00:31] {3108} INFO - iteration 18, current learner lgbm\n",
            "INFO:flaml.automl:iteration 18, current learner lgbm\n",
            "[flaml.automl: 11-10 19:00:32] {3294} INFO -  at 23.7s,\testimator lgbm's best error=0.1880,\tbest estimator lgbm's best error=0.1880\n",
            "INFO:flaml.automl: at 23.7s,\testimator lgbm's best error=0.1880,\tbest estimator lgbm's best error=0.1880\n",
            "[flaml.automl: 11-10 19:00:32] {3108} INFO - iteration 19, current learner lgbm\n",
            "INFO:flaml.automl:iteration 19, current learner lgbm\n",
            "[flaml.automl: 11-10 19:00:36] {3294} INFO -  at 27.7s,\testimator lgbm's best error=0.1755,\tbest estimator lgbm's best error=0.1755\n",
            "INFO:flaml.automl: at 27.7s,\testimator lgbm's best error=0.1755,\tbest estimator lgbm's best error=0.1755\n",
            "[flaml.automl: 11-10 19:00:36] {3108} INFO - iteration 20, current learner lgbm\n",
            "INFO:flaml.automl:iteration 20, current learner lgbm\n",
            "[flaml.automl: 11-10 19:00:38] {3294} INFO -  at 29.2s,\testimator lgbm's best error=0.1755,\tbest estimator lgbm's best error=0.1755\n",
            "INFO:flaml.automl: at 29.2s,\testimator lgbm's best error=0.1755,\tbest estimator lgbm's best error=0.1755\n",
            "[flaml.automl: 11-10 19:00:38] {3108} INFO - iteration 21, current learner lgbm\n",
            "INFO:flaml.automl:iteration 21, current learner lgbm\n",
            "[flaml.automl: 11-10 19:00:38] {3294} INFO -  at 29.5s,\testimator lgbm's best error=0.1755,\tbest estimator lgbm's best error=0.1755\n",
            "INFO:flaml.automl: at 29.5s,\testimator lgbm's best error=0.1755,\tbest estimator lgbm's best error=0.1755\n",
            "[flaml.automl: 11-10 19:00:38] {3108} INFO - iteration 22, current learner lgbm\n",
            "INFO:flaml.automl:iteration 22, current learner lgbm\n",
            "[flaml.automl: 11-10 19:00:39] {3294} INFO -  at 30.8s,\testimator lgbm's best error=0.1596,\tbest estimator lgbm's best error=0.1596\n",
            "INFO:flaml.automl: at 30.8s,\testimator lgbm's best error=0.1596,\tbest estimator lgbm's best error=0.1596\n",
            "[flaml.automl: 11-10 19:00:39] {3108} INFO - iteration 23, current learner lgbm\n",
            "INFO:flaml.automl:iteration 23, current learner lgbm\n",
            "[flaml.automl: 11-10 19:00:48] {3294} INFO -  at 39.4s,\testimator lgbm's best error=0.1447,\tbest estimator lgbm's best error=0.1447\n",
            "INFO:flaml.automl: at 39.4s,\testimator lgbm's best error=0.1447,\tbest estimator lgbm's best error=0.1447\n",
            "[flaml.automl: 11-10 19:00:48] {3108} INFO - iteration 24, current learner catboost\n",
            "INFO:flaml.automl:iteration 24, current learner catboost\n",
            "[flaml.automl: 11-10 19:00:56] {3294} INFO -  at 47.8s,\testimator catboost's best error=0.1533,\tbest estimator lgbm's best error=0.1447\n",
            "INFO:flaml.automl: at 47.8s,\testimator catboost's best error=0.1533,\tbest estimator lgbm's best error=0.1447\n",
            "[flaml.automl: 11-10 19:00:56] {3108} INFO - iteration 25, current learner rf\n",
            "INFO:flaml.automl:iteration 25, current learner rf\n",
            "[flaml.automl: 11-10 19:00:58] {3294} INFO -  at 49.6s,\testimator rf's best error=0.3876,\tbest estimator lgbm's best error=0.1447\n",
            "INFO:flaml.automl: at 49.6s,\testimator rf's best error=0.3876,\tbest estimator lgbm's best error=0.1447\n",
            "[flaml.automl: 11-10 19:00:58] {3108} INFO - iteration 26, current learner lgbm\n",
            "INFO:flaml.automl:iteration 26, current learner lgbm\n",
            "[flaml.automl: 11-10 19:00:59] {3294} INFO -  at 50.8s,\testimator lgbm's best error=0.1447,\tbest estimator lgbm's best error=0.1447\n",
            "INFO:flaml.automl: at 50.8s,\testimator lgbm's best error=0.1447,\tbest estimator lgbm's best error=0.1447\n",
            "[flaml.automl: 11-10 19:00:59] {3108} INFO - iteration 27, current learner catboost\n",
            "INFO:flaml.automl:iteration 27, current learner catboost\n",
            "[flaml.automl: 11-10 19:01:05] {3294} INFO -  at 56.4s,\testimator catboost's best error=0.1533,\tbest estimator lgbm's best error=0.1447\n",
            "INFO:flaml.automl: at 56.4s,\testimator catboost's best error=0.1533,\tbest estimator lgbm's best error=0.1447\n",
            "[flaml.automl: 11-10 19:01:05] {3108} INFO - iteration 28, current learner catboost\n",
            "INFO:flaml.automl:iteration 28, current learner catboost\n",
            "[flaml.automl: 11-10 19:01:15] {3294} INFO -  at 66.3s,\testimator catboost's best error=0.1514,\tbest estimator lgbm's best error=0.1447\n",
            "INFO:flaml.automl: at 66.3s,\testimator catboost's best error=0.1514,\tbest estimator lgbm's best error=0.1447\n",
            "[flaml.automl: 11-10 19:01:15] {3108} INFO - iteration 29, current learner catboost\n",
            "INFO:flaml.automl:iteration 29, current learner catboost\n",
            "[flaml.automl: 11-10 19:01:28] {3294} INFO -  at 79.9s,\testimator catboost's best error=0.1514,\tbest estimator lgbm's best error=0.1447\n",
            "INFO:flaml.automl: at 79.9s,\testimator catboost's best error=0.1514,\tbest estimator lgbm's best error=0.1447\n",
            "[flaml.automl: 11-10 19:01:28] {3108} INFO - iteration 30, current learner lgbm\n",
            "INFO:flaml.automl:iteration 30, current learner lgbm\n",
            "[flaml.automl: 11-10 19:01:31] {3294} INFO -  at 82.3s,\testimator lgbm's best error=0.1447,\tbest estimator lgbm's best error=0.1447\n",
            "INFO:flaml.automl: at 82.3s,\testimator lgbm's best error=0.1447,\tbest estimator lgbm's best error=0.1447\n",
            "[flaml.automl: 11-10 19:01:31] {3108} INFO - iteration 31, current learner xgboost\n",
            "INFO:flaml.automl:iteration 31, current learner xgboost\n",
            "[flaml.automl: 11-10 19:01:31] {3294} INFO -  at 82.9s,\testimator xgboost's best error=0.2296,\tbest estimator lgbm's best error=0.1447\n",
            "INFO:flaml.automl: at 82.9s,\testimator xgboost's best error=0.2296,\tbest estimator lgbm's best error=0.1447\n",
            "[flaml.automl: 11-10 19:01:31] {3108} INFO - iteration 32, current learner xgboost\n",
            "INFO:flaml.automl:iteration 32, current learner xgboost\n",
            "[flaml.automl: 11-10 19:01:32] {3294} INFO -  at 83.3s,\testimator xgboost's best error=0.2296,\tbest estimator lgbm's best error=0.1447\n",
            "INFO:flaml.automl: at 83.3s,\testimator xgboost's best error=0.2296,\tbest estimator lgbm's best error=0.1447\n",
            "[flaml.automl: 11-10 19:01:32] {3108} INFO - iteration 33, current learner lgbm\n",
            "INFO:flaml.automl:iteration 33, current learner lgbm\n",
            "[flaml.automl: 11-10 19:01:39] {3294} INFO -  at 90.4s,\testimator lgbm's best error=0.1447,\tbest estimator lgbm's best error=0.1447\n",
            "INFO:flaml.automl: at 90.4s,\testimator lgbm's best error=0.1447,\tbest estimator lgbm's best error=0.1447\n",
            "[flaml.automl: 11-10 19:01:39] {3108} INFO - iteration 34, current learner xgboost\n",
            "INFO:flaml.automl:iteration 34, current learner xgboost\n",
            "[flaml.automl: 11-10 19:01:40] {3294} INFO -  at 91.2s,\testimator xgboost's best error=0.2153,\tbest estimator lgbm's best error=0.1447\n",
            "INFO:flaml.automl: at 91.2s,\testimator xgboost's best error=0.2153,\tbest estimator lgbm's best error=0.1447\n",
            "[flaml.automl: 11-10 19:01:40] {3108} INFO - iteration 35, current learner xgboost\n",
            "INFO:flaml.automl:iteration 35, current learner xgboost\n",
            "[flaml.automl: 11-10 19:01:40] {3294} INFO -  at 91.7s,\testimator xgboost's best error=0.2153,\tbest estimator lgbm's best error=0.1447\n",
            "INFO:flaml.automl: at 91.7s,\testimator xgboost's best error=0.2153,\tbest estimator lgbm's best error=0.1447\n",
            "[flaml.automl: 11-10 19:01:40] {3108} INFO - iteration 36, current learner rf\n",
            "INFO:flaml.automl:iteration 36, current learner rf\n",
            "[flaml.automl: 11-10 19:01:41] {3294} INFO -  at 93.1s,\testimator rf's best error=0.3876,\tbest estimator lgbm's best error=0.1447\n",
            "INFO:flaml.automl: at 93.1s,\testimator rf's best error=0.3876,\tbest estimator lgbm's best error=0.1447\n",
            "[flaml.automl: 11-10 19:01:41] {3108} INFO - iteration 37, current learner lgbm\n",
            "INFO:flaml.automl:iteration 37, current learner lgbm\n",
            "[flaml.automl: 11-10 19:01:58] {3294} INFO -  at 109.6s,\testimator lgbm's best error=0.1447,\tbest estimator lgbm's best error=0.1447\n",
            "INFO:flaml.automl: at 109.6s,\testimator lgbm's best error=0.1447,\tbest estimator lgbm's best error=0.1447\n",
            "[flaml.automl: 11-10 19:01:58] {3108} INFO - iteration 38, current learner lgbm\n",
            "INFO:flaml.automl:iteration 38, current learner lgbm\n",
            "[flaml.automl: 11-10 19:02:04] {3294} INFO -  at 115.3s,\testimator lgbm's best error=0.1447,\tbest estimator lgbm's best error=0.1447\n",
            "INFO:flaml.automl: at 115.3s,\testimator lgbm's best error=0.1447,\tbest estimator lgbm's best error=0.1447\n",
            "[flaml.automl: 11-10 19:02:04] {3108} INFO - iteration 39, current learner xgboost\n",
            "INFO:flaml.automl:iteration 39, current learner xgboost\n",
            "[flaml.automl: 11-10 19:02:05] {3294} INFO -  at 116.6s,\testimator xgboost's best error=0.1904,\tbest estimator lgbm's best error=0.1447\n",
            "INFO:flaml.automl: at 116.6s,\testimator xgboost's best error=0.1904,\tbest estimator lgbm's best error=0.1447\n",
            "[flaml.automl: 11-10 19:02:05] {3108} INFO - iteration 40, current learner xgboost\n",
            "INFO:flaml.automl:iteration 40, current learner xgboost\n",
            "[flaml.automl: 11-10 19:02:06] {3294} INFO -  at 117.4s,\testimator xgboost's best error=0.1904,\tbest estimator lgbm's best error=0.1447\n",
            "INFO:flaml.automl: at 117.4s,\testimator xgboost's best error=0.1904,\tbest estimator lgbm's best error=0.1447\n",
            "[flaml.automl: 11-10 19:02:06] {3108} INFO - iteration 41, current learner lgbm\n",
            "INFO:flaml.automl:iteration 41, current learner lgbm\n",
            "[flaml.automl: 11-10 19:02:10] {3294} INFO -  at 121.3s,\testimator lgbm's best error=0.1447,\tbest estimator lgbm's best error=0.1447\n",
            "INFO:flaml.automl: at 121.3s,\testimator lgbm's best error=0.1447,\tbest estimator lgbm's best error=0.1447\n",
            "[flaml.automl: 11-10 19:02:10] {3108} INFO - iteration 42, current learner xgboost\n",
            "INFO:flaml.automl:iteration 42, current learner xgboost\n",
            "[flaml.automl: 11-10 19:02:12] {3294} INFO -  at 123.6s,\testimator xgboost's best error=0.1904,\tbest estimator lgbm's best error=0.1447\n",
            "INFO:flaml.automl: at 123.6s,\testimator xgboost's best error=0.1904,\tbest estimator lgbm's best error=0.1447\n",
            "[flaml.automl: 11-10 19:02:12] {3108} INFO - iteration 43, current learner lgbm\n",
            "INFO:flaml.automl:iteration 43, current learner lgbm\n",
            "[flaml.automl: 11-10 19:02:22] {3294} INFO -  at 133.5s,\testimator lgbm's best error=0.1447,\tbest estimator lgbm's best error=0.1447\n",
            "INFO:flaml.automl: at 133.5s,\testimator lgbm's best error=0.1447,\tbest estimator lgbm's best error=0.1447\n",
            "[flaml.automl: 11-10 19:02:22] {3108} INFO - iteration 44, current learner rf\n",
            "INFO:flaml.automl:iteration 44, current learner rf\n",
            "[flaml.automl: 11-10 19:02:24] {3294} INFO -  at 135.3s,\testimator rf's best error=0.3411,\tbest estimator lgbm's best error=0.1447\n",
            "INFO:flaml.automl: at 135.3s,\testimator rf's best error=0.3411,\tbest estimator lgbm's best error=0.1447\n",
            "[flaml.automl: 11-10 19:02:24] {3108} INFO - iteration 45, current learner catboost\n",
            "INFO:flaml.automl:iteration 45, current learner catboost\n",
            "[flaml.automl: 11-10 19:02:30] {3294} INFO -  at 142.0s,\testimator catboost's best error=0.1514,\tbest estimator lgbm's best error=0.1447\n",
            "INFO:flaml.automl: at 142.0s,\testimator catboost's best error=0.1514,\tbest estimator lgbm's best error=0.1447\n",
            "[flaml.automl: 11-10 19:02:30] {3108} INFO - iteration 46, current learner xgboost\n",
            "INFO:flaml.automl:iteration 46, current learner xgboost\n",
            "[flaml.automl: 11-10 19:02:32] {3294} INFO -  at 144.1s,\testimator xgboost's best error=0.1598,\tbest estimator lgbm's best error=0.1447\n",
            "INFO:flaml.automl: at 144.1s,\testimator xgboost's best error=0.1598,\tbest estimator lgbm's best error=0.1447\n",
            "[flaml.automl: 11-10 19:02:32] {3108} INFO - iteration 47, current learner xgboost\n",
            "INFO:flaml.automl:iteration 47, current learner xgboost\n",
            "[flaml.automl: 11-10 19:02:37] {3294} INFO -  at 148.2s,\testimator xgboost's best error=0.1533,\tbest estimator lgbm's best error=0.1447\n",
            "INFO:flaml.automl: at 148.2s,\testimator xgboost's best error=0.1533,\tbest estimator lgbm's best error=0.1447\n",
            "[flaml.automl: 11-10 19:02:37] {3108} INFO - iteration 48, current learner xgboost\n",
            "INFO:flaml.automl:iteration 48, current learner xgboost\n",
            "[flaml.automl: 11-10 19:02:39] {3294} INFO -  at 150.4s,\testimator xgboost's best error=0.1533,\tbest estimator lgbm's best error=0.1447\n",
            "INFO:flaml.automl: at 150.4s,\testimator xgboost's best error=0.1533,\tbest estimator lgbm's best error=0.1447\n",
            "[flaml.automl: 11-10 19:02:39] {3108} INFO - iteration 49, current learner xgboost\n",
            "INFO:flaml.automl:iteration 49, current learner xgboost\n",
            "[flaml.automl: 11-10 19:02:43] {3294} INFO -  at 155.0s,\testimator xgboost's best error=0.1501,\tbest estimator lgbm's best error=0.1447\n",
            "INFO:flaml.automl: at 155.0s,\testimator xgboost's best error=0.1501,\tbest estimator lgbm's best error=0.1447\n",
            "[flaml.automl: 11-10 19:02:43] {3108} INFO - iteration 50, current learner rf\n",
            "INFO:flaml.automl:iteration 50, current learner rf\n",
            "[flaml.automl: 11-10 19:02:45] {3294} INFO -  at 156.8s,\testimator rf's best error=0.3082,\tbest estimator lgbm's best error=0.1447\n",
            "INFO:flaml.automl: at 156.8s,\testimator rf's best error=0.3082,\tbest estimator lgbm's best error=0.1447\n",
            "[flaml.automl: 11-10 19:02:45] {3108} INFO - iteration 51, current learner xgboost\n",
            "INFO:flaml.automl:iteration 51, current learner xgboost\n",
            "[flaml.automl: 11-10 19:02:49] {3294} INFO -  at 160.7s,\testimator xgboost's best error=0.1501,\tbest estimator lgbm's best error=0.1447\n",
            "INFO:flaml.automl: at 160.7s,\testimator xgboost's best error=0.1501,\tbest estimator lgbm's best error=0.1447\n",
            "[flaml.automl: 11-10 19:02:49] {3108} INFO - iteration 52, current learner lgbm\n",
            "INFO:flaml.automl:iteration 52, current learner lgbm\n",
            "[flaml.automl: 11-10 19:02:59] {3294} INFO -  at 170.5s,\testimator lgbm's best error=0.1447,\tbest estimator lgbm's best error=0.1447\n",
            "INFO:flaml.automl: at 170.5s,\testimator lgbm's best error=0.1447,\tbest estimator lgbm's best error=0.1447\n",
            "[flaml.automl: 11-10 19:02:59] {3108} INFO - iteration 53, current learner xgboost\n",
            "INFO:flaml.automl:iteration 53, current learner xgboost\n",
            "[flaml.automl: 11-10 19:03:08] {3294} INFO -  at 180.0s,\testimator xgboost's best error=0.1447,\tbest estimator lgbm's best error=0.1447\n",
            "INFO:flaml.automl: at 180.0s,\testimator xgboost's best error=0.1447,\tbest estimator lgbm's best error=0.1447\n",
            "[flaml.automl: 11-10 19:03:08] {3108} INFO - iteration 54, current learner xgboost\n",
            "INFO:flaml.automl:iteration 54, current learner xgboost\n",
            "[flaml.automl: 11-10 19:03:13] {3294} INFO -  at 184.6s,\testimator xgboost's best error=0.1447,\tbest estimator lgbm's best error=0.1447\n",
            "INFO:flaml.automl: at 184.6s,\testimator xgboost's best error=0.1447,\tbest estimator lgbm's best error=0.1447\n",
            "[flaml.automl: 11-10 19:03:13] {3108} INFO - iteration 55, current learner rf\n",
            "INFO:flaml.automl:iteration 55, current learner rf\n",
            "[flaml.automl: 11-10 19:03:15] {3294} INFO -  at 186.4s,\testimator rf's best error=0.3082,\tbest estimator lgbm's best error=0.1447\n",
            "INFO:flaml.automl: at 186.4s,\testimator rf's best error=0.3082,\tbest estimator lgbm's best error=0.1447\n",
            "[flaml.automl: 11-10 19:03:15] {3108} INFO - iteration 56, current learner xgboost\n",
            "INFO:flaml.automl:iteration 56, current learner xgboost\n",
            "[flaml.automl: 11-10 19:03:25] {3294} INFO -  at 196.6s,\testimator xgboost's best error=0.1447,\tbest estimator lgbm's best error=0.1447\n",
            "INFO:flaml.automl: at 196.6s,\testimator xgboost's best error=0.1447,\tbest estimator lgbm's best error=0.1447\n",
            "[flaml.automl: 11-10 19:03:25] {3108} INFO - iteration 57, current learner xgboost\n",
            "INFO:flaml.automl:iteration 57, current learner xgboost\n",
            "[flaml.automl: 11-10 19:03:30] {3294} INFO -  at 202.0s,\testimator xgboost's best error=0.1447,\tbest estimator lgbm's best error=0.1447\n",
            "INFO:flaml.automl: at 202.0s,\testimator xgboost's best error=0.1447,\tbest estimator lgbm's best error=0.1447\n",
            "[flaml.automl: 11-10 19:03:30] {3108} INFO - iteration 58, current learner xgboost\n",
            "INFO:flaml.automl:iteration 58, current learner xgboost\n",
            "[flaml.automl: 11-10 19:03:33] {3294} INFO -  at 204.9s,\testimator xgboost's best error=0.1447,\tbest estimator lgbm's best error=0.1447\n",
            "INFO:flaml.automl: at 204.9s,\testimator xgboost's best error=0.1447,\tbest estimator lgbm's best error=0.1447\n",
            "[flaml.automl: 11-10 19:03:33] {3108} INFO - iteration 59, current learner xgboost\n",
            "INFO:flaml.automl:iteration 59, current learner xgboost\n",
            "[flaml.automl: 11-10 19:03:59] {3294} INFO -  at 230.9s,\testimator xgboost's best error=0.1447,\tbest estimator lgbm's best error=0.1447\n",
            "INFO:flaml.automl: at 230.9s,\testimator xgboost's best error=0.1447,\tbest estimator lgbm's best error=0.1447\n",
            "[flaml.automl: 11-10 19:03:59] {3108} INFO - iteration 60, current learner catboost\n",
            "INFO:flaml.automl:iteration 60, current learner catboost\n",
            "[flaml.automl: 11-10 19:04:06] {3294} INFO -  at 237.5s,\testimator catboost's best error=0.1514,\tbest estimator lgbm's best error=0.1447\n",
            "INFO:flaml.automl: at 237.5s,\testimator catboost's best error=0.1514,\tbest estimator lgbm's best error=0.1447\n",
            "[flaml.automl: 11-10 19:04:06] {3108} INFO - iteration 61, current learner xgboost\n",
            "INFO:flaml.automl:iteration 61, current learner xgboost\n",
            "[flaml.automl: 11-10 19:04:12] {3294} INFO -  at 243.6s,\testimator xgboost's best error=0.1447,\tbest estimator lgbm's best error=0.1447\n",
            "INFO:flaml.automl: at 243.6s,\testimator xgboost's best error=0.1447,\tbest estimator lgbm's best error=0.1447\n",
            "[flaml.automl: 11-10 19:04:12] {3108} INFO - iteration 62, current learner rf\n",
            "INFO:flaml.automl:iteration 62, current learner rf\n",
            "[flaml.automl: 11-10 19:04:15] {3294} INFO -  at 246.9s,\testimator rf's best error=0.2695,\tbest estimator lgbm's best error=0.1447\n",
            "INFO:flaml.automl: at 246.9s,\testimator rf's best error=0.2695,\tbest estimator lgbm's best error=0.1447\n",
            "[flaml.automl: 11-10 19:04:15] {3108} INFO - iteration 63, current learner rf\n",
            "INFO:flaml.automl:iteration 63, current learner rf\n",
            "[flaml.automl: 11-10 19:04:17] {3294} INFO -  at 248.4s,\testimator rf's best error=0.2695,\tbest estimator lgbm's best error=0.1447\n",
            "INFO:flaml.automl: at 248.4s,\testimator rf's best error=0.2695,\tbest estimator lgbm's best error=0.1447\n",
            "[flaml.automl: 11-10 19:04:17] {3108} INFO - iteration 64, current learner xgboost\n",
            "INFO:flaml.automl:iteration 64, current learner xgboost\n",
            "[flaml.automl: 11-10 19:04:27] {3294} INFO -  at 258.8s,\testimator xgboost's best error=0.1447,\tbest estimator lgbm's best error=0.1447\n",
            "INFO:flaml.automl: at 258.8s,\testimator xgboost's best error=0.1447,\tbest estimator lgbm's best error=0.1447\n",
            "[flaml.automl: 11-10 19:04:27] {3108} INFO - iteration 65, current learner lgbm\n",
            "INFO:flaml.automl:iteration 65, current learner lgbm\n",
            "[flaml.automl: 11-10 19:04:33] {3294} INFO -  at 264.3s,\testimator lgbm's best error=0.1447,\tbest estimator lgbm's best error=0.1447\n",
            "INFO:flaml.automl: at 264.3s,\testimator lgbm's best error=0.1447,\tbest estimator lgbm's best error=0.1447\n",
            "[flaml.automl: 11-10 19:04:33] {3108} INFO - iteration 66, current learner rf\n",
            "INFO:flaml.automl:iteration 66, current learner rf\n",
            "[flaml.automl: 11-10 19:04:36] {3294} INFO -  at 267.3s,\testimator rf's best error=0.2246,\tbest estimator lgbm's best error=0.1447\n",
            "INFO:flaml.automl: at 267.3s,\testimator rf's best error=0.2246,\tbest estimator lgbm's best error=0.1447\n",
            "[flaml.automl: 11-10 19:04:36] {3108} INFO - iteration 67, current learner rf\n",
            "INFO:flaml.automl:iteration 67, current learner rf\n",
            "[flaml.automl: 11-10 19:04:38] {3294} INFO -  at 269.8s,\testimator rf's best error=0.2246,\tbest estimator lgbm's best error=0.1447\n",
            "INFO:flaml.automl: at 269.8s,\testimator rf's best error=0.2246,\tbest estimator lgbm's best error=0.1447\n",
            "[flaml.automl: 11-10 19:04:38] {3108} INFO - iteration 68, current learner xgboost\n",
            "INFO:flaml.automl:iteration 68, current learner xgboost\n",
            "[flaml.automl: 11-10 19:04:47] {3294} INFO -  at 278.3s,\testimator xgboost's best error=0.1447,\tbest estimator lgbm's best error=0.1447\n",
            "INFO:flaml.automl: at 278.3s,\testimator xgboost's best error=0.1447,\tbest estimator lgbm's best error=0.1447\n",
            "[flaml.automl: 11-10 19:04:47] {3108} INFO - iteration 69, current learner rf\n",
            "INFO:flaml.automl:iteration 69, current learner rf\n",
            "[flaml.automl: 11-10 19:04:50] {3294} INFO -  at 282.0s,\testimator rf's best error=0.2246,\tbest estimator lgbm's best error=0.1447\n",
            "INFO:flaml.automl: at 282.0s,\testimator rf's best error=0.2246,\tbest estimator lgbm's best error=0.1447\n",
            "[flaml.automl: 11-10 19:04:50] {3108} INFO - iteration 70, current learner rf\n",
            "INFO:flaml.automl:iteration 70, current learner rf\n",
            "[flaml.automl: 11-10 19:04:52] {3294} INFO -  at 283.7s,\testimator rf's best error=0.2201,\tbest estimator lgbm's best error=0.1447\n",
            "INFO:flaml.automl: at 283.7s,\testimator rf's best error=0.2201,\tbest estimator lgbm's best error=0.1447\n",
            "[flaml.automl: 11-10 19:04:52] {3108} INFO - iteration 71, current learner lgbm\n",
            "INFO:flaml.automl:iteration 71, current learner lgbm\n",
            "[flaml.automl: 11-10 19:05:00] {3294} INFO -  at 291.2s,\testimator lgbm's best error=0.1431,\tbest estimator lgbm's best error=0.1431\n",
            "INFO:flaml.automl: at 291.2s,\testimator lgbm's best error=0.1431,\tbest estimator lgbm's best error=0.1431\n",
            "[flaml.automl: 11-10 19:05:00] {3108} INFO - iteration 72, current learner rf\n",
            "INFO:flaml.automl:iteration 72, current learner rf\n",
            "[flaml.automl: 11-10 19:05:02] {3294} INFO -  at 294.1s,\testimator rf's best error=0.2028,\tbest estimator lgbm's best error=0.1431\n",
            "INFO:flaml.automl: at 294.1s,\testimator rf's best error=0.2028,\tbest estimator lgbm's best error=0.1431\n",
            "[flaml.automl: 11-10 19:05:02] {3108} INFO - iteration 73, current learner rf\n",
            "INFO:flaml.automl:iteration 73, current learner rf\n",
            "[flaml.automl: 11-10 19:05:07] {3294} INFO -  at 298.2s,\testimator rf's best error=0.1949,\tbest estimator lgbm's best error=0.1431\n",
            "INFO:flaml.automl: at 298.2s,\testimator rf's best error=0.1949,\tbest estimator lgbm's best error=0.1431\n",
            "[flaml.automl: 11-10 19:05:08] {3554} INFO - retrain lgbm for 1.5s\n",
            "INFO:flaml.automl:retrain lgbm for 1.5s\n",
            "[flaml.automl: 11-10 19:05:08] {3559} INFO - retrained model: LGBMRegressor(colsample_bytree=0.875183151668791,\n",
            "              learning_rate=0.11638978786387756, max_bin=127,\n",
            "              min_child_samples=81, n_estimators=398, num_leaves=89,\n",
            "              reg_alpha=0.06441369344589583, reg_lambda=103.883235206324,\n",
            "              verbose=-1)\n",
            "INFO:flaml.automl:retrained model: LGBMRegressor(colsample_bytree=0.875183151668791,\n",
            "              learning_rate=0.11638978786387756, max_bin=127,\n",
            "              min_child_samples=81, n_estimators=398, num_leaves=89,\n",
            "              reg_alpha=0.06441369344589583, reg_lambda=103.883235206324,\n",
            "              verbose=-1)\n",
            "[flaml.automl: 11-10 19:05:08] {2837} INFO - fit succeeded\n",
            "INFO:flaml.automl:fit succeeded\n",
            "[flaml.automl: 11-10 19:05:08] {2839} INFO - Time taken to find the best model: 291.19155716896057\n",
            "INFO:flaml.automl:Time taken to find the best model: 291.19155716896057\n",
            "[flaml.automl: 11-10 19:05:08] {2853} WARNING - Time taken to find the best model is 97% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.\n",
            "WARNING:flaml.automl:Time taken to find the best model is 97% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.\n"
          ]
        }
      ],
      "source": [
        "#X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=100)\n",
        "automl.fit(X_train, y_train, **settings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee3a556f",
      "metadata": {
        "id": "ee3a556f"
      },
      "outputs": [],
      "source": [
        "#automl.fit(X_train=x_train, y_train=y_train, **settings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ddc970f6",
      "metadata": {
        "id": "ddc970f6",
        "outputId": "f9791b1c-f173-42f5-95c8-9021664aa3ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best ML leaner: lgbm\n",
            "Best hyperparmeter config: {'n_estimators': 398, 'num_leaves': 89, 'min_child_samples': 81, 'learning_rate': 0.11638978786387756, 'log_max_bin': 7, 'colsample_bytree': 0.875183151668791, 'reg_alpha': 0.06441369344589583, 'reg_lambda': 103.883235206324}\n",
            "Best r2 accuracy on validation data: 0.8569\n",
            "Training duration of best run: 1.534 s\n"
          ]
        }
      ],
      "source": [
        "print('Best ML leaner:', automl.best_estimator)\n",
        "print('Best hyperparmeter config:', automl.best_config)\n",
        "print('Best r2 accuracy on validation data: {0:.4g}'.format(1-automl.best_loss))\n",
        "print('Training duration of best run: {0:.4g} s'.format(automl.best_config_train_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac00e5f0",
      "metadata": {
        "id": "ac00e5f0",
        "outputId": "01509cee-e670-495b-e262-3162d9801fbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 8 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.barh(automl.feature_names_in_, automl.feature_importances_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0946e9bf",
      "metadata": {
        "id": "0946e9bf",
        "outputId": "447092aa-1146-4e5b-dafc-ac60218e214b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted labels [0.83486448 1.25240202 0.92585458 ... 1.04302382 1.12821845 1.31258268]\n",
            "True labels 14740    0.862468\n",
            "10101    1.227592\n",
            "20566    1.100943\n",
            "2670     0.545227\n",
            "15709    1.722767\n",
            "           ...   \n",
            "13132    0.793897\n",
            "8228     0.864997\n",
            "3948     0.958967\n",
            "8522     1.185707\n",
            "16798    1.296370\n",
            "Name: price, Length: 5160, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "y_pred = automl.predict(X_test)\n",
        "print('Predicted labels', y_pred)\n",
        "print('True labels', y_test)\n",
        "#y_pred_proba = automl.predict_proba(X_test)[:,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81b1107e",
      "metadata": {
        "id": "81b1107e"
      },
      "outputs": [],
      "source": [
        "#import numpy as np\n",
        "#from sklearn.preprocessing import LabelEncoder\n",
        "#label_encoder = LabelEncoder()\n",
        "#label_encoder = label_encoder.fit(y_pred)\n",
        "#y_pred = label_encoder.transform(y_pred)\n",
        "#label_encoder_test = label_encoder.fit(y_test)\n",
        "#y_test = label_encoder_test.transform(y_test)\n",
        "#y_pred_proba = np.argmax(y_pred_proba, axis=0) \n",
        "#y_train = float(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a425ecdb",
      "metadata": {
        "id": "a425ecdb",
        "outputId": "af703bf5-1d73-4f02-c514-6bf9ee3b6178",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "r2 = 0.8647471133422999\n",
            "mse = 0.01714366249372399\n",
            "mae = 0.09077562791836823\n"
          ]
        }
      ],
      "source": [
        "from flaml.ml import sklearn_metric_loss_score\n",
        "#print('accuracy', '=', 1 - sklearn_metric_loss_score('accuracy', y_pred, y_test))\n",
        "print('r2', '=', 1 - sklearn_metric_loss_score('r2', y_pred, y_test))\n",
        "print('mse', '=', sklearn_metric_loss_score('mse', y_pred, y_test))\n",
        "print('mae', '=', sklearn_metric_loss_score('mae', y_pred, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c8e7baa",
      "metadata": {
        "id": "5c8e7baa",
        "outputId": "a9a770d7-626b-43a1-8944-b06afb21705f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Current Learner': 'xgboost', 'Current Sample': 15480, 'Current Hyper-parameters': {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 0.9999999999999993, 'learning_rate': 0.09999999999999995, 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.0}, 'Best Learner': 'xgboost', 'Best Hyper-parameters': {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 0.9999999999999993, 'learning_rate': 0.09999999999999995, 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.0}}\n",
            "{'Current Learner': 'lgbm', 'Current Sample': 15480, 'Current Hyper-parameters': {'n_estimators': 4, 'num_leaves': 4, 'min_child_samples': 20, 'learning_rate': 0.09999999999999995, 'log_max_bin': 8, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.0}, 'Best Learner': 'lgbm', 'Best Hyper-parameters': {'n_estimators': 4, 'num_leaves': 4, 'min_child_samples': 20, 'learning_rate': 0.09999999999999995, 'log_max_bin': 8, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.0}}\n",
            "{'Current Learner': 'lgbm', 'Current Sample': 15480, 'Current Hyper-parameters': {'n_estimators': 9, 'num_leaves': 4, 'min_child_samples': 28, 'learning_rate': 0.20176123704491705, 'log_max_bin': 7, 'colsample_bytree': 0.9314232379468054, 'reg_alpha': 0.0012314819445617192, 'reg_lambda': 9.114157883298441}, 'Best Learner': 'lgbm', 'Best Hyper-parameters': {'n_estimators': 9, 'num_leaves': 4, 'min_child_samples': 28, 'learning_rate': 0.20176123704491705, 'log_max_bin': 7, 'colsample_bytree': 0.9314232379468054, 'reg_alpha': 0.0012314819445617192, 'reg_lambda': 9.114157883298441}}\n",
            "{'Current Learner': 'lgbm', 'Current Sample': 15480, 'Current Hyper-parameters': {'n_estimators': 6, 'num_leaves': 4, 'min_child_samples': 61, 'learning_rate': 0.36577797144209806, 'log_max_bin': 8, 'colsample_bytree': 0.937620536138218, 'reg_alpha': 0.002576372585734981, 'reg_lambda': 5.496308954481066}, 'Best Learner': 'lgbm', 'Best Hyper-parameters': {'n_estimators': 6, 'num_leaves': 4, 'min_child_samples': 61, 'learning_rate': 0.36577797144209806, 'log_max_bin': 8, 'colsample_bytree': 0.937620536138218, 'reg_alpha': 0.002576372585734981, 'reg_lambda': 5.496308954481066}}\n",
            "{'Current Learner': 'lgbm', 'Current Sample': 15480, 'Current Hyper-parameters': {'n_estimators': 8, 'num_leaves': 10, 'min_child_samples': 28, 'learning_rate': 0.2017612370449172, 'log_max_bin': 7, 'colsample_bytree': 0.9314232379468054, 'reg_alpha': 0.0012314819445617194, 'reg_lambda': 9.114157883298441}, 'Best Learner': 'lgbm', 'Best Hyper-parameters': {'n_estimators': 8, 'num_leaves': 10, 'min_child_samples': 28, 'learning_rate': 0.2017612370449172, 'log_max_bin': 7, 'colsample_bytree': 0.9314232379468054, 'reg_alpha': 0.0012314819445617194, 'reg_lambda': 9.114157883298441}}\n",
            "{'Current Learner': 'xgboost', 'Current Sample': 15480, 'Current Hyper-parameters': {'n_estimators': 4, 'max_leaves': 19, 'min_child_weight': 7.7498252354192525, 'learning_rate': 0.5614525792907483, 'subsample': 0.8682107206706305, 'colsample_bylevel': 0.9814926103574051, 'colsample_bytree': 0.9637227875682511, 'reg_alpha': 0.01901656243042618, 'reg_lambda': 7.905641865583111}, 'Best Learner': 'xgboost', 'Best Hyper-parameters': {'n_estimators': 4, 'max_leaves': 19, 'min_child_weight': 7.7498252354192525, 'learning_rate': 0.5614525792907483, 'subsample': 0.8682107206706305, 'colsample_bylevel': 0.9814926103574051, 'colsample_bytree': 0.9637227875682511, 'reg_alpha': 0.01901656243042618, 'reg_lambda': 7.905641865583111}}\n",
            "{'Current Learner': 'lgbm', 'Current Sample': 15480, 'Current Hyper-parameters': {'n_estimators': 27, 'num_leaves': 48, 'min_child_samples': 37, 'learning_rate': 0.44513640053511977, 'log_max_bin': 6, 'colsample_bytree': 1.0, 'reg_alpha': 0.0023163407854001295, 'reg_lambda': 840.1909058267559}, 'Best Learner': 'lgbm', 'Best Hyper-parameters': {'n_estimators': 27, 'num_leaves': 48, 'min_child_samples': 37, 'learning_rate': 0.44513640053511977, 'log_max_bin': 6, 'colsample_bytree': 1.0, 'reg_alpha': 0.0023163407854001295, 'reg_lambda': 840.1909058267559}}\n",
            "{'Current Learner': 'lgbm', 'Current Sample': 15480, 'Current Hyper-parameters': {'n_estimators': 47, 'num_leaves': 21, 'min_child_samples': 38, 'learning_rate': 0.4732324793353391, 'log_max_bin': 7, 'colsample_bytree': 1.0, 'reg_alpha': 0.05459907332416601, 'reg_lambda': 1002.5603227054668}, 'Best Learner': 'lgbm', 'Best Hyper-parameters': {'n_estimators': 47, 'num_leaves': 21, 'min_child_samples': 38, 'learning_rate': 0.4732324793353391, 'log_max_bin': 7, 'colsample_bytree': 1.0, 'reg_alpha': 0.05459907332416601, 'reg_lambda': 1002.5603227054668}}\n",
            "{'Current Learner': 'lgbm', 'Current Sample': 15480, 'Current Hyper-parameters': {'n_estimators': 67, 'num_leaves': 108, 'min_child_samples': 48, 'learning_rate': 0.4619435287144398, 'log_max_bin': 8, 'colsample_bytree': 0.9658460846273239, 'reg_alpha': 0.024216249836091042, 'reg_lambda': 1024.0}, 'Best Learner': 'lgbm', 'Best Hyper-parameters': {'n_estimators': 67, 'num_leaves': 108, 'min_child_samples': 48, 'learning_rate': 0.4619435287144398, 'log_max_bin': 8, 'colsample_bytree': 0.9658460846273239, 'reg_alpha': 0.024216249836091042, 'reg_lambda': 1024.0}}\n",
            "{'Current Learner': 'lgbm', 'Current Sample': 15480, 'Current Hyper-parameters': {'n_estimators': 380, 'num_leaves': 84, 'min_child_samples': 63, 'learning_rate': 0.32211978809524644, 'log_max_bin': 8, 'colsample_bytree': 1.0, 'reg_alpha': 0.0094126519923551, 'reg_lambda': 495.42920908748346}, 'Best Learner': 'lgbm', 'Best Hyper-parameters': {'n_estimators': 380, 'num_leaves': 84, 'min_child_samples': 63, 'learning_rate': 0.32211978809524644, 'log_max_bin': 8, 'colsample_bytree': 1.0, 'reg_alpha': 0.0094126519923551, 'reg_lambda': 495.42920908748346}}\n"
          ]
        }
      ],
      "source": [
        "from flaml.data import get_output_from_log\n",
        "time_history, best_valid_loss_history, valid_loss_history, config_history, metric_history = \\\n",
        "    get_output_from_log(filename=settings['log_file_name'], time_budget=240)\n",
        "for config in config_history:\n",
        "    print(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a08a6fc1",
      "metadata": {
        "id": "a08a6fc1",
        "outputId": "b27ca0c0-7b70-41da-e9f2-da421a622cf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "plt.title('Learning Curve')\n",
        "plt.xlabel('Wall Clock Time (s)')\n",
        "plt.ylabel('Validation Accuracy')\n",
        "plt.scatter(time_history, 1 - np.array(valid_loss_history))\n",
        "plt.step(time_history, 1 - np.array(best_valid_loss_history), where='post')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84ea470d",
      "metadata": {
        "id": "84ea470d"
      },
      "outputs": [],
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "lgbm = LGBMClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d88c8bc",
      "metadata": {
        "id": "4d88c8bc"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder = label_encoder.fit(y_train)\n",
        "Y_train = label_encoder.transform(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cffc2ad2",
      "metadata": {
        "id": "cffc2ad2",
        "outputId": "c6066021-4462-4146-8621-f8526a6d0b23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LGBMClassifier()"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "lgbm.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ace93d3c",
      "metadata": {
        "id": "ace93d3c"
      },
      "outputs": [],
      "source": [
        "y_pred_lgbm = lgbm.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da1978ee",
      "metadata": {
        "id": "da1978ee"
      },
      "outputs": [],
      "source": [
        "#from xgboost import XGBClassifier\n",
        "#xgb = XGBClassifier()\n",
        "#cat_columns = X_train.select_dtypes(include=['category']).columns\n",
        "#X = X_train.copy()\n",
        "#X[cat_columns] = X[cat_columns].apply(lambda x: x.cat.codes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b3f6751",
      "metadata": {
        "id": "8b3f6751"
      },
      "outputs": [],
      "source": [
        "#from sklearn.preprocessing import LabelEncoder\n",
        "#label_encoder = LabelEncoder()\n",
        "#label_encoder = label_encoder.fit(y_train)\n",
        "#y_train = label_encoder.transform(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3d81000",
      "metadata": {
        "id": "c3d81000"
      },
      "outputs": [],
      "source": [
        "#xgb.fit(X, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44eb980c",
      "metadata": {
        "id": "44eb980c"
      },
      "outputs": [],
      "source": [
        "#X = X_test.copy()\n",
        "##X[cat_columns] = X[cat_columns].apply(lambda x: x.cat.codes)\n",
        "#y_pred_xgb = xgb.predict(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e0188f1",
      "metadata": {
        "id": "4e0188f1"
      },
      "outputs": [],
      "source": [
        "#y_test = [float(x) for x in np.array(y_test)]\n",
        "#y_pred_lgbm = [float(x) for x in np.array(y_pred_lgbm)]\n",
        "#y_pred = [float(x) for x in np.array(y_pred)]\n",
        "#print (y_pred_lgbm)\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder_ytest = label_encoder.fit(y_test)\n",
        "Y_test = label_encoder_ytest.transform(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "916ba0ea",
      "metadata": {
        "id": "916ba0ea"
      },
      "outputs": [],
      "source": [
        "#from catboost import CatBoostClassifier\n",
        "#cat = CatBoostClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "640d6923",
      "metadata": {
        "id": "640d6923"
      },
      "outputs": [],
      "source": [
        "#cat.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87d370ed",
      "metadata": {
        "id": "87d370ed"
      },
      "outputs": [],
      "source": [
        "#y_pred_cat = cat.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db4e9c3b",
      "metadata": {
        "id": "db4e9c3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5594c57a-6bd7-4954-9d5c-910db0fbebc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "default lgbm accuracy = -1.3042519058160065\n",
            "flaml (5 min) r2 = -25132016.474995118\n",
            "r2 = -25132016.474995118\n",
            "mse = 3185549.9429605766\n",
            "mae = 1534.908478832173\n"
          ]
        }
      ],
      "source": [
        "#print('default xgboost accuracy', '=', 1 - sklearn_metric_loss_score('accuracy', y_pred_xgb, Y_test))\n",
        "print('default lgbm accuracy', '=', 1 - sklearn_metric_loss_score('r2', y_pred_lgbm, Y_test))\n",
        "#print('default catboost accuracy', '=', 1 - sklearn_metric_loss_score('accuracy', y_pred_cat, Y_test))\n",
        "print('flaml (5 min) r2', '=', 1 - sklearn_metric_loss_score('r2', y_pred, y_test))\n",
        "print('r2', '=', 1 - sklearn_metric_loss_score('r2', y_pred, y_test))\n",
        "print('mse', '=', sklearn_metric_loss_score('mse', y_pred, y_test))\n",
        "print('mae', '=', sklearn_metric_loss_score('mae', y_pred, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install optuna==2.8.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_2a9NZZ6H_V",
        "outputId": "83b0e7c4-eeac-4b44-d959-c572e2e8cc80"
      },
      "id": "i_2a9NZZ6H_V",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: optuna==2.8.0 in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
            "Requirement already satisfied: cmaes>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from optuna==2.8.0) (0.9.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna==2.8.0) (21.3)\n",
            "Requirement already satisfied: cliff in /usr/local/lib/python3.7/dist-packages (from optuna==2.8.0) (3.10.1)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.7/dist-packages (from optuna==2.8.0) (6.7.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna==2.8.0) (4.64.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna==2.8.0) (1.4.43)\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna==2.8.0) (1.7.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna==2.8.0) (1.21.6)\n",
            "Requirement already satisfied: alembic in /usr/local/lib/python3.7/dist-packages (from optuna==2.8.0) (1.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna==2.8.0) (3.0.9)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna==2.8.0) (2.0.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna==2.8.0) (4.13.0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.7/dist-packages (from alembic->optuna==2.8.0) (1.2.3)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic->optuna==2.8.0) (5.10.0)\n",
            "Requirement already satisfied: autopage>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna==2.8.0) (0.5.1)\n",
            "Requirement already satisfied: PyYAML>=3.12 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna==2.8.0) (6.0)\n",
            "Requirement already satisfied: cmd2>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna==2.8.0) (2.4.2)\n",
            "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna==2.8.0) (5.11.0)\n",
            "Requirement already satisfied: stevedore>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna==2.8.0) (3.5.2)\n",
            "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna==2.8.0) (3.5.0)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna==2.8.0) (0.2.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna==2.8.0) (4.1.1)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna==2.8.0) (22.1.0)\n",
            "Requirement already satisfied: pyperclip>=1.6 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna==2.8.0) (1.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna==2.8.0) (3.10.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna==2.8.0) (2.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_x, val_x, train_y, val_y = train_test_split(X_train, y_train, test_size=0.1)\n",
        "import optuna.integration.lightgbm as lgb\n",
        "dtrain = lgb.Dataset(train_x, label=train_y)\n",
        "dval = lgb.Dataset(val_x, label=val_y)\n",
        "params = {\n",
        "    \"objective\": \"regression\",\n",
        "    \"metric\": \"regression\",\n",
        "    \"verbosity\": -1,\n",
        "}"
      ],
      "metadata": {
        "id": "8iCLlBrO6IRo"
      },
      "id": "8iCLlBrO6IRo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "model = lgb.train(params, dtrain, valid_sets=[dtrain, dval], verbose_eval=10000) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5KgF_5r6NyN",
        "outputId": "29a7ad48-c6bd-4488-fbbf-e1ec5c164179"
      },
      "id": "s5KgF_5r6NyN",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-11-10 19:32:05,448]\u001b[0m A new study created in memory with name: no-name-c8cd7215-8b0a-4f8a-9cf0-0e5a36b55c45\u001b[0m\n",
            "feature_fraction, val_score: inf:   0%|          | 0/7 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "feature_fraction, val_score: 145402.173901:  14%|#4        | 1/7 [00:02<00:16,  2.77s/it]\u001b[32m[I 2022-11-10 19:32:08,234]\u001b[0m Trial 0 finished with value: 145402.1739008843 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 0 with value: 145402.1739008843.\u001b[0m\n",
            "feature_fraction, val_score: 145402.173901:  29%|##8       | 2/7 [00:11<00:32,  6.49s/it]\u001b[32m[I 2022-11-10 19:32:17,325]\u001b[0m Trial 1 finished with value: 149604.23608478418 and parameters: {'feature_fraction': 0.6}. Best is trial 0 with value: 145402.1739008843.\u001b[0m\n",
            "feature_fraction, val_score: 145402.173901:  43%|####2     | 3/7 [00:21<00:32,  8.04s/it]\u001b[32m[I 2022-11-10 19:32:27,212]\u001b[0m Trial 2 finished with value: 150293.7718278574 and parameters: {'feature_fraction': 0.5}. Best is trial 0 with value: 145402.1739008843.\u001b[0m\n",
            "feature_fraction, val_score: 145402.173901:  57%|#####7    | 4/7 [00:32<00:26,  8.93s/it]\u001b[32m[I 2022-11-10 19:32:37,504]\u001b[0m Trial 3 finished with value: 145727.8016390479 and parameters: {'feature_fraction': 0.8}. Best is trial 0 with value: 145402.1739008843.\u001b[0m\n",
            "feature_fraction, val_score: 145402.173901:  71%|#######1  | 5/7 [00:34<00:12,  6.42s/it]\u001b[32m[I 2022-11-10 19:32:39,478]\u001b[0m Trial 4 finished with value: 145727.8016390479 and parameters: {'feature_fraction': 0.7}. Best is trial 0 with value: 145402.1739008843.\u001b[0m\n",
            "feature_fraction, val_score: 145402.173901:  86%|########5 | 6/7 [00:36<00:04,  4.99s/it]\u001b[32m[I 2022-11-10 19:32:41,678]\u001b[0m Trial 5 finished with value: 152540.8565157757 and parameters: {'feature_fraction': 1.0}. Best is trial 0 with value: 145402.1739008843.\u001b[0m\n",
            "feature_fraction, val_score: 145402.173901: 100%|##########| 7/7 [00:37<00:00,  3.92s/it]\u001b[32m[I 2022-11-10 19:32:43,410]\u001b[0m Trial 6 finished with value: 150803.99663946524 and parameters: {'feature_fraction': 0.4}. Best is trial 0 with value: 145402.1739008843.\u001b[0m\n",
            "feature_fraction, val_score: 145402.173901: 100%|##########| 7/7 [00:37<00:00,  5.42s/it]\n",
            "num_leaves, val_score: 145402.173901:   5%|5         | 1/20 [00:04<01:28,  4.67s/it]\u001b[32m[I 2022-11-10 19:32:48,106]\u001b[0m Trial 7 finished with value: 151416.39139871404 and parameters: {'num_leaves': 96}. Best is trial 7 with value: 151416.39139871404.\u001b[0m\n",
            "num_leaves, val_score: 145402.173901:  10%|#         | 2/20 [00:10<01:41,  5.64s/it]\u001b[32m[I 2022-11-10 19:32:54,433]\u001b[0m Trial 8 finished with value: 155039.6757640944 and parameters: {'num_leaves': 138}. Best is trial 7 with value: 151416.39139871404.\u001b[0m\n",
            "num_leaves, val_score: 145402.173901:  15%|#5        | 3/20 [00:20<02:06,  7.44s/it]\u001b[32m[I 2022-11-10 19:33:04,013]\u001b[0m Trial 9 finished with value: 153972.27838362165 and parameters: {'num_leaves': 221}. Best is trial 7 with value: 151416.39139871404.\u001b[0m\n",
            "num_leaves, val_score: 145402.173901:  20%|##        | 4/20 [00:28<02:02,  7.67s/it]\u001b[32m[I 2022-11-10 19:33:12,029]\u001b[0m Trial 10 finished with value: 152574.20414270667 and parameters: {'num_leaves': 182}. Best is trial 7 with value: 151416.39139871404.\u001b[0m\n",
            "num_leaves, val_score: 145402.173901:  25%|##5       | 5/20 [00:30<01:26,  5.76s/it]\u001b[32m[I 2022-11-10 19:33:14,416]\u001b[0m Trial 11 finished with value: 147116.06347147518 and parameters: {'num_leaves': 37}. Best is trial 11 with value: 147116.06347147518.\u001b[0m\n",
            "num_leaves, val_score: 145402.173901:  30%|###       | 6/20 [00:31<00:56,  4.06s/it]\u001b[32m[I 2022-11-10 19:33:15,170]\u001b[0m Trial 12 finished with value: 182961.7590347785 and parameters: {'num_leaves': 3}. Best is trial 11 with value: 147116.06347147518.\u001b[0m\n",
            "num_leaves, val_score: 145402.173901:  35%|###5      | 7/20 [00:33<00:41,  3.23s/it]\u001b[32m[I 2022-11-10 19:33:16,685]\u001b[0m Trial 13 finished with value: 151532.01849153038 and parameters: {'num_leaves': 15}. Best is trial 11 with value: 147116.06347147518.\u001b[0m\n",
            "num_leaves, val_score: 145402.173901:  40%|####      | 8/20 [00:37<00:42,  3.58s/it]\u001b[32m[I 2022-11-10 19:33:21,010]\u001b[0m Trial 14 finished with value: 147188.74895412364 and parameters: {'num_leaves': 86}. Best is trial 11 with value: 147116.06347147518.\u001b[0m\n",
            "num_leaves, val_score: 145402.173901:  45%|####5     | 9/20 [00:39<00:33,  3.02s/it]\u001b[32m[I 2022-11-10 19:33:22,811]\u001b[0m Trial 15 finished with value: 149471.71438617323 and parameters: {'num_leaves': 22}. Best is trial 11 with value: 147116.06347147518.\u001b[0m\n",
            "num_leaves, val_score: 145402.173901:  50%|#####     | 10/20 [00:48<00:48,  4.86s/it]\u001b[32m[I 2022-11-10 19:33:31,789]\u001b[0m Trial 16 finished with value: 151628.4926321099 and parameters: {'num_leaves': 199}. Best is trial 11 with value: 147116.06347147518.\u001b[0m\n",
            "num_leaves, val_score: 145402.173901:  55%|#####5    | 11/20 [00:51<00:37,  4.19s/it]\u001b[32m[I 2022-11-10 19:33:34,466]\u001b[0m Trial 17 finished with value: 146386.83776756556 and parameters: {'num_leaves': 45}. Best is trial 17 with value: 146386.83776756556.\u001b[0m\n",
            "num_leaves, val_score: 145402.173901:  60%|######    | 12/20 [00:54<00:31,  3.90s/it]\u001b[32m[I 2022-11-10 19:33:37,684]\u001b[0m Trial 18 finished with value: 148727.62030890855 and parameters: {'num_leaves': 60}. Best is trial 17 with value: 146386.83776756556.\u001b[0m\n",
            "num_leaves, val_score: 145402.173901:  65%|######5   | 13/20 [00:57<00:25,  3.60s/it]\u001b[32m[I 2022-11-10 19:33:40,600]\u001b[0m Trial 19 finished with value: 149141.2290268296 and parameters: {'num_leaves': 50}. Best is trial 17 with value: 146386.83776756556.\u001b[0m\n",
            "num_leaves, val_score: 145402.173901:  70%|#######   | 14/20 [01:03<00:26,  4.39s/it]\u001b[32m[I 2022-11-10 19:33:46,830]\u001b[0m Trial 20 finished with value: 153666.96528052073 and parameters: {'num_leaves': 134}. Best is trial 17 with value: 146386.83776756556.\u001b[0m\n",
            "num_leaves, val_score: 145402.173901:  75%|#######5  | 15/20 [01:06<00:19,  3.87s/it]\u001b[32m[I 2022-11-10 19:33:49,483]\u001b[0m Trial 21 finished with value: 152233.40011864642 and parameters: {'num_leaves': 44}. Best is trial 17 with value: 146386.83776756556.\u001b[0m\n",
            "num_leaves, val_score: 145402.173901:  80%|########  | 16/20 [01:10<00:16,  4.12s/it]\u001b[32m[I 2022-11-10 19:33:54,191]\u001b[0m Trial 22 finished with value: 148070.2905883162 and parameters: {'num_leaves': 95}. Best is trial 17 with value: 146386.83776756556.\u001b[0m\n",
            "num_leaves, val_score: 145402.173901:  85%|########5 | 17/20 [01:11<00:09,  3.15s/it]\u001b[32m[I 2022-11-10 19:33:55,081]\u001b[0m Trial 23 finished with value: 167172.3750499696 and parameters: {'num_leaves': 4}. Best is trial 17 with value: 146386.83776756556.\u001b[0m\n",
            "num_leaves, val_score: 145402.173901:  90%|######### | 18/20 [01:15<00:06,  3.32s/it]\u001b[32m[I 2022-11-10 19:33:58,787]\u001b[0m Trial 24 finished with value: 149664.46983310164 and parameters: {'num_leaves': 72}. Best is trial 17 with value: 146386.83776756556.\u001b[0m\n",
            "num_leaves, val_score: 145402.173901:  95%|#########5| 19/20 [01:18<00:03,  3.20s/it]\u001b[32m[I 2022-11-10 19:34:01,711]\u001b[0m Trial 25 finished with value: 147205.5004346438 and parameters: {'num_leaves': 34}. Best is trial 17 with value: 146386.83776756556.\u001b[0m\n",
            "num_leaves, val_score: 145402.173901: 100%|##########| 20/20 [01:26<00:00,  4.72s/it]\u001b[32m[I 2022-11-10 19:34:09,973]\u001b[0m Trial 26 finished with value: 148330.1057775252 and parameters: {'num_leaves': 114}. Best is trial 17 with value: 146386.83776756556.\u001b[0m\n",
            "num_leaves, val_score: 145402.173901: 100%|##########| 20/20 [01:26<00:00,  4.33s/it]\n",
            "bagging, val_score: 145402.173901:  10%|#         | 1/10 [00:06<00:54,  6.09s/it]\u001b[32m[I 2022-11-10 19:34:16,089]\u001b[0m Trial 27 finished with value: 150952.82731992815 and parameters: {'bagging_fraction': 0.8174136040653037, 'bagging_freq': 6}. Best is trial 27 with value: 150952.82731992815.\u001b[0m\n",
            "bagging, val_score: 145402.173901:  20%|##        | 2/10 [00:09<00:34,  4.37s/it]\u001b[32m[I 2022-11-10 19:34:19,244]\u001b[0m Trial 28 finished with value: 156130.60513117694 and parameters: {'bagging_fraction': 0.5151716157328605, 'bagging_freq': 6}. Best is trial 27 with value: 150952.82731992815.\u001b[0m\n",
            "bagging, val_score: 145402.173901:  30%|###       | 3/10 [00:12<00:25,  3.68s/it]\u001b[32m[I 2022-11-10 19:34:22,103]\u001b[0m Trial 29 finished with value: 148600.1157863396 and parameters: {'bagging_fraction': 0.8758142380754236, 'bagging_freq': 5}. Best is trial 29 with value: 148600.1157863396.\u001b[0m\n",
            "bagging, val_score: 145402.173901:  40%|####      | 4/10 [00:16<00:22,  3.82s/it]\u001b[32m[I 2022-11-10 19:34:26,145]\u001b[0m Trial 30 finished with value: 149157.55805135463 and parameters: {'bagging_fraction': 0.9889398529475416, 'bagging_freq': 1}. Best is trial 29 with value: 148600.1157863396.\u001b[0m\n",
            "bagging, val_score: 145402.173901:  50%|#####     | 5/10 [00:19<00:17,  3.47s/it]\u001b[32m[I 2022-11-10 19:34:28,997]\u001b[0m Trial 31 finished with value: 152186.13126052424 and parameters: {'bagging_fraction': 0.7994225857884643, 'bagging_freq': 6}. Best is trial 29 with value: 148600.1157863396.\u001b[0m\n",
            "bagging, val_score: 145402.173901:  60%|######    | 6/10 [00:22<00:13,  3.32s/it]\u001b[32m[I 2022-11-10 19:34:32,013]\u001b[0m Trial 32 finished with value: 156622.5870933075 and parameters: {'bagging_fraction': 0.6075622540907596, 'bagging_freq': 5}. Best is trial 29 with value: 148600.1157863396.\u001b[0m\n",
            "bagging, val_score: 145402.173901:  70%|#######   | 7/10 [00:24<00:09,  3.15s/it]\u001b[32m[I 2022-11-10 19:34:34,834]\u001b[0m Trial 33 finished with value: 153712.63418879555 and parameters: {'bagging_fraction': 0.8475638875740332, 'bagging_freq': 3}. Best is trial 29 with value: 148600.1157863396.\u001b[0m\n",
            "bagging, val_score: 145402.173901:  80%|########  | 8/10 [00:27<00:06,  3.08s/it]\u001b[32m[I 2022-11-10 19:34:37,760]\u001b[0m Trial 34 finished with value: 152017.22147054967 and parameters: {'bagging_fraction': 0.6910963178186873, 'bagging_freq': 7}. Best is trial 29 with value: 148600.1157863396.\u001b[0m\n",
            "bagging, val_score: 145402.173901:  90%|######### | 9/10 [00:30<00:03,  3.05s/it]\u001b[32m[I 2022-11-10 19:34:40,750]\u001b[0m Trial 35 finished with value: 154580.16396192642 and parameters: {'bagging_fraction': 0.6508808462930197, 'bagging_freq': 7}. Best is trial 29 with value: 148600.1157863396.\u001b[0m\n",
            "bagging, val_score: 145402.173901: 100%|##########| 10/10 [00:33<00:00,  3.06s/it]\u001b[32m[I 2022-11-10 19:34:43,819]\u001b[0m Trial 36 finished with value: 152789.57376056953 and parameters: {'bagging_fraction': 0.6658090341596479, 'bagging_freq': 2}. Best is trial 29 with value: 148600.1157863396.\u001b[0m\n",
            "bagging, val_score: 145402.173901: 100%|##########| 10/10 [00:33<00:00,  3.38s/it]\n",
            "feature_fraction_stage2, val_score: 145402.173901:  17%|#6        | 1/6 [00:02<00:11,  2.25s/it]\u001b[32m[I 2022-11-10 19:34:46,089]\u001b[0m Trial 37 finished with value: 152540.8565157757 and parameters: {'feature_fraction': 0.9799999999999999}. Best is trial 37 with value: 152540.8565157757.\u001b[0m\n",
            "feature_fraction_stage2, val_score: 145402.173901:  33%|###3      | 2/6 [00:04<00:08,  2.22s/it]\u001b[32m[I 2022-11-10 19:34:48,295]\u001b[0m Trial 38 finished with value: 152540.8565157757 and parameters: {'feature_fraction': 0.948}. Best is trial 37 with value: 152540.8565157757.\u001b[0m\n",
            "feature_fraction_stage2, val_score: 145402.173901:  50%|#####     | 3/6 [00:06<00:06,  2.27s/it]\u001b[32m[I 2022-11-10 19:34:50,632]\u001b[0m Trial 39 finished with value: 145402.1739008843 and parameters: {'feature_fraction': 0.82}. Best is trial 39 with value: 145402.1739008843.\u001b[0m\n",
            "feature_fraction_stage2, val_score: 145402.173901:  67%|######6   | 4/6 [00:08<00:04,  2.24s/it]\u001b[32m[I 2022-11-10 19:34:52,811]\u001b[0m Trial 40 finished with value: 145402.1739008843 and parameters: {'feature_fraction': 0.852}. Best is trial 39 with value: 145402.1739008843.\u001b[0m\n",
            "feature_fraction_stage2, val_score: 145402.173901:  83%|########3 | 5/6 [00:11<00:02,  2.21s/it]\u001b[32m[I 2022-11-10 19:34:54,965]\u001b[0m Trial 41 finished with value: 145402.1739008843 and parameters: {'feature_fraction': 0.9159999999999999}. Best is trial 39 with value: 145402.1739008843.\u001b[0m\n",
            "feature_fraction_stage2, val_score: 145402.173901: 100%|##########| 6/6 [00:13<00:00,  2.19s/it]\u001b[32m[I 2022-11-10 19:34:57,119]\u001b[0m Trial 42 finished with value: 145402.1739008843 and parameters: {'feature_fraction': 0.8839999999999999}. Best is trial 39 with value: 145402.1739008843.\u001b[0m\n",
            "feature_fraction_stage2, val_score: 145402.173901: 100%|##########| 6/6 [00:13<00:00,  2.21s/it]\n",
            "regularization_factors, val_score: 145402.172931:   5%|5         | 1/20 [00:02<00:43,  2.29s/it]\u001b[32m[I 2022-11-10 19:34:59,424]\u001b[0m Trial 43 finished with value: 145402.1729310215 and parameters: {'lambda_l1': 5.485616507662499e-06, 'lambda_l2': 4.285377631241825e-06}. Best is trial 43 with value: 145402.1729310215.\u001b[0m\n",
            "regularization_factors, val_score: 144146.582772:  10%|#         | 2/20 [00:04<00:40,  2.27s/it]\u001b[32m[I 2022-11-10 19:35:01,687]\u001b[0m Trial 44 finished with value: 144146.58277217348 and parameters: {'lambda_l1': 0.19347942125375422, 'lambda_l2': 1.9227951301224e-07}. Best is trial 44 with value: 144146.58277217348.\u001b[0m\n",
            "regularization_factors, val_score: 144146.582772:  15%|#5        | 3/20 [00:06<00:38,  2.25s/it]\u001b[32m[I 2022-11-10 19:35:03,922]\u001b[0m Trial 45 finished with value: 148245.10736462486 and parameters: {'lambda_l1': 1.112694484112261e-06, 'lambda_l2': 0.1118508626994239}. Best is trial 44 with value: 144146.58277217348.\u001b[0m\n",
            "regularization_factors, val_score: 144146.582772:  20%|##        | 4/20 [00:09<00:35,  2.25s/it]\u001b[32m[I 2022-11-10 19:35:06,159]\u001b[0m Trial 46 finished with value: 145402.17389213998 and parameters: {'lambda_l1': 1.5723148917348605e-08, 'lambda_l2': 3.664658919923927e-08}. Best is trial 44 with value: 144146.58277217348.\u001b[0m\n",
            "regularization_factors, val_score: 144146.582772:  25%|##5       | 5/20 [00:11<00:33,  2.26s/it]\u001b[32m[I 2022-11-10 19:35:08,434]\u001b[0m Trial 47 finished with value: 145402.17370804632 and parameters: {'lambda_l1': 1.1401876429276097e-05, 'lambda_l2': 8.645858621380952e-07}. Best is trial 44 with value: 144146.58277217348.\u001b[0m\n",
            "regularization_factors, val_score: 144146.582772:  30%|###       | 6/20 [00:13<00:31,  2.27s/it]\u001b[32m[I 2022-11-10 19:35:10,731]\u001b[0m Trial 48 finished with value: 145402.17376895042 and parameters: {'lambda_l1': 7.156093434495805e-07, 'lambda_l2': 6.514594097013733e-07}. Best is trial 44 with value: 144146.58277217348.\u001b[0m\n",
            "regularization_factors, val_score: 144146.582772:  35%|###5      | 7/20 [00:15<00:29,  2.27s/it]\u001b[32m[I 2022-11-10 19:35:12,990]\u001b[0m Trial 49 finished with value: 147456.1823902661 and parameters: {'lambda_l1': 5.2893625111732875e-05, 'lambda_l2': 0.02038615873353984}. Best is trial 44 with value: 144146.58277217348.\u001b[0m\n",
            "regularization_factors, val_score: 144146.582772:  40%|####      | 8/20 [00:18<00:27,  2.27s/it]\u001b[32m[I 2022-11-10 19:35:15,277]\u001b[0m Trial 50 finished with value: 146087.5137083765 and parameters: {'lambda_l1': 0.13182506105415687, 'lambda_l2': 7.119271244703367e-07}. Best is trial 44 with value: 144146.58277217348.\u001b[0m\n",
            "regularization_factors, val_score: 144146.582772:  45%|####5     | 9/20 [00:20<00:25,  2.29s/it]\u001b[32m[I 2022-11-10 19:35:17,596]\u001b[0m Trial 51 finished with value: 146982.51791832695 and parameters: {'lambda_l1': 2.314860158594459e-05, 'lambda_l2': 3.4117050555532735}. Best is trial 44 with value: 144146.58277217348.\u001b[0m\n",
            "regularization_factors, val_score: 144146.582772:  50%|#####     | 10/20 [00:22<00:22,  2.29s/it]\u001b[32m[I 2022-11-10 19:35:19,893]\u001b[0m Trial 52 finished with value: 145402.17389379087 and parameters: {'lambda_l1': 1.7197233202951514e-07, 'lambda_l2': 6.175146926761645e-08}. Best is trial 44 with value: 144146.58277217348.\u001b[0m\n",
            "regularization_factors, val_score: 144146.582772:  55%|#####5    | 11/20 [00:25<00:20,  2.30s/it]\u001b[32m[I 2022-11-10 19:35:22,205]\u001b[0m Trial 53 finished with value: 148914.55778304115 and parameters: {'lambda_l1': 2.370248174632029, 'lambda_l2': 4.494983779128513e-05}. Best is trial 44 with value: 144146.58277217348.\u001b[0m\n",
            "regularization_factors, val_score: 144146.582772:  60%|######    | 12/20 [00:27<00:18,  2.31s/it]\u001b[32m[I 2022-11-10 19:35:24,537]\u001b[0m Trial 54 finished with value: 145402.1490070354 and parameters: {'lambda_l1': 0.007310857553780388, 'lambda_l2': 3.933625954238338e-05}. Best is trial 44 with value: 144146.58277217348.\u001b[0m\n",
            "regularization_factors, val_score: 144146.582772:  65%|######5   | 13/20 [00:29<00:16,  2.31s/it]\u001b[32m[I 2022-11-10 19:35:26,848]\u001b[0m Trial 55 finished with value: 144734.1387785525 and parameters: {'lambda_l1': 0.006856953461560711, 'lambda_l2': 0.0011440471628016357}. Best is trial 44 with value: 144146.58277217348.\u001b[0m\n",
            "regularization_factors, val_score: 144146.582772:  70%|#######   | 14/20 [00:31<00:13,  2.30s/it]\u001b[32m[I 2022-11-10 19:35:29,130]\u001b[0m Trial 56 finished with value: 144733.8623457379 and parameters: {'lambda_l1': 0.0034431559271349615, 'lambda_l2': 0.00220550901505234}. Best is trial 44 with value: 144146.58277217348.\u001b[0m\n",
            "regularization_factors, val_score: 144146.582772:  75%|#######5  | 15/20 [00:34<00:11,  2.31s/it]\u001b[32m[I 2022-11-10 19:35:31,453]\u001b[0m Trial 57 finished with value: 147807.64988690912 and parameters: {'lambda_l1': 0.0025288524162504714, 'lambda_l2': 0.005129902546418847}. Best is trial 44 with value: 144146.58277217348.\u001b[0m\n",
            "regularization_factors, val_score: 144146.582772:  80%|########  | 16/20 [00:36<00:09,  2.31s/it]\u001b[32m[I 2022-11-10 19:35:33,774]\u001b[0m Trial 58 finished with value: 150280.1285381596 and parameters: {'lambda_l1': 5.223369055497152, 'lambda_l2': 0.6265803342846891}. Best is trial 44 with value: 144146.58277217348.\u001b[0m\n",
            "regularization_factors, val_score: 144146.559870:  85%|########5 | 17/20 [00:38<00:06,  2.31s/it]\u001b[32m[I 2022-11-10 19:35:36,082]\u001b[0m Trial 59 finished with value: 144146.55986989368 and parameters: {'lambda_l1': 0.18320682014983003, 'lambda_l2': 0.00017106817965028106}. Best is trial 59 with value: 144146.55986989368.\u001b[0m\n",
            "regularization_factors, val_score: 144146.559870:  90%|######### | 18/20 [00:41<00:04,  2.31s/it]\u001b[32m[I 2022-11-10 19:35:38,392]\u001b[0m Trial 60 finished with value: 144146.56611101815 and parameters: {'lambda_l1': 0.1907769914491844, 'lambda_l2': 8.775203551947814e-05}. Best is trial 59 with value: 144146.55986989368.\u001b[0m\n",
            "regularization_factors, val_score: 144146.559870:  95%|#########5| 19/20 [00:43<00:02,  2.31s/it]\u001b[32m[I 2022-11-10 19:35:40,715]\u001b[0m Trial 61 finished with value: 146066.10372833075 and parameters: {'lambda_l1': 0.1174750329919743, 'lambda_l2': 0.00013018060934546366}. Best is trial 59 with value: 144146.55986989368.\u001b[0m\n",
            "regularization_factors, val_score: 144146.559870: 100%|##########| 20/20 [00:45<00:00,  2.32s/it]\u001b[32m[I 2022-11-10 19:35:43,044]\u001b[0m Trial 62 finished with value: 148210.3289233848 and parameters: {'lambda_l1': 0.8690793387112837, 'lambda_l2': 1.0387644692769522e-05}. Best is trial 59 with value: 144146.55986989368.\u001b[0m\n",
            "regularization_factors, val_score: 144146.559870: 100%|##########| 20/20 [00:45<00:00,  2.30s/it]\n",
            "min_data_in_leaf, val_score: 144146.559870:  20%|##        | 1/5 [00:02<00:11,  2.97s/it]\u001b[32m[I 2022-11-10 19:35:46,051]\u001b[0m Trial 63 finished with value: 149361.5314217695 and parameters: {'min_child_samples': 100}. Best is trial 63 with value: 149361.5314217695.\u001b[0m\n",
            "min_data_in_leaf, val_score: 144146.559870:  40%|####      | 2/5 [00:05<00:07,  2.53s/it]\u001b[32m[I 2022-11-10 19:35:48,279]\u001b[0m Trial 64 finished with value: 150696.69119957427 and parameters: {'min_child_samples': 10}. Best is trial 63 with value: 149361.5314217695.\u001b[0m\n",
            "min_data_in_leaf, val_score: 144146.559870:  60%|######    | 3/5 [00:07<00:04,  2.44s/it]\u001b[32m[I 2022-11-10 19:35:50,609]\u001b[0m Trial 65 finished with value: 149407.86138678357 and parameters: {'min_child_samples': 25}. Best is trial 63 with value: 149361.5314217695.\u001b[0m\n",
            "min_data_in_leaf, val_score: 144146.559870:  80%|########  | 4/5 [00:10<00:02,  2.50s/it]\u001b[32m[I 2022-11-10 19:35:53,196]\u001b[0m Trial 66 finished with value: 144904.71048816046 and parameters: {'min_child_samples': 50}. Best is trial 66 with value: 144904.71048816046.\u001b[0m\n",
            "min_data_in_leaf, val_score: 144146.559870: 100%|##########| 5/5 [00:12<00:00,  2.40s/it]\u001b[32m[I 2022-11-10 19:35:55,406]\u001b[0m Trial 67 finished with value: 146910.55429405867 and parameters: {'min_child_samples': 5}. Best is trial 66 with value: 144904.71048816046.\u001b[0m\n",
            "min_data_in_leaf, val_score: 144146.559870: 100%|##########| 5/5 [00:12<00:00,  2.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 6min 41s, sys: 9.94 s, total: 6min 51s\n",
            "Wall time: 3min 49s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)\n",
        "from flaml.ml import sklearn_metric_loss_score\n",
        "print('Optuna LightGBM Tuner r2', '=', 1 - sklearn_metric_loss_score('r2', y_pred, Y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZBvilSZ6RFb",
        "outputId": "c749c91c-09d3-4c4d-9e73-3acd5cb117c4"
      },
      "id": "nZBvilSZ6RFb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optuna LightGBM Tuner r2 = 0.3306821760581846\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "236ea059",
      "metadata": {
        "id": "236ea059"
      },
      "outputs": [],
      "source": [
        "#predict = automl.predict(X_test)\n",
        "#predict = [float(x) for x in np.array(predict)]\n",
        "#from sklearn.metrics import classification_report\n",
        "#print(classification_report(y_test, predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cafd7d6",
      "metadata": {
        "id": "1cafd7d6"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('house_regression.pkl', 'wb') as b:\n",
        "    pickle.dump(automl, b, pickle.HIGHEST_PROTOCOL)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}